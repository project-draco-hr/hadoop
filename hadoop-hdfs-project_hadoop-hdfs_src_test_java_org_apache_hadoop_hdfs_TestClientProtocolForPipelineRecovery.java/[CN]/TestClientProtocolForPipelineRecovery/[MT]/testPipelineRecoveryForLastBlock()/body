{
  DFSClientFaultInjector faultInjector=Mockito.mock(DFSClientFaultInjector.class);
  DFSClientFaultInjector oldInjector=DFSClientFaultInjector.instance;
  DFSClientFaultInjector.instance=faultInjector;
  Configuration conf=new HdfsConfiguration();
  conf.setInt(DFSConfigKeys.DFS_CLIENT_BLOCK_WRITE_LOCATEFOLLOWINGBLOCK_RETRIES_KEY,3);
  MiniDFSCluster cluster=null;
  try {
    int numDataNodes=3;
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).build();
    cluster.waitActive();
    FileSystem fileSys=cluster.getFileSystem();
    Path file=new Path("dataprotocol1.dat");
    Mockito.when(faultInjector.failPacket()).thenReturn(true);
    DFSTestUtil.createFile(fileSys,file,68000000L,(short)numDataNodes,0L);
    FSDataInputStream in=fileSys.open(file);
    try {
      int c=in.read();
    }
 catch (    org.apache.hadoop.hdfs.BlockMissingException bme) {
      Assert.fail("Block is missing because the file was closed with" + " corrupt replicas.");
    }
  }
  finally {
    DFSClientFaultInjector.instance=oldInjector;
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
