{
  setupGroupsProvider();
  Properties props=new Properties();
  props.setProperty("hadoop.http.filter.initializers",DummyFilterInitializer.class.getName());
  props.setProperty(MRConfig.MR_ACLS_ENABLED,String.valueOf(true));
  props.setProperty("dfs.permissions.enabled","false");
  props.setProperty("mapred.job.tracker.history.completed.location","historyDoneFolderOnHDFS");
  props.setProperty(MRJobConfig.SETUP_CLEANUP_NEEDED,"false");
  props.setProperty(MRConfig.MR_SUPERGROUP,"superGroup");
  props.setProperty(MRConfig.MR_ADMINS,mrAdminUser + " " + mrAdminGroup);
  props.setProperty(JTConfig.JT_RETIREJOBS,"true");
  String[] queueNames={"default"};
  String[] submitAclStrings=new String[]{jobSubmitter};
  String[] adminsAclStrings=new String[]{qAdmin};
  startCluster(props,queueNames,submitAclStrings,adminsAclStrings);
  MiniMRCluster cluster=getMRCluster();
  int infoPort=cluster.getJobTrackerRunner().getJobTrackerInfoPort();
  JobConf conf=new JobConf(cluster.createJobConf());
  conf.set(MRJobConfig.JOB_ACL_VIEW_JOB,viewColleague + " group3");
  conf.set(MRJobConfig.JOB_ACL_MODIFY_JOB," group1,group3");
  final SleepJob sleepJob=new SleepJob();
  sleepJob.setConf(conf);
  UserGroupInformation jobSubmitterUGI=UserGroupInformation.createRemoteUser(jobSubmitter);
  Job job=jobSubmitterUGI.doAs(new PrivilegedExceptionAction<Job>(){
    public Job run() throws Exception {
      Job job=sleepJob.createJob(1,0,1000,1,0,0);
      job.waitForCompletion(true);
      return job;
    }
  }
);
  org.apache.hadoop.mapreduce.JobID jobid=job.getJobID();
  for (int i=0; i < 10 && !job.isRetired(); i++) {
    UtilsForTests.waitFor(1000);
    LOG.info("waiting for the job " + jobid + " to retire");
  }
  assertTrue("Job did not retire",job.isRetired());
  String historyFileName=job.getStatus().getHistoryFile();
  String jtURL="http://localhost:" + infoPort;
  String jobDetailsJSP=jtURL + "/jobdetailshistory.jsp?logFile=" + historyFileName;
  validateViewJob(jobDetailsJSP,"GET");
  String jobTasksJSP=jtURL + "/jobtaskshistory.jsp?logFile=" + historyFileName;
  String[] taskTypes=new String[]{"JOb_SETUP","MAP","REDUCE","JOB_CLEANUP"};
  String[] states=new String[]{"all","SUCCEEDED","FAILED","KILLED"};
  for (  String taskType : taskTypes) {
    for (    String state : states) {
      validateViewJob(jobTasksJSP + "&taskType=" + taskType+ "&status="+ state,"GET");
    }
  }
  JobHistoryParser parser=new JobHistoryParser(new Path(historyFileName).getFileSystem(conf),historyFileName);
  JobInfo jobInfo=parser.parse();
  Map<TaskID,TaskInfo> tipsMap=jobInfo.getAllTasks();
  for (  TaskID tip : tipsMap.keySet()) {
    validateViewJob(jtURL + "/taskdetailshistory.jsp?logFile=" + historyFileName+ "&tipid="+ tip.toString(),"GET");
    Map<TaskAttemptID,TaskAttemptInfo> attemptsMap=tipsMap.get(tip).getAllTaskAttempts();
    for (    TaskAttemptID attempt : attemptsMap.keySet()) {
      validateViewJob(jtURL + "/taskstatshistory.jsp?attemptid=" + attempt.toString()+ "&logFile="+ historyFileName,"GET");
      String stdoutURL=TaskLogServlet.getTaskLogUrl("localhost",Integer.toString(attemptsMap.get(attempt).getHttpPort()),attempt.toString()) + "&filter=" + TaskLog.LogName.STDOUT;
      validateViewJob(stdoutURL,"GET");
      String stderrURL=TaskLogServlet.getTaskLogUrl("localhost",Integer.toString(attemptsMap.get(attempt).getHttpPort()),attempt.toString()) + "&filter=" + TaskLog.LogName.STDERR;
      validateViewJob(stderrURL,"GET");
    }
  }
  Path jobACLsFilePath=new Path(TaskLog.getJobDir(jobid).toString(),TaskTracker.jobACLsFile);
  assertTrue("Could not delete job-acls.xml file.",new File(jobACLsFilePath.toUri().getPath()).delete());
  for (  TaskID tip : tipsMap.keySet()) {
    Map<TaskAttemptID,TaskAttemptInfo> attemptsMap=tipsMap.get(tip).getAllTaskAttempts();
    for (    TaskAttemptID attempt : attemptsMap.keySet()) {
      String stdoutURL=TaskLogServlet.getTaskLogUrl("localhost",Integer.toString(attemptsMap.get(attempt).getHttpPort()),attempt.toString()) + "&filter=" + TaskLog.LogName.STDOUT;
      ;
      String stderrURL=TaskLogServlet.getTaskLogUrl("localhost",Integer.toString(attemptsMap.get(attempt).getHttpPort()),attempt.toString()) + "&filter=" + TaskLog.LogName.STDERR;
      assertEquals("Incorrect return code for " + unauthorizedUser,HttpURLConnection.HTTP_OK,getHttpStatusCode(stdoutURL,unauthorizedUser,"GET"));
      assertEquals("Incorrect return code for " + unauthorizedUser,HttpURLConnection.HTTP_OK,getHttpStatusCode(stderrURL,unauthorizedUser,"GET"));
      File attemptLogDir=TaskLog.getAttemptDir(org.apache.hadoop.mapred.TaskAttemptID.downgrade(attempt),false);
      FileUtil.fullyDelete(attemptLogDir);
      assertEquals("Incorrect return code for " + jobSubmitter,HttpURLConnection.HTTP_GONE,getHttpStatusCode(stdoutURL,jobSubmitter,"GET"));
      assertEquals("Incorrect return code for " + jobSubmitter,HttpURLConnection.HTTP_GONE,getHttpStatusCode(stderrURL,jobSubmitter,"GET"));
    }
  }
  String analyseJobHistoryJSP=jtURL + "/analysejobhistory.jsp?logFile=" + historyFileName;
  validateViewJob(analyseJobHistoryJSP,"GET");
  String jobConfJSP=jtURL + "/jobconf_history.jsp?logFile=" + historyFileName;
  validateViewJob(jobConfJSP,"GET");
}
