{
  long localstart=Time.monotonicNow();
  final DfsClientConf conf=dfsClient.getConf();
  long sleeptime=conf.getBlockWriteLocateFollowingInitialDelayMs();
  boolean fileComplete=false;
  int retries=conf.getNumBlockWriteLocateFollowingRetry();
  while (!fileComplete) {
    fileComplete=dfsClient.namenode.complete(src,dfsClient.clientName,last,fileId);
    if (!fileComplete) {
      final int hdfsTimeout=conf.getHdfsTimeout();
      if (!dfsClient.clientRunning || (hdfsTimeout > 0 && localstart + hdfsTimeout < Time.monotonicNow())) {
        String msg="Unable to close file because dfsclient " + " was unable to contact the HDFS servers. clientRunning " + dfsClient.clientRunning + " hdfsTimeout "+ hdfsTimeout;
        DFSClient.LOG.info(msg);
        throw new IOException(msg);
      }
      try {
        if (retries == 0) {
          throw new IOException("Unable to close file because the last block" + last + " does not have enough number of replicas.");
        }
        retries--;
        Thread.sleep(sleeptime);
        sleeptime*=2;
        if (Time.monotonicNow() - localstart > 5000) {
          DFSClient.LOG.info("Could not complete " + src + " retrying...");
        }
      }
 catch (      InterruptedException ie) {
        DFSClient.LOG.warn("Caught exception ",ie);
      }
    }
  }
}
