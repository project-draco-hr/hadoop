{
  TraceScope scope=dfsClient.newPathTraceScope("newStreamForCreate",src);
  try {
    HdfsFileStatus stat=null;
    boolean shouldRetry=true;
    int retryCount=CREATE_RETRY_COUNT;
    while (shouldRetry) {
      shouldRetry=false;
      try {
        stat=dfsClient.namenode.create(src,masked,dfsClient.clientName,new EnumSetWritable<CreateFlag>(flag),createParent,replication,blockSize,SUPPORTED_CRYPTO_VERSIONS);
        break;
      }
 catch (      RemoteException re) {
        IOException e=re.unwrapRemoteException(AccessControlException.class,DSQuotaExceededException.class,QuotaByStorageTypeExceededException.class,FileAlreadyExistsException.class,FileNotFoundException.class,ParentNotDirectoryException.class,NSQuotaExceededException.class,RetryStartFileException.class,SafeModeException.class,UnresolvedPathException.class,SnapshotAccessControlException.class,UnknownCryptoProtocolVersionException.class);
        if (e instanceof RetryStartFileException) {
          if (retryCount > 0) {
            shouldRetry=true;
            retryCount--;
          }
 else {
            throw new IOException("Too many retries because of encryption" + " zone operations",e);
          }
        }
 else {
          throw e;
        }
      }
    }
    Preconditions.checkNotNull(stat,"HdfsFileStatus should not be null!");
    final DFSOutputStream out=new DFSOutputStream(dfsClient,src,stat,flag,progress,checksum,favoredNodes);
    out.start();
    return out;
  }
  finally {
    scope.close();
  }
}
