{
  JobImpl mockJob=mock(JobImpl.class);
  mockJob.tasks=new HashMap<TaskId,Task>();
  OutputCommitter mockCommitter=mock(OutputCommitter.class);
  EventHandler mockEventHandler=mock(EventHandler.class);
  JobContext mockJobContext=mock(JobContext.class);
  when(mockJob.getCommitter()).thenReturn(mockCommitter);
  when(mockJob.getEventHandler()).thenReturn(mockEventHandler);
  when(mockJob.getJobContext()).thenReturn(mockJobContext);
  when(mockJob.finished(JobState.KILLED)).thenReturn(JobState.KILLED);
  when(mockJob.finished(JobState.FAILED)).thenReturn(JobState.FAILED);
  when(mockJob.finished(JobState.SUCCEEDED)).thenReturn(JobState.SUCCEEDED);
  try {
    doThrow(new IOException()).when(mockCommitter).commitJob(any(JobContext.class));
  }
 catch (  IOException e) {
  }
  doNothing().when(mockEventHandler).handle(any(JobHistoryEvent.class));
  JobState jobState=JobImpl.checkJobCompleteSuccess(mockJob);
  Assert.assertNotNull("checkJobCompleteSuccess incorrectly returns null " + "for successful job",jobState);
  Assert.assertEquals("checkJobCompleteSuccess returns incorrect state",JobState.FAILED,jobState);
  verify(mockJob).abortJob(eq(org.apache.hadoop.mapreduce.JobStatus.State.FAILED));
}
