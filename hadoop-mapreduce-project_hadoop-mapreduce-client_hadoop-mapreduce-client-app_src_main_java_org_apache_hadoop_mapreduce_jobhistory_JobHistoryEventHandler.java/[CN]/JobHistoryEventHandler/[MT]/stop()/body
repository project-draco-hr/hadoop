{
  LOG.info("Stopping JobHistoryEventHandler. " + "Size of the outstanding queue size is " + eventQueue.size());
  stopped=true;
synchronized (lock) {
    if (eventHandlingThread != null)     eventHandlingThread.interrupt();
  }
  try {
    if (eventHandlingThread != null)     eventHandlingThread.join();
  }
 catch (  InterruptedException ie) {
    LOG.info("Interruped Exception while stopping",ie);
  }
  for (  MetaInfo mi : fileMap.values()) {
    try {
      mi.shutDownTimer();
    }
 catch (    IOException e) {
      LOG.info("Exception while cancelling delayed flush timer. " + "Likely caused by a failed flush " + e.getMessage());
    }
  }
  Iterator<JobHistoryEvent> it=eventQueue.iterator();
  while (it.hasNext()) {
    JobHistoryEvent ev=it.next();
    LOG.info("In stop, writing event " + ev.getType());
    handleEvent(ev);
  }
  Iterator<JobId> jobIt=fileMap.keySet().iterator();
  if (isSignalled) {
    while (jobIt.hasNext()) {
      JobId toClose=jobIt.next();
      MetaInfo mi=fileMap.get(toClose);
      if (mi != null && mi.isWriterActive()) {
        LOG.warn("Found jobId " + toClose + " to have not been closed. Will close");
        JobUnsuccessfulCompletionEvent jucEvent=new JobUnsuccessfulCompletionEvent(TypeConverter.fromYarn(toClose),System.currentTimeMillis(),context.getJob(toClose).getCompletedMaps(),context.getJob(toClose).getCompletedReduces(),JobState.KILLED.toString());
        JobHistoryEvent jfEvent=new JobHistoryEvent(toClose,jucEvent);
        handleEvent(jfEvent);
      }
    }
  }
  for (  MetaInfo mi : fileMap.values()) {
    try {
      mi.closeWriter();
    }
 catch (    IOException e) {
      LOG.info("Exception while closing file " + e.getMessage());
    }
  }
  LOG.info("Stopped JobHistoryEventHandler. super.stop()");
  super.stop();
}
