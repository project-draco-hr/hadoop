{
  OutputStream os=getFileSystem().create(new Path(getInputDir(),"text.txt"));
  Writer wr=new OutputStreamWriter(os);
  wr.write("hello1\n");
  wr.write("hello2\n");
  wr.write("hello3\n");
  wr.write("hello4\n");
  wr.close();
  if (restart) {
    stopCluster();
    startCluster(false,null);
  }
  JobConf conf=createJobConf();
  conf.setJobName("mr");
  conf.setInputFormat(TextInputFormat.class);
  conf.setMapOutputKeyClass(LongWritable.class);
  conf.setMapOutputValueClass(Text.class);
  conf.setOutputFormat(TextOutputFormat.class);
  conf.setOutputKeyClass(LongWritable.class);
  conf.setOutputValueClass(Text.class);
  conf.setMapperClass(org.apache.hadoop.mapred.lib.IdentityMapper.class);
  conf.setReducerClass(org.apache.hadoop.mapred.lib.IdentityReducer.class);
  FileInputFormat.setInputPaths(conf,getInputDir());
  FileOutputFormat.setOutputPath(conf,getOutputDir());
  JobClient.runJob(conf);
  Path[] outputFiles=FileUtil.stat2Paths(getFileSystem().listStatus(getOutputDir(),new Utils.OutputFileUtils.OutputFilesFilter()));
  if (outputFiles.length > 0) {
    InputStream is=getFileSystem().open(outputFiles[0]);
    BufferedReader reader=new BufferedReader(new InputStreamReader(is));
    String line=reader.readLine();
    int counter=0;
    while (line != null) {
      counter++;
      assertTrue(line.contains("hello"));
      line=reader.readLine();
    }
    reader.close();
    assertEquals(4,counter);
  }
}
