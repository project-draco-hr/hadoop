{
  Configuration conf=new Configuration();
  conf.setLong(DFS_BLOCK_SIZE_KEY,BLOCK_SIZE);
  conf.setInt(DFS_NAMENODE_LAZY_PERSIST_FILE_SCRUB_INTERVAL_SEC,LAZY_WRITE_FILE_SCRUBBER_INTERVAL_SEC);
  conf.setLong(DFS_HEARTBEAT_INTERVAL_KEY,HEARTBEAT_INTERVAL_SEC);
  conf.setInt(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,HEARTBEAT_RECHECK_INTERVAL_MSEC);
  conf.setInt(DFS_DATANODE_LAZY_WRITER_INTERVAL_SEC,LAZY_WRITER_INTERVAL_SEC);
  if (useSCR) {
    conf.setBoolean(HdfsClientConfigKeys.Read.ShortCircuit.KEY,useSCR);
    conf.set(DFS_CLIENT_CONTEXT,UUID.randomUUID().toString());
    sockDir=new TemporarySocketDirectory();
    conf.set(DFS_DOMAIN_SOCKET_PATH_KEY,new File(sockDir.getDir(),this.getClass().getSimpleName() + "._PORT.sock").getAbsolutePath());
    conf.set(DFS_BLOCK_LOCAL_PATH_ACCESS_USER_KEY,UserGroupInformation.getCurrentUser().getShortUserName());
  }
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).storageTypes(storageTypes != null ? storageTypes : new StorageType[]{DEFAULT,DEFAULT}).build();
  fs=cluster.getFileSystem();
  client=fs.getClient();
  if (ramDiskStorageLimit >= 0) {
    List<? extends FsVolumeSpi> volumes=cluster.getDataNodes().get(0).getFSDataset().getVolumes();
    for (    FsVolumeSpi volume : volumes) {
      if (volume.getStorageType() == RAM_DISK) {
        ((FsVolumeImpl)volume).setCapacityForTesting(ramDiskStorageLimit);
      }
    }
  }
  LOG.info("Cluster startup complete");
}
