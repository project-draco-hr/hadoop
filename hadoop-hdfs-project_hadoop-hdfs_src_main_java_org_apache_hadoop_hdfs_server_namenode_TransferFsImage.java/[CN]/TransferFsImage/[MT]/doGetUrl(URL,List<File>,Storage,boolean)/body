{
  long startTime=Time.monotonicNow();
  HttpURLConnection connection;
  try {
    connection=(HttpURLConnection)connectionFactory.openConnection(url,isSpnegoEnabled);
  }
 catch (  AuthenticationException e) {
    throw new IOException(e);
  }
  if (timeout <= 0) {
    Configuration conf=new HdfsConfiguration();
    timeout=conf.getInt(DFSConfigKeys.DFS_IMAGE_TRANSFER_TIMEOUT_KEY,DFSConfigKeys.DFS_IMAGE_TRANSFER_TIMEOUT_DEFAULT);
  }
  if (timeout > 0) {
    connection.setConnectTimeout(timeout);
    connection.setReadTimeout(timeout);
  }
  if (connection.getResponseCode() != HttpURLConnection.HTTP_OK) {
    throw new HttpGetFailedException("Image transfer servlet at " + url + " failed with status code "+ connection.getResponseCode()+ "\nResponse message:\n"+ connection.getResponseMessage(),connection);
  }
  long advertisedSize;
  String contentLength=connection.getHeaderField(CONTENT_LENGTH);
  if (contentLength != null) {
    advertisedSize=Long.parseLong(contentLength);
  }
 else {
    throw new IOException(CONTENT_LENGTH + " header is not provided " + "by the namenode when trying to fetch "+ url);
  }
  if (localPaths != null) {
    String fsImageName=connection.getHeaderField(GetImageServlet.HADOOP_IMAGE_EDITS_HEADER);
    List<File> newLocalPaths=new ArrayList<File>();
    for (    File localPath : localPaths) {
      if (localPath.isDirectory()) {
        if (fsImageName == null) {
          throw new IOException("No filename header provided by server");
        }
        newLocalPaths.add(new File(localPath,fsImageName));
      }
 else {
        newLocalPaths.add(localPath);
      }
    }
    localPaths=newLocalPaths;
  }
  MD5Hash advertisedDigest=parseMD5Header(connection);
  long received=0;
  InputStream stream=connection.getInputStream();
  MessageDigest digester=null;
  if (getChecksum) {
    digester=MD5Hash.getDigester();
    stream=new DigestInputStream(stream,digester);
  }
  boolean finishedReceiving=false;
  List<FileOutputStream> outputStreams=Lists.newArrayList();
  try {
    if (localPaths != null) {
      for (      File f : localPaths) {
        try {
          if (f.exists()) {
            LOG.warn("Overwriting existing file " + f + " with file downloaded from "+ url);
          }
          outputStreams.add(new FileOutputStream(f));
        }
 catch (        IOException ioe) {
          LOG.warn("Unable to download file " + f,ioe);
          if (dstStorage != null && (dstStorage instanceof StorageErrorReporter)) {
            ((StorageErrorReporter)dstStorage).reportErrorOnFile(f);
          }
        }
      }
      if (outputStreams.isEmpty()) {
        throw new IOException("Unable to download to any storage directory");
      }
    }
    int num=1;
    byte[] buf=new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];
    while (num > 0) {
      num=stream.read(buf);
      if (num > 0) {
        received+=num;
        for (        FileOutputStream fos : outputStreams) {
          fos.write(buf,0,num);
        }
      }
    }
    finishedReceiving=true;
  }
  finally {
    stream.close();
    for (    FileOutputStream fos : outputStreams) {
      fos.getChannel().force(true);
      fos.close();
    }
    if (finishedReceiving && received != advertisedSize) {
      throw new IOException("File " + url + " received length "+ received+ " is not of the advertised size "+ advertisedSize);
    }
  }
  double xferSec=Math.max(((float)(Time.monotonicNow() - startTime)) / 1000.0,0.001);
  long xferKb=received / 1024;
  LOG.info(String.format("Transfer took %.2fs at %.2f KB/s",xferSec,xferKb / xferSec));
  if (digester != null) {
    MD5Hash computedDigest=new MD5Hash(digester.digest());
    if (advertisedDigest != null && !computedDigest.equals(advertisedDigest)) {
      throw new IOException("File " + url + " computed digest "+ computedDigest+ " does not match advertised digest "+ advertisedDigest);
    }
    return computedDigest;
  }
 else {
    return null;
  }
}
