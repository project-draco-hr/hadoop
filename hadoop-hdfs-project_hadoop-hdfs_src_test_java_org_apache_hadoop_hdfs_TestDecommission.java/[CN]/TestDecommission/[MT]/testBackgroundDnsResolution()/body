{
  Configuration hdfsConf=new Configuration(conf);
  hdfsConf.setInt(DFSConfigKeys.DFS_NAMENODE_HOSTS_DNS_RESOLUTION_INTERVAL_SECONDS,1);
  cluster=new MiniDFSCluster.Builder(hdfsConf).numDataNodes(1).checkDataNodeHostConfig(true).setupHostsFile(true).build();
  cluster.waitActive();
  ArrayList<String> nodes=new ArrayList<String>();
  String localhost=java.net.InetAddress.getLocalHost().getHostName();
  nodes.add(localhost);
  writeConfigFile(hostsFile,nodes);
  HostFileManager.dnsResolutionDisabledForTesting=true;
  refreshNodes(cluster.getNamesystem(0),hdfsConf);
  DFSClient client=getDfsClient(cluster.getNameNode(0),hdfsConf);
  while (true) {
    DatanodeInfo info[]=client.datanodeReport(DatanodeReportType.DEAD);
    if (info.length == 1) {
      break;
    }
    LOG.info("Waiting for datanode to be marked dead");
    Thread.sleep(HEARTBEAT_INTERVAL * 1000);
  }
  HostFileManager.dnsResolutionDisabledForTesting=false;
  cluster.restartDataNode(0);
  while (true) {
    DatanodeInfo info[]=client.datanodeReport(DatanodeReportType.LIVE);
    if (info.length == 1) {
      Assert.assertFalse(info[0].isDecommissioned());
      Assert.assertFalse(info[0].isDecommissionInProgress());
      break;
    }
    LOG.info("Waiting for datanode to come back");
    Thread.sleep(HEARTBEAT_INTERVAL * 1000);
  }
}
