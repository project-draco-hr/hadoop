{
  LOG.info("Starting test testDecommissionWithNamenodeRestart");
  int numNamenodes=1;
  int numDatanodes=1;
  int replicas=1;
  getConf().setLong(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_DEFAULT);
  getConf().setLong(DFSConfigKeys.DFS_BLOCKREPORT_INITIAL_DELAY_KEY,5);
  startCluster(numNamenodes,numDatanodes);
  Path file1=new Path("testDecommissionWithNamenodeRestart.dat");
  FileSystem fileSys=getCluster().getFileSystem();
  writeFile(fileSys,file1,replicas);
  DFSClient client=getDfsClient(0);
  DatanodeInfo[] info=client.datanodeReport(DatanodeReportType.LIVE);
  DatanodeID excludedDatanodeID=info[0];
  String excludedDatanodeName=info[0].getXferAddr();
  initExcludeHost(excludedDatanodeName);
  getCluster().startDataNodes(getConf(),1,true,null,null,null,null);
  numDatanodes+=1;
  assertEquals("Number of datanodes should be 2 ",2,getCluster().getDataNodes().size());
  getCluster().restartNameNode();
  DatanodeInfo datanodeInfo=NameNodeAdapter.getDatanode(getCluster().getNamesystem(),excludedDatanodeID);
  waitNodeState(datanodeInfo,AdminStates.DECOMMISSIONED);
  assertEquals("All datanodes must be alive",numDatanodes,client.datanodeReport(DatanodeReportType.LIVE).length);
  assertTrue("Checked if block was replicated after decommission.",checkFile(fileSys,file1,replicas,datanodeInfo.getXferAddr(),numDatanodes) == null);
  cleanupFile(fileSys,file1);
  shutdownCluster();
  startCluster(numNamenodes,numDatanodes);
}
