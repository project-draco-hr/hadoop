{
  String jobName=TypeConverter.fromYarn(applicationAttemptId.getApplicationId()).toString();
  String jobhistoryDir=JobHistoryUtils.getConfiguredHistoryStagingDirPrefix(getConfig());
  FSDataInputStream in=null;
  Path historyFile=null;
  Path histDirPath=FileContext.getFileContext(getConfig()).makeQualified(new Path(jobhistoryDir));
  FileContext fc=FileContext.getFileContext(histDirPath.toUri(),getConfig());
  historyFile=fc.makeQualified(JobHistoryUtils.getStagingJobHistoryFile(histDirPath,jobName,(applicationAttemptId.getAttemptId() - 1)));
  LOG.info("History file is at " + historyFile);
  in=fc.open(historyFile);
  JobHistoryParser parser=new JobHistoryParser(in);
  jobInfo=parser.parse();
  Exception parseException=parser.getParseException();
  if (parseException != null) {
    LOG.info("Got an error parsing job-history file " + historyFile + ", ignoring incomplete events.",parseException);
  }
  Map<org.apache.hadoop.mapreduce.TaskID,TaskInfo> taskInfos=jobInfo.getAllTasks();
  for (  TaskInfo taskInfo : taskInfos.values()) {
    if (TaskState.SUCCEEDED.toString().equals(taskInfo.getTaskStatus())) {
      completedTasks.put(TypeConverter.toYarn(taskInfo.getTaskId()),taskInfo);
      LOG.info("Read from history task " + TypeConverter.toYarn(taskInfo.getTaskId()));
    }
  }
  LOG.info("Read completed tasks from history " + completedTasks.size());
}
