{
  MiniDFSCluster dfs=null;
  MiniMRCluster mr=null;
  FileSystem fileSys=null;
  try {
    Configuration conf=new Configuration();
    dfs=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_HADOOP_SLAVES).build();
    fileSys=dfs.getFileSystem();
    mr=new MiniMRCluster(NUM_HADOOP_SLAVES,fileSys.getUri().toString(),1);
    int numReducers=2;
    int numMappers=NUM_HADOOP_SLAVES * NUM_MAPS_PER_NODE;
    createInput(fileSys,numMappers);
    Path output1=new Path("/testlazy/output1");
    runTestLazyOutput(mr.createJobConf(),output1,numReducers,true);
    Path[] fileList=FileUtil.stat2Paths(fileSys.listStatus(output1,new Utils.OutputFileUtils.OutputFilesFilter()));
    for (int i=0; i < fileList.length; ++i) {
      System.out.println("Test1 File list[" + i + "]"+ ": "+ fileList[i]);
    }
    assertTrue(fileList.length == (numReducers - 1));
    Path output2=new Path("/testlazy/output2");
    runTestLazyOutput(mr.createJobConf(),output2,0,true);
    fileList=FileUtil.stat2Paths(fileSys.listStatus(output2,new Utils.OutputFileUtils.OutputFilesFilter()));
    for (int i=0; i < fileList.length; ++i) {
      System.out.println("Test2 File list[" + i + "]"+ ": "+ fileList[i]);
    }
    assertTrue(fileList.length == numMappers - 1);
    Path output3=new Path("/testlazy/output3");
    runTestLazyOutput(mr.createJobConf(),output3,0,false);
    fileList=FileUtil.stat2Paths(fileSys.listStatus(output3,new Utils.OutputFileUtils.OutputFilesFilter()));
    for (int i=0; i < fileList.length; ++i) {
      System.out.println("Test3 File list[" + i + "]"+ ": "+ fileList[i]);
    }
    assertTrue(fileList.length == numMappers);
  }
  finally {
    if (dfs != null) {
      dfs.shutdown();
    }
    if (mr != null) {
      mr.shutdown();
    }
  }
}
