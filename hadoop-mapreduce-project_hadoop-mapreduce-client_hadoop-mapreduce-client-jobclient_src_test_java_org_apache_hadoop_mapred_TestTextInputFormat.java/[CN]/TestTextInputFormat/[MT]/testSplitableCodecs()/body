{
  JobConf conf=new JobConf(defaultConf);
  int seed=new Random().nextInt();
  CompressionCodec codec=null;
  try {
    codec=(CompressionCodec)ReflectionUtils.newInstance(conf.getClassByName("org.apache.hadoop.io.compress.BZip2Codec"),conf);
  }
 catch (  ClassNotFoundException cnfe) {
    throw new IOException("Illegal codec!");
  }
  Path file=new Path(workDir,"test" + codec.getDefaultExtension());
  Reporter reporter=Reporter.NULL;
  LOG.info("seed = " + seed);
  Random random=new Random(seed);
  FileSystem localFs=FileSystem.getLocal(conf);
  localFs.delete(workDir,true);
  FileInputFormat.setInputPaths(conf,workDir);
  final int MAX_LENGTH=500000;
  for (int length=MAX_LENGTH / 2; length < MAX_LENGTH; length+=random.nextInt(MAX_LENGTH / 4) + 1) {
    for (int i=0; i < 3; i++) {
      int numSplits=random.nextInt(MAX_LENGTH / 2000) + 1;
      verifyPartitions(length,numSplits,file,codec,conf);
    }
  }
  verifyPartitions(471507,218,file,codec,conf);
  verifyPartitions(473608,110,file,codec,conf);
}
