{
  File[] baseDirs;
  StorageInfo storageInfo=null;
  for (int numDirs=1; numDirs <= 2; numDirs++) {
    conf=new HdfsConfiguration();
    conf=UpgradeUtilities.initializeStorageStateConf(numDirs,conf);
    String[] nameNodeDirs=conf.getStrings(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY);
    String[] dataNodeDirs=conf.getStrings(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY);
    conf.setBoolean(DFSConfigKeys.DFS_DATANODE_DUPLICATE_REPLICA_DELETION,false);
    log("Normal NameNode upgrade",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    try {
      final DistributedFileSystem dfs=cluster.getFileSystem();
      dfs.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
      dfs.rollingUpgrade(RollingUpgradeAction.PREPARE);
      fail();
    }
 catch (    RemoteException re) {
      assertEquals(InconsistentFSStateException.class.getName(),re.getClassName());
      LOG.info("The exception is expected.",re);
    }
    checkNameNode(nameNodeDirs,EXPECTED_TXID);
    if (numDirs > 1)     TestParallelImageWrite.checkImages(cluster.getNamesystem(),numDirs);
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("Normal DataNode upgrade",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    cluster.startDataNodes(conf,1,false,StartupOption.REGULAR,null);
    checkDataNode(dataNodeDirs,UpgradeUtilities.getCurrentBlockPoolID(null));
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("NameNode upgrade with existing previous dir",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"previous");
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("DataNode upgrade with existing previous dir",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"previous");
    cluster.startDataNodes(conf,1,false,StartupOption.REGULAR,null);
    checkDataNode(dataNodeDirs,UpgradeUtilities.getCurrentBlockPoolID(null));
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("DataNode upgrade with future stored layout version in current",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    baseDirs=UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    storageInfo=new StorageInfo(Integer.MIN_VALUE,UpgradeUtilities.getCurrentNamespaceID(cluster),UpgradeUtilities.getCurrentClusterID(cluster),UpgradeUtilities.getCurrentFsscTime(cluster),NodeType.DATA_NODE);
    UpgradeUtilities.createDataNodeVersionFile(baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startBlockPoolShouldFail(StartupOption.REGULAR,UpgradeUtilities.getCurrentBlockPoolID(null));
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("DataNode upgrade with newer fsscTime in current",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    baseDirs=UpgradeUtilities.createDataNodeStorageDirs(dataNodeDirs,"current");
    storageInfo=new StorageInfo(HdfsServerConstants.DATANODE_LAYOUT_VERSION,UpgradeUtilities.getCurrentNamespaceID(cluster),UpgradeUtilities.getCurrentClusterID(cluster),Long.MAX_VALUE,NodeType.DATA_NODE);
    UpgradeUtilities.createDataNodeVersionFile(baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startBlockPoolShouldFail(StartupOption.REGULAR,UpgradeUtilities.getCurrentBlockPoolID(null));
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    UpgradeUtilities.createEmptyDirs(dataNodeDirs);
    log("NameNode upgrade with no edits file",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    deleteStorageFilesWithPrefix(nameNodeDirs,"edits_");
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode upgrade with no image file",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    deleteStorageFilesWithPrefix(nameNodeDirs,"fsimage_");
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode upgrade with corrupt version file",numDirs);
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    for (    File f : baseDirs) {
      UpgradeUtilities.corruptFile(new File(f,"VERSION"),"layoutVersion".getBytes(Charsets.UTF_8),"xxxxxxxxxxxxx".getBytes(Charsets.UTF_8));
    }
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode upgrade with old layout version in current",numDirs);
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    storageInfo=new StorageInfo(Storage.LAST_UPGRADABLE_LAYOUT_VERSION + 1,UpgradeUtilities.getCurrentNamespaceID(null),UpgradeUtilities.getCurrentClusterID(null),UpgradeUtilities.getCurrentFsscTime(null),NodeType.NAME_NODE);
    UpgradeUtilities.createNameNodeVersionFile(conf,baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
    log("NameNode upgrade with future layout version in current",numDirs);
    baseDirs=UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    storageInfo=new StorageInfo(Integer.MIN_VALUE,UpgradeUtilities.getCurrentNamespaceID(null),UpgradeUtilities.getCurrentClusterID(null),UpgradeUtilities.getCurrentFsscTime(null),NodeType.NAME_NODE);
    UpgradeUtilities.createNameNodeVersionFile(conf,baseDirs,storageInfo,UpgradeUtilities.getCurrentBlockPoolID(cluster));
    startNameNodeShouldFail(StartupOption.UPGRADE);
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
  }
  int numDirs=4;
{
    conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_SCAN_PERIOD_HOURS_KEY,-1);
    conf.setBoolean(DFSConfigKeys.DFS_DATANODE_DUPLICATE_REPLICA_DELETION,false);
    conf=UpgradeUtilities.initializeStorageStateConf(numDirs,conf);
    String[] nameNodeDirs=conf.getStrings(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY);
    log("Normal NameNode upgrade",numDirs);
    UpgradeUtilities.createNameNodeStorageDirs(nameNodeDirs,"current");
    cluster=createCluster();
    try {
      final DistributedFileSystem dfs=cluster.getFileSystem();
      dfs.setSafeMode(SafeModeAction.SAFEMODE_ENTER);
      dfs.rollingUpgrade(RollingUpgradeAction.PREPARE);
      fail();
    }
 catch (    RemoteException re) {
      assertEquals(InconsistentFSStateException.class.getName(),re.getClassName());
      LOG.info("The exception is expected.",re);
    }
    checkNameNode(nameNodeDirs,EXPECTED_TXID);
    TestParallelImageWrite.checkImages(cluster.getNamesystem(),numDirs);
    cluster.shutdown();
    UpgradeUtilities.createEmptyDirs(nameNodeDirs);
  }
}
