{
  org.apache.hadoop.mapreduce.v2.api.records.JobId jobId=TypeConverter.toYarn(oldJobID);
  GetJobReportRequest request=recordFactory.newRecordInstance(GetJobReportRequest.class);
  request.setJobId(jobId);
  JobReport report=((GetJobReportResponse)invoke("getJobReport",GetJobReportRequest.class,request)).getJobReport();
  if (EnumSet.of(JobState.SUCCEEDED,JobState.FAILED,JobState.KILLED,JobState.ERROR).contains(report.getJobState())) {
    if (oldTaskAttemptID != null) {
      GetTaskAttemptReportRequest taRequest=recordFactory.newRecordInstance(GetTaskAttemptReportRequest.class);
      taRequest.setTaskAttemptId(TypeConverter.toYarn(oldTaskAttemptID));
      TaskAttemptReport taReport=((GetTaskAttemptReportResponse)invoke("getTaskAttemptReport",GetTaskAttemptReportRequest.class,taRequest)).getTaskAttemptReport();
      if (taReport.getContainerId() == null || taReport.getNodeManagerHost() == null) {
        throw new IOException("Unable to get log information for task: " + oldTaskAttemptID);
      }
      return new LogParams(taReport.getContainerId().toString(),taReport.getContainerId().getApplicationAttemptId().getApplicationId().toString(),BuilderUtils.newNodeId(taReport.getNodeManagerHost(),taReport.getNodeManagerPort()).toString(),report.getUser());
    }
 else {
      if (report.getAMInfos() == null || report.getAMInfos().size() == 0) {
        throw new IOException("Unable to get log information for job: " + oldJobID);
      }
      AMInfo amInfo=report.getAMInfos().get(report.getAMInfos().size() - 1);
      return new LogParams(amInfo.getContainerId().toString(),amInfo.getAppAttemptId().getApplicationId().toString(),BuilderUtils.newNodeId(amInfo.getNodeManagerHost(),amInfo.getNodeManagerPort()).toString(),report.getUser());
    }
  }
 else {
    throw new IOException("Cannot get log path for a in-progress job");
  }
}
