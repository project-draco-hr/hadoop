{
  org.apache.hadoop.mapreduce.v2.api.records.JobId jobID=TypeConverter.toYarn(arg0);
  List<org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptCompletionEvent> list=null;
  GetTaskAttemptCompletionEventsRequest request=recordFactory.newRecordInstance(GetTaskAttemptCompletionEventsRequest.class);
  MRClientProtocol protocol;
  try {
    request.setJobId(jobID);
    request.setFromEventId(arg1);
    request.setMaxEvents(arg2);
    protocol=getProxy(arg0);
    if (protocol == null) {
      return new TaskCompletionEvent[0];
    }
    list=getProxy(arg0).getTaskAttemptCompletionEvents(request).getCompletionEventList();
  }
 catch (  YarnRemoteException yre) {
    LOG.warn(RPCUtil.toString(yre));
    throw yre;
  }
catch (  Exception e) {
    LOG.debug("Failed to contact application master ",e);
    try {
      request.setJobId(jobID);
      request.setFromEventId(arg1);
      request.setMaxEvents(arg2);
      protocol=getRefreshedProxy(arg0);
      if (protocol == null) {
        return new TaskCompletionEvent[0];
      }
      list=protocol.getTaskAttemptCompletionEvents(request).getCompletionEventList();
    }
 catch (    YarnRemoteException yre) {
      LOG.warn(RPCUtil.toString(yre));
      throw yre;
    }
  }
  return TypeConverter.fromYarn(list.toArray(new org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptCompletionEvent[0]));
}
