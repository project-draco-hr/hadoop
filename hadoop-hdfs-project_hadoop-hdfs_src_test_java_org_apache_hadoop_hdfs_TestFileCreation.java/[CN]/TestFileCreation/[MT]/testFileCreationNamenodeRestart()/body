{
  Configuration conf=new HdfsConfiguration();
  final int MAX_IDLE_TIME=2000;
  conf.setInt("ipc.client.connection.maxidletime",MAX_IDLE_TIME);
  conf.setInt(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,1000);
  conf.setInt(DFS_HEARTBEAT_INTERVAL_KEY,1);
  if (simulatedStorage) {
    SimulatedFSDataset.setFactory(conf);
  }
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  DistributedFileSystem fs=null;
  try {
    cluster.waitActive();
    fs=cluster.getFileSystem();
    final int nnport=cluster.getNameNodePort();
    Path file1=new Path("/filestatus.dat");
    HdfsDataOutputStream stm=create(fs,file1,1);
    System.out.println("testFileCreationNamenodeRestart: " + "Created file " + file1);
    assertEquals(file1 + " should be replicated to 1 datanode.",1,stm.getCurrentBlockReplication());
    writeFile(stm,numBlocks * blockSize);
    stm.hflush();
    assertEquals(file1 + " should still be replicated to 1 datanode.",1,stm.getCurrentBlockReplication());
    Path fileRenamed=new Path("/filestatusRenamed.dat");
    fs.rename(file1,fileRenamed);
    System.out.println("testFileCreationNamenodeRestart: " + "Renamed file " + file1 + " to "+ fileRenamed);
    file1=fileRenamed;
    Path file2=new Path("/filestatus2.dat");
    FSDataOutputStream stm2=createFile(fs,file2,1);
    System.out.println("testFileCreationNamenodeRestart: " + "Created file " + file2);
    Path file3=new Path("/user/home/fullpath.dat");
    FSDataOutputStream stm3=createFile(fs,file3,1);
    System.out.println("testFileCreationNamenodeRestart: " + "Created file " + file3);
    Path file4=new Path("/user/home/fullpath4.dat");
    FSDataOutputStream stm4=createFile(fs,file4,1);
    System.out.println("testFileCreationNamenodeRestart: " + "Created file " + file4);
    fs.mkdirs(new Path("/bin"));
    fs.rename(new Path("/user/home"),new Path("/bin"));
    Path file3new=new Path("/bin/home/fullpath.dat");
    System.out.println("testFileCreationNamenodeRestart: " + "Renamed file " + file3 + " to "+ file3new);
    Path file4new=new Path("/bin/home/fullpath4.dat");
    System.out.println("testFileCreationNamenodeRestart: " + "Renamed file " + file4 + " to "+ file4new);
    cluster.shutdown(false,false);
    try {
      Thread.sleep(2 * MAX_IDLE_TIME);
    }
 catch (    InterruptedException e) {
    }
    cluster=new MiniDFSCluster.Builder(conf).nameNodePort(nnport).format(false).build();
    cluster.waitActive();
    cluster.shutdown(false,false);
    try {
      Thread.sleep(5000);
    }
 catch (    InterruptedException e) {
    }
    cluster=new MiniDFSCluster.Builder(conf).nameNodePort(nnport).format(false).build();
    cluster.waitActive();
    fs=cluster.getFileSystem();
    DFSOutputStream dfstream=(DFSOutputStream)(stm.getWrappedStream());
    dfstream.setTestFilename(file1.toString());
    dfstream=(DFSOutputStream)(stm3.getWrappedStream());
    dfstream.setTestFilename(file3new.toString());
    dfstream=(DFSOutputStream)(stm4.getWrappedStream());
    dfstream.setTestFilename(file4new.toString());
    byte[] buffer=AppendTestUtil.randomBytes(seed,1);
    stm.write(buffer);
    stm.close();
    stm2.write(buffer);
    stm2.close();
    stm3.close();
    stm4.close();
    DFSClient client=fs.dfs;
    LocatedBlocks locations=client.getNamenode().getBlockLocations(file1.toString(),0,Long.MAX_VALUE);
    System.out.println("locations = " + locations.locatedBlockCount());
    assertTrue("Error blocks were not cleaned up for file " + file1,locations.locatedBlockCount() == 3);
    locations=client.getNamenode().getBlockLocations(file2.toString(),0,Long.MAX_VALUE);
    System.out.println("locations = " + locations.locatedBlockCount());
    assertTrue("Error blocks were not cleaned up for file " + file2,locations.locatedBlockCount() == 1);
  }
  finally {
    IOUtils.closeStream(fs);
    cluster.shutdown();
  }
}
