{
  final short repl=3;
  final int blockSize=1024;
  final int numOfBlocks=2;
  DistributedFileSystem fs=cluster.getFileSystem();
  Path dir=getTestRootPath(fc,"test/hadoop");
  Path file=getTestRootPath(fc,"test/hadoop/file");
  final byte[] data=FileSystemTestHelper.getFileData(numOfBlocks,blockSize);
  FileSystemTestHelper.createFile(fs,file,data,blockSize,repl);
  final int newLength=blockSize;
  boolean isReady=fc.truncate(file,newLength);
  Assert.assertTrue("Recovery is not expected.",isReady);
  FileStatus fileStatus=fc.getFileStatus(file);
  Assert.assertEquals(fileStatus.getLen(),newLength);
  AppendTestUtil.checkFullFile(fs,file,newLength,data,file.toString());
  ContentSummary cs=fs.getContentSummary(dir);
  Assert.assertEquals("Bad disk space usage",cs.getSpaceConsumed(),newLength * repl);
  Assert.assertTrue(fs.delete(dir,true));
}
