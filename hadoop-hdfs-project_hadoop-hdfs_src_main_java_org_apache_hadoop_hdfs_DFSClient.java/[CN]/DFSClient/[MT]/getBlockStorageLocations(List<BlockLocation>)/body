{
  if (!getConf().getHdfsBlocksMetadataEnabled) {
    throw new UnsupportedOperationException("Datanode-side support for " + "getVolumeBlockLocations() must also be enabled in the client " + "configuration.");
  }
  List<LocatedBlock> blocks=new ArrayList<LocatedBlock>();
  for (  BlockLocation loc : blockLocations) {
    if (!(loc instanceof HdfsBlockLocation)) {
      throw new ClassCastException("DFSClient#getVolumeBlockLocations " + "expected to be passed HdfsBlockLocations");
    }
    HdfsBlockLocation hdfsLoc=(HdfsBlockLocation)loc;
    blocks.add(hdfsLoc.getLocatedBlock());
  }
  Map<DatanodeInfo,List<LocatedBlock>> datanodeBlocks=new LinkedHashMap<DatanodeInfo,List<LocatedBlock>>();
  for (  LocatedBlock b : blocks) {
    for (    DatanodeInfo info : b.getLocations()) {
      if (!datanodeBlocks.containsKey(info)) {
        datanodeBlocks.put(info,new ArrayList<LocatedBlock>());
      }
      List<LocatedBlock> l=datanodeBlocks.get(info);
      l.add(b);
    }
  }
  TraceScope scope=Trace.startSpan("getBlockStorageLocations",traceSampler);
  Map<DatanodeInfo,HdfsBlocksMetadata> metadatas;
  try {
    metadatas=BlockStorageLocationUtil.queryDatanodesForHdfsBlocksMetadata(conf,datanodeBlocks,getConf().getFileBlockStorageLocationsNumThreads,getConf().getFileBlockStorageLocationsTimeoutMs,getConf().connectToDnViaHostname);
    if (LOG.isTraceEnabled()) {
      LOG.trace("metadata returned: " + Joiner.on("\n").withKeyValueSeparator("=").join(metadatas));
    }
  }
  finally {
    scope.close();
  }
  Map<LocatedBlock,List<VolumeId>> blockVolumeIds=BlockStorageLocationUtil.associateVolumeIdsWithBlocks(blocks,metadatas);
  BlockStorageLocation[] volumeBlockLocations=BlockStorageLocationUtil.convertToVolumeBlockLocations(blocks,blockVolumeIds);
  return volumeBlockLocations;
}
