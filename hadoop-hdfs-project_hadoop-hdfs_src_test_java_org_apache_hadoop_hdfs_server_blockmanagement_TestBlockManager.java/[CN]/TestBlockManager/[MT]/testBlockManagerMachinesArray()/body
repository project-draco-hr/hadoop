{
  final Configuration conf=new HdfsConfiguration();
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(4).build();
  cluster.waitActive();
  BlockManager blockManager=cluster.getNamesystem().getBlockManager();
  FileSystem fs=cluster.getFileSystem();
  final Path filePath=new Path("/tmp.txt");
  final long fileLen=1L;
  DFSTestUtil.createFile(fs,filePath,fileLen,(short)3,1L);
  ArrayList<DataNode> datanodes=cluster.getDataNodes();
  assertEquals(datanodes.size(),4);
  FSNamesystem ns=cluster.getNamesystem();
  final String bpid=cluster.getNamesystem().getBlockPoolId();
  File storageDir=cluster.getInstanceStorageDir(0,0);
  File dataDir=MiniDFSCluster.getFinalizedDir(storageDir,bpid);
  assertTrue("Data directory does not exist",dataDir.exists());
  BlockInfo blockInfo=blockManager.blocksMap.getBlocks().iterator().next();
  ExtendedBlock blk=new ExtendedBlock(bpid,blockInfo.getBlockId(),blockInfo.getNumBytes(),blockInfo.getGenerationStamp());
  DatanodeDescriptor failedStorageDataNode=blockManager.getStoredBlock(blockInfo).getDatanode(0);
  DatanodeDescriptor corruptStorageDataNode=blockManager.getStoredBlock(blockInfo).getDatanode(1);
  ArrayList<StorageReport> reports=new ArrayList<StorageReport>();
  for (int i=0; i < failedStorageDataNode.getStorageInfos().length; i++) {
    DatanodeStorageInfo storageInfo=failedStorageDataNode.getStorageInfos()[i];
    DatanodeStorage dns=new DatanodeStorage(failedStorageDataNode.getStorageInfos()[i].getStorageID(),DatanodeStorage.State.FAILED,failedStorageDataNode.getStorageInfos()[i].getStorageType());
    while (storageInfo.getBlockIterator().hasNext()) {
      BlockInfo blockInfo1=storageInfo.getBlockIterator().next();
      if (blockInfo1.equals(blockInfo)) {
        StorageReport report=new StorageReport(dns,true,storageInfo.getCapacity(),storageInfo.getDfsUsed(),storageInfo.getRemaining(),storageInfo.getBlockPoolUsed(),0L);
        reports.add(report);
        break;
      }
    }
  }
  failedStorageDataNode.updateHeartbeat(reports.toArray(StorageReport.EMPTY_ARRAY),0L,0L,0,0,null);
  ns.writeLock();
  DatanodeStorageInfo corruptStorageInfo=null;
  for (int i=0; i < corruptStorageDataNode.getStorageInfos().length; i++) {
    corruptStorageInfo=corruptStorageDataNode.getStorageInfos()[i];
    while (corruptStorageInfo.getBlockIterator().hasNext()) {
      BlockInfo blockInfo1=corruptStorageInfo.getBlockIterator().next();
      if (blockInfo1.equals(blockInfo)) {
        break;
      }
    }
  }
  blockManager.findAndMarkBlockAsCorrupt(blk,corruptStorageDataNode,corruptStorageInfo.getStorageID(),CorruptReplicasMap.Reason.ANY.toString());
  ns.writeUnlock();
  BlockInfo[] blockInfos=new BlockInfo[]{blockInfo};
  ns.readLock();
  LocatedBlocks locatedBlocks=blockManager.createLocatedBlocks(blockInfos,3L,false,0L,3L,false,false,null,null);
  assertTrue("Located Blocks should exclude corrupt" + "replicas and failed storages",locatedBlocks.getLocatedBlocks().size() == 1);
  ns.readUnlock();
}
