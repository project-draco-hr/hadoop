{
  CountDownLatch createWorkPlanLatch=new CountDownLatch(1);
  CountDownLatch removeDiskLatch=new CountDownLatch(1);
  AtomicInteger errorCount=new AtomicInteger(0);
  LOG.info("FSDataSet: " + node.getFSDataset());
  final FsDatasetSpi<?> fsDatasetSpy=Mockito.spy(node.getFSDataset());
  doAnswer(new Answer<Object>(){
    public Object answer(    InvocationOnMock invocation){
      try {
        node.getFSDataset().moveBlockAcrossVolumes((ExtendedBlock)invocation.getArguments()[0],(FsVolumeSpi)invocation.getArguments()[1]);
      }
 catch (      Exception e) {
        errorCount.incrementAndGet();
      }
      return null;
    }
  }
).when(fsDatasetSpy).moveBlockAcrossVolumes(any(ExtendedBlock.class),any(FsVolumeSpi.class));
  DiskBalancerMover diskBalancerMover=new DiskBalancerMover(fsDatasetSpy,conf);
  diskBalancerMover.setRunnable();
  DiskBalancerMover diskBalancerMoverSpy=Mockito.spy(diskBalancerMover);
  doAnswer(new Answer<Object>(){
    public Object answer(    InvocationOnMock invocation){
      createWorkPlanLatch.countDown();
      LOG.info("Waiting for the disk removal!");
      try {
        removeDiskLatch.await();
      }
 catch (      InterruptedException e) {
        LOG.info("Encountered " + e);
      }
      LOG.info("Got disk removal notification, resuming copyBlocks!");
      diskBalancerMover.copyBlocks((VolumePair)(invocation.getArguments()[0]),(DiskBalancerWorkItem)(invocation.getArguments()[1]));
      return null;
    }
  }
).when(diskBalancerMoverSpy).copyBlocks(any(VolumePair.class),any(DiskBalancerWorkItem.class));
  DiskBalancer diskBalancer=new DiskBalancer(node.getDatanodeUuid(),conf,diskBalancerMoverSpy);
  List<String> oldDirs=new ArrayList<String>(node.getConf().getTrimmedStringCollection(DFSConfigKeys.DFS_DATANODE_DATA_DIR_KEY));
  final String newDirs=oldDirs.get(0);
  LOG.info("Reconfigure newDirs:" + newDirs);
  Thread reconfigThread=new Thread(){
    public void run(){
      try {
        LOG.info("Waiting for work plan creation!");
        createWorkPlanLatch.await();
        LOG.info("Work plan created. Removing disk!");
        assertThat("DN did not update its own config",node.reconfigurePropertyImpl(DFS_DATANODE_DATA_DIR_KEY,newDirs),is(node.getConf().get(DFS_DATANODE_DATA_DIR_KEY)));
        Thread.sleep(1000);
        LOG.info("Removed disk!");
        removeDiskLatch.countDown();
      }
 catch (      ReconfigurationException|InterruptedException e) {
        Assert.fail("Unexpected error while reconfiguring: " + e);
      }
    }
  }
;
  reconfigThread.start();
  String planJson=plan.toJson();
  String planID=DigestUtils.shaHex(planJson);
  diskBalancer.submitPlan(planID,1,PLAN_FILE,planJson,false);
  GenericTestUtils.waitFor(new Supplier<Boolean>(){
    @Override public Boolean get(){
      try {
        LOG.info("Work Status: " + diskBalancer.queryWorkStatus().toJsonString());
        Result result=diskBalancer.queryWorkStatus().getResult();
        return (result == Result.PLAN_DONE);
      }
 catch (      IOException e) {
        return false;
      }
    }
  }
,1000,100000);
  assertTrue("Disk balancer operation hit max errors!",errorCount.get() < DFSConfigKeys.DFS_DISK_BALANCER_MAX_DISK_ERRORS_DEFAULT);
  createWorkPlanLatch.await();
  removeDiskLatch.await();
}
