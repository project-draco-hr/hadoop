{
  final int SEED=0xFADED;
  Configuration conf=new HdfsConfiguration();
  conf.setLong(DFS_HEARTBEAT_INTERVAL_KEY,1);
  conf.setInt(DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,500);
  conf.setLong(DFSConfigKeys.DFS_NAMENODE_REPLICATION_INTERVAL_KEY,1);
  conf.setLong(DFSConfigKeys.DFS_BALANCER_GETBLOCKS_MIN_BLOCK_SIZE_KEY,1L);
  final int BLOCK_SIZE=1024 * 1024;
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).storageCapacities(new long[]{BLOCK_SIZE * 10}).storageTypes(new StorageType[]{DEFAULT}).storagesPerDatanode(1).build();
  try {
    cluster.waitActive();
    final String METHOD_NAME=GenericTestUtils.getMethodName();
    final Path path1=new Path("/" + METHOD_NAME + ".01.dat");
    DistributedFileSystem fs=cluster.getFileSystem();
    DFSTestUtil.createFile(fs,path1,BLOCK_SIZE,BLOCK_SIZE * 2,BLOCK_SIZE,(short)1,SEED);
    cluster.startDataNodes(conf,1,true,null,null);
    cluster.triggerHeartbeats();
    Collection<URI> namenodes=DFSUtil.getNsServiceRpcUris(conf);
    final Balancer.Parameters p=Parameters.DEFAULT;
    fs.setSafeMode(HdfsConstants.SafeModeAction.SAFEMODE_ENTER);
    fs.rollingUpgrade(HdfsConstants.RollingUpgradeAction.PREPARE);
    fs.setSafeMode(HdfsConstants.SafeModeAction.SAFEMODE_LEAVE);
    assertEquals(ExitStatus.UNFINALIZED_UPGRADE.getExitCode(),Balancer.run(namenodes,p,conf));
    final Balancer.Parameters runDuringUpgrade=new Balancer.Parameters(Parameters.DEFAULT.policy,Parameters.DEFAULT.threshold,Parameters.DEFAULT.maxIdleIteration,Parameters.DEFAULT.excludedNodes,Parameters.DEFAULT.includedNodes,Parameters.DEFAULT.sourceNodes,Balancer.Parameters.DEFAULT.blockpools,true);
    assertEquals(ExitStatus.SUCCESS.getExitCode(),Balancer.run(namenodes,runDuringUpgrade,conf));
    fs.rollingUpgrade(HdfsConstants.RollingUpgradeAction.FINALIZE);
    assertEquals(ExitStatus.SUCCESS.getExitCode(),Balancer.run(namenodes,p,conf));
  }
  finally {
    cluster.shutdown();
  }
}
