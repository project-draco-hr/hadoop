{
  final Configuration conf=new HdfsConfiguration();
  conf.setLong(DFSConfigKeys.DFS_NAMENODE_RECONSTRUCTION_PENDING_TIMEOUT_SEC_KEY,TIMEOUT);
  MiniDFSCluster cluster=null;
  Block block;
  BlockInfo blockInfo;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_COUNT).build();
    cluster.waitActive();
    FSNamesystem fsn=cluster.getNamesystem();
    BlockManager blkManager=fsn.getBlockManager();
    PendingReconstructionBlocks pendingReconstruction=blkManager.pendingReconstruction;
    LowRedundancyBlocks neededReconstruction=blkManager.neededReconstruction;
    BlocksMap blocksMap=blkManager.blocksMap;
    block=new Block(1,1,0);
    blockInfo=new BlockInfoContiguous(block,(short)3);
    pendingReconstruction.increment(blockInfo,DatanodeStorageInfo.toDatanodeDescriptors(DFSTestUtil.createDatanodeStorageInfos(1)));
    BlockCollection bc=Mockito.mock(BlockCollection.class);
    blockInfo.setGenerationStamp(1);
    blocksMap.addBlockCollection(blockInfo,bc);
    assertEquals("Size of pendingReconstructions ",1,pendingReconstruction.size());
    block=new Block(2,2,0);
    blockInfo=new BlockInfoContiguous(block,(short)3);
    pendingReconstruction.increment(blockInfo,DatanodeStorageInfo.toDatanodeDescriptors(DFSTestUtil.createDatanodeStorageInfos(1)));
    assertEquals("Size of pendingReconstructions ",2,pendingReconstruction.size());
    while (pendingReconstruction.size() > 0) {
      try {
        Thread.sleep(100);
      }
 catch (      Exception e) {
      }
    }
    while (neededReconstruction.size() == 0) {
      try {
        Thread.sleep(100);
      }
 catch (      Exception e) {
      }
    }
    for (    Block b : neededReconstruction) {
      assertEquals("Generation stamp is 1 ",1,b.getGenerationStamp());
    }
    assertEquals("size of neededReconstruction is 1 ",1,neededReconstruction.size());
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
