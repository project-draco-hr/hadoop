{
  Configuration conf=new HdfsConfiguration();
  conf.setInt(HdfsClientConfigKeys.BlockWrite.LOCATEFOLLOWINGBLOCK_RETRIES_KEY,1);
  MiniDFSCluster cluster=null;
  final int nodes=8;
  final int fileCount=5;
  final short fileRepl=3;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(nodes).build();
    cluster.waitActive();
    final FSNamesystem namesystem=cluster.getNamesystem();
    final DatanodeManager dnm=namesystem.getBlockManager().getDatanodeManager();
    List<DataNode> datanodes=cluster.getDataNodes();
    final DistributedFileSystem fs=cluster.getFileSystem();
    triggerHeartbeats(datanodes);
    int expectedTotalLoad=nodes;
    int expectedInServiceNodes=nodes;
    int expectedInServiceLoad=nodes;
    checkClusterHealth(nodes,namesystem,expectedTotalLoad,expectedInServiceNodes,expectedInServiceLoad);
    for (int i=0; i < nodes / 2; i++) {
      DataNode dn=datanodes.get(i);
      DatanodeDescriptor dnd=dnm.getDatanode(dn.getDatanodeId());
      dn.shutdown();
      DFSTestUtil.setDatanodeDead(dnd);
      BlockManagerTestUtil.checkHeartbeat(namesystem.getBlockManager());
      dnm.getDecomManager().startDecommission(dnd);
      expectedInServiceNodes--;
      assertEquals(expectedInServiceNodes,namesystem.getNumLiveDataNodes());
      assertEquals(expectedInServiceNodes,getNumDNInService(namesystem));
      dnm.getDecomManager().stopDecommission(dnd);
      assertEquals(expectedInServiceNodes,getNumDNInService(namesystem));
    }
    cluster.restartDataNodes();
    cluster.waitActive();
    datanodes=cluster.getDataNodes();
    expectedInServiceNodes=nodes;
    assertEquals(nodes,datanodes.size());
    checkClusterHealth(nodes,namesystem,expectedTotalLoad,expectedInServiceNodes,expectedInServiceLoad);
    DFSOutputStream[] streams=new DFSOutputStream[fileCount];
    for (int i=0; i < fileCount; i++) {
      streams[i]=(DFSOutputStream)fs.create(new Path("/f" + i),fileRepl).getWrappedStream();
      streams[i].write("1".getBytes());
      streams[i].hsync();
      expectedTotalLoad+=2 * fileRepl;
      expectedInServiceLoad+=2 * fileRepl;
    }
    triggerHeartbeats(datanodes);
    checkClusterHealth(nodes,namesystem,expectedTotalLoad,expectedInServiceNodes,expectedInServiceLoad);
    for (int i=0; i < fileRepl; i++) {
      expectedInServiceNodes--;
      DatanodeDescriptor dnd=dnm.getDatanode(datanodes.get(i).getDatanodeId());
      expectedInServiceLoad-=dnd.getXceiverCount();
      dnm.getDecomManager().startDecommission(dnd);
      DataNodeTestUtils.triggerHeartbeat(datanodes.get(i));
      Thread.sleep(100);
      checkClusterHealth(nodes,namesystem,expectedTotalLoad,expectedInServiceNodes,expectedInServiceLoad);
    }
    for (int i=0; i < fileCount; i++) {
      int decomm=0;
      for (      DatanodeInfo dni : streams[i].getPipeline()) {
        DatanodeDescriptor dnd=dnm.getDatanode(dni);
        expectedTotalLoad-=2;
        if (dnd.isDecommissionInProgress() || dnd.isDecommissioned()) {
          decomm++;
        }
 else {
          expectedInServiceLoad-=2;
        }
      }
      try {
        streams[i].close();
      }
 catch (      IOException ioe) {
        if (decomm < fileRepl) {
          throw ioe;
        }
      }
      triggerHeartbeats(datanodes);
      checkClusterHealth(nodes,namesystem,expectedTotalLoad,expectedInServiceNodes,expectedInServiceLoad);
    }
    for (int i=0; i < nodes; i++) {
      DataNode dn=datanodes.get(i);
      dn.shutdown();
      DatanodeDescriptor dnDesc=dnm.getDatanode(dn.getDatanodeId());
      DFSTestUtil.setDatanodeDead(dnDesc);
      BlockManagerTestUtil.checkHeartbeat(namesystem.getBlockManager());
      assertEquals(nodes - 1 - i,namesystem.getNumLiveDataNodes());
      if (i >= fileRepl) {
        expectedInServiceNodes--;
      }
      assertEquals(expectedInServiceNodes,getNumDNInService(namesystem));
      double expectedXceiverAvg=(i == nodes - 1) ? 0.0 : 1.0;
      assertEquals((double)expectedXceiverAvg,getInServiceXceiverAverage(namesystem),EPSILON);
    }
    checkClusterHealth(0,namesystem,0.0,0,0.0);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
