{
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  long reserved=10000;
  conf.setLong(DFSConfigKeys.DFS_DATANODE_DU_RESERVED_KEY,reserved);
  try {
    cluster=new MiniDFSCluster.Builder(conf).build();
    cluster.waitActive();
    final FSNamesystem namesystem=cluster.getNamesystem();
    final DatanodeManager dm=cluster.getNamesystem().getBlockManager().getDatanodeManager();
    final List<DatanodeDescriptor> live=new ArrayList<DatanodeDescriptor>();
    final List<DatanodeDescriptor> dead=new ArrayList<DatanodeDescriptor>();
    dm.fetchDatanodes(live,dead,false);
    assertTrue(live.size() == 1);
    long used, remaining, configCapacity, nonDFSUsed, bpUsed;
    float percentUsed, percentRemaining, percentBpUsed;
    for (    final DatanodeDescriptor datanode : live) {
      used=datanode.getDfsUsed();
      remaining=datanode.getRemaining();
      nonDFSUsed=datanode.getNonDfsUsed();
      configCapacity=datanode.getCapacity();
      percentUsed=datanode.getDfsUsedPercent();
      percentRemaining=datanode.getRemainingPercent();
      bpUsed=datanode.getBlockPoolUsed();
      percentBpUsed=datanode.getBlockPoolUsedPercent();
      LOG.info("Datanode configCapacity " + configCapacity + " used "+ used+ " non DFS used "+ nonDFSUsed+ " remaining "+ remaining+ " perentUsed "+ percentUsed+ " percentRemaining "+ percentRemaining);
      assertTrue(configCapacity >= (used + remaining + nonDFSUsed));
      assertTrue(percentUsed == DFSUtilClient.getPercentUsed(used,configCapacity));
      assertTrue(percentRemaining == DFSUtilClient.getPercentRemaining(remaining,configCapacity));
      assertTrue(percentBpUsed == DFSUtilClient.getPercentUsed(bpUsed,configCapacity));
    }
    final FsDatasetTestUtils utils=cluster.getFsDatasetTestUtils(0);
    int numOfDataDirs=utils.getDefaultNumOfDataDirs();
    long diskCapacity=numOfDataDirs * utils.getRawCapacity();
    reserved*=numOfDataDirs;
    configCapacity=namesystem.getCapacityTotal();
    used=namesystem.getCapacityUsed();
    nonDFSUsed=namesystem.getNonDfsUsedSpace();
    remaining=namesystem.getCapacityRemaining();
    percentUsed=namesystem.getPercentUsed();
    percentRemaining=namesystem.getPercentRemaining();
    bpUsed=namesystem.getBlockPoolUsedSpace();
    percentBpUsed=namesystem.getPercentBlockPoolUsed();
    LOG.info("Data node directory " + cluster.getDataDirectory());
    LOG.info("Name node diskCapacity " + diskCapacity + " configCapacity "+ configCapacity+ " reserved "+ reserved+ " used "+ used+ " remaining "+ remaining+ " nonDFSUsed "+ nonDFSUsed+ " remaining "+ remaining+ " percentUsed "+ percentUsed+ " percentRemaining "+ percentRemaining+ " bpUsed "+ bpUsed+ " percentBpUsed "+ percentBpUsed);
    assertTrue(configCapacity == diskCapacity - reserved);
    assertTrue(configCapacity >= (used + remaining + nonDFSUsed));
    assertTrue(percentUsed == DFSUtilClient.getPercentUsed(used,configCapacity));
    assertTrue(percentBpUsed == DFSUtilClient.getPercentUsed(bpUsed,configCapacity));
    assertTrue(percentRemaining == ((float)remaining * 100.0f) / (float)configCapacity);
    final int fileCount=5;
    final DistributedFileSystem fs=cluster.getFileSystem();
    DFSOutputStream[] streams=new DFSOutputStream[fileCount];
    for (int i=0; i < fileCount; i++) {
      streams[i]=(DFSOutputStream)fs.create(new Path("/f" + i)).getWrappedStream();
      streams[i].write("1".getBytes());
      streams[i].hsync();
    }
    triggerHeartbeats(cluster.getDataNodes());
    assertTrue(configCapacity > (namesystem.getCapacityUsed() + namesystem.getCapacityRemaining() + namesystem.getNonDfsUsedSpace()));
    assertTrue((namesystem.getCapacityUsed() + namesystem.getCapacityRemaining() + namesystem.getNonDfsUsedSpace()+ fileCount * fs.getDefaultBlockSize()) - configCapacity < 1 * 1024);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
