{
  JobConf conf=new JobConf();
  CompressionEmulationUtil.setCompressionEmulationEnabled(conf,true);
  CompressionEmulationUtil.setInputCompressionEmulationEnabled(conf,true);
  FileSystem lfs=FileSystem.getLocal(conf);
  int dataSize=1024 * 1024 * 10;
  float ratio=0.357F;
  Path rootTempDir=new Path(System.getProperty("test.build.data","/tmp")).makeQualified(lfs.getUri(),lfs.getWorkingDirectory());
  Path tempDir=new Path(rootTempDir,"TestPossiblyCompressibleGridmixRecord");
  lfs.delete(tempDir,true);
  GridmixRecord record=new GridmixRecord(dataSize,0);
  record.setCompressibility(true,ratio);
  conf.setClass(FileOutputFormat.COMPRESS_CODEC,GzipCodec.class,CompressionCodec.class);
  org.apache.hadoop.mapred.FileOutputFormat.setCompressOutput(conf,true);
  Path recordFile=new Path(tempDir,"record");
  OutputStream outStream=CompressionEmulationUtil.getPossiblyCompressedOutputStream(recordFile,conf);
  DataOutputStream out=new DataOutputStream(outStream);
  record.write(out);
  out.close();
  outStream.close();
  Path actualRecordFile=recordFile.suffix(".gz");
  InputStream in=CompressionEmulationUtil.getPossiblyDecompressedInputStream(actualRecordFile,conf,0);
  long compressedFileSize=lfs.listStatus(actualRecordFile)[0].getLen();
  GridmixRecord recordRead=new GridmixRecord();
  recordRead.readFields(new DataInputStream(in));
  assertEquals("Record size mismatch in a compressible GridmixRecord",dataSize,recordRead.getSize());
  assertTrue("Failed to generate a compressible GridmixRecord",recordRead.getSize() > compressedFileSize);
  float seenRatio=((float)compressedFileSize) / dataSize;
  assertEquals(CompressionEmulationUtil.standardizeCompressionRatio(ratio),CompressionEmulationUtil.standardizeCompressionRatio(seenRatio),1.0D);
}
