{
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=null;
  FileSystem fileSys=null;
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  final FSEditLog editLog=fsimage.getEditLog();
  fileSys.mkdirs(new Path("/tmp"));
  Iterator<StorageDirectory> iter=fsimage.getStorage().dirIterator(NameNodeDirType.EDITS);
  LinkedList<StorageDirectory> sds=new LinkedList<StorageDirectory>();
  while (iter.hasNext()) {
    sds.add(iter.next());
  }
  editLog.close();
  cluster.shutdown();
  for (  StorageDirectory sd : sds) {
    File editFile=NNStorage.getFinalizedEditsFile(sd,1,3);
    assertTrue(editFile.exists());
    long fileLen=editFile.length();
    LOG.debug("Corrupting Log File: " + editFile + " len: "+ fileLen);
    RandomAccessFile rwf=new RandomAccessFile(editFile,"rw");
    rwf.seek(fileLen - 4);
    int b=rwf.readInt();
    rwf.seek(fileLen - 4);
    rwf.writeInt(b + 1);
    rwf.close();
  }
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).format(false).build();
    fail("should not be able to start");
  }
 catch (  IOException e) {
    assertEquals("Cause of exception should be ChecksumException",ChecksumException.class,e.getCause().getClass());
  }
}
