{
  Configuration conf=new Configuration();
  conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY,1000);
  conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY,1);
  conf.setInt(HdfsClientConfigKeys.DFS_CLIENT_SOCKET_TIMEOUT_KEY,3000);
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(4).build();
  DistributedFileSystem fileSystem=null;
  try {
    fileSystem=cluster.getFileSystem();
    Path f=new Path("/testAppend");
    FSDataOutputStream create=fileSystem.create(f,(short)2);
    create.write("/testAppend".getBytes());
    create.close();
    DFSTestUtil.waitReplication(fileSystem,f,(short)2);
    LocatedBlocks lbs=fileSystem.dfs.getNamenode().getBlockLocations("/testAppend",0,Long.MAX_VALUE);
    List<DataNode> dnsOfCluster=cluster.getDataNodes();
    DatanodeInfo[] dnsWithLocations=lbs.getLastLocatedBlock().getLocations();
    for (    DataNode dn : dnsOfCluster) {
      for (      DatanodeInfo loc : dnsWithLocations) {
        if (dn.getDatanodeId().equals(loc)) {
          dn.shutdown();
          DFSTestUtil.waitForDatanodeDeath(dn);
        }
      }
    }
    DFSTestUtil.waitReplication(fileSystem,f,(short)0);
    try {
      fileSystem.append(f);
      fail("Append should fail because insufficient locations");
    }
 catch (    IOException e) {
      LOG.info("Expected exception: ",e);
    }
    FSDirectory dir=cluster.getNamesystem().getFSDirectory();
    final INodeFile inode=INodeFile.valueOf(dir.getINode("/testAppend"),"/testAppend");
    assertTrue("File should remain closed",!inode.isUnderConstruction());
  }
  finally {
    if (null != fileSystem) {
      fileSystem.close();
    }
    cluster.shutdown();
  }
}
