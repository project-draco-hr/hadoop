{
  final PathPolicyMap pathPolicyMap=new PathPolicyMap(0);
  final NamespaceScheme nsScheme=pathPolicyMap.newNamespaceScheme();
  final long diskCapacity=(3 + HdfsConstants.MIN_BLOCKS_FOR_WRITE) * BLOCK_SIZE;
  final long archiveCapacity=100 * BLOCK_SIZE;
  final long[][] capacities=genCapacities(NUM_DATANODES,1,1,diskCapacity,archiveCapacity);
  final ClusterScheme clusterScheme=new ClusterScheme(DEFAULT_CONF,NUM_DATANODES,REPL,genStorageTypes(NUM_DATANODES,1,1),capacities);
  final MigrationTest test=new MigrationTest(clusterScheme,nsScheme);
  test.runBasicTest(false);
  final short replication=3;
{
    int hotFileCount=0;
    try {
      for (; ; hotFileCount++) {
        final Path p=new Path(pathPolicyMap.hot,"file" + hotFileCount);
        DFSTestUtil.createFile(test.dfs,p,BLOCK_SIZE,replication,0L);
      }
    }
 catch (    IOException e) {
      LOG.info("Expected: hotFileCount=" + hotFileCount,e);
    }
    Assert.assertTrue(hotFileCount >= 2);
  }
{
    int hotFileCount_r1=0;
    try {
      for (; ; hotFileCount_r1++) {
        final Path p=new Path(pathPolicyMap.hot,"file_r1_" + hotFileCount_r1);
        DFSTestUtil.createFile(test.dfs,p,BLOCK_SIZE,(short)1,0L);
      }
    }
 catch (    IOException e) {
      LOG.info("Expected: hotFileCount_r1=" + hotFileCount_r1,e);
    }
  }
{
    final Path file0=new Path(pathPolicyMap.hot,"file0");
    final Replication r=test.getReplication(file0);
    LOG.info("XXX " + file0 + ": replication="+ r);
    final short newReplication=(short)5;
    test.dfs.setReplication(file0,newReplication);
    Thread.sleep(10000);
    test.verifyReplication(file0,r.disk,newReplication - r.disk);
  }
{
    final Path p=new Path(pathPolicyMap.cold,"foo");
    DFSTestUtil.createFile(test.dfs,p,BLOCK_SIZE,replication,0L);
    test.verifyReplication(p,0,replication);
    final short newReplication=5;
    test.dfs.setReplication(p,newReplication);
    Thread.sleep(10000);
    test.verifyReplication(p,0,newReplication);
  }
{
  }
  test.shutdownCluster();
}
