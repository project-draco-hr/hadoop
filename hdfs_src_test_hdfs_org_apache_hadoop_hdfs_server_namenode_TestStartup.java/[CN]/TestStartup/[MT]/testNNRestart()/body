{
  MiniDFSCluster cluster=null;
  FileSystem localFileSys;
  Path hostsFile;
  Path excludeFile;
  Configuration conf=new HdfsConfiguration();
  int HEARTBEAT_INTERVAL=1;
  localFileSys=FileSystem.getLocal(conf);
  Path workingDir=localFileSys.getWorkingDirectory();
  Path dir=new Path(workingDir,"build/test/data/work-dir/restartnn");
  hostsFile=new Path(dir,"hosts");
  excludeFile=new Path(dir,"exclude");
  conf.set(DFSConfigKeys.DFS_HOSTS_EXCLUDE,excludeFile.toUri().getPath());
  writeConfigFile(localFileSys,excludeFile,null);
  conf.set(DFSConfigKeys.DFS_HOSTS,hostsFile.toUri().getPath());
  ArrayList<String> list=new ArrayList<String>();
  byte b[]={127,0,0,1};
  InetAddress inetAddress=InetAddress.getByAddress(b);
  list.add(inetAddress.getHostName());
  writeConfigFile(localFileSys,hostsFile,list);
  int numNameNodes=1;
  int numDatanodes=1;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numNameNodes(numNameNodes).numDataNodes(numDatanodes).setupHostsFile(true).build();
    cluster.waitActive();
    cluster.restartNameNode();
    NameNode nn=cluster.getNameNode();
    assertNotNull(nn);
    Assert.assertTrue(cluster.isDataNodeUp());
    DatanodeInfo[] info=nn.getDatanodeReport(DatanodeReportType.LIVE);
    for (int i=0; i < 5 && info.length != numDatanodes; i++) {
      Thread.sleep(HEARTBEAT_INTERVAL * 1000);
      info=nn.getDatanodeReport(DatanodeReportType.LIVE);
    }
    assertEquals("Number of live nodes should be " + numDatanodes,numDatanodes,info.length);
  }
 catch (  IOException e) {
    fail(StringUtils.stringifyException(e));
    throw e;
  }
 finally {
    cleanupFile(localFileSys,excludeFile.getParent());
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
