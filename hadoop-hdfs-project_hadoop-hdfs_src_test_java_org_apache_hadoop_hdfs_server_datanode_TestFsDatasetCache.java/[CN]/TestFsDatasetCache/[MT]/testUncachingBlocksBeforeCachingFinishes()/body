{
  LOG.info("beginning testUncachingBlocksBeforeCachingFinishes");
  final int NUM_BLOCKS=5;
  verifyExpectedCacheUsage(0);
  final Path testFile=new Path("/testCacheBlock");
  final long testFileLen=BLOCK_SIZE * NUM_BLOCKS;
  DFSTestUtil.createFile(fs,testFile,testFileLen,(short)1,0xABBAl);
  HdfsBlockLocation[] locs=(HdfsBlockLocation[])fs.getFileBlockLocations(testFile,0,testFileLen);
  assertEquals("Unexpected number of blocks",NUM_BLOCKS,locs.length);
  final long[] blockSizes=getBlockSizes(locs);
  final long cacheCapacity=fsd.getCacheCapacity();
  long cacheUsed=fsd.getCacheUsed();
  long current=0;
  assertEquals("Unexpected cache capacity",CACHE_CAPACITY,cacheCapacity);
  assertEquals("Unexpected amount of cache used",current,cacheUsed);
  NativeIO.POSIX.cacheManipulator=new NativeIO.POSIX.CacheManipulator(){
    @Override public void mlock(    String identifier,    ByteBuffer mmap,    long length) throws IOException {
      LOG.info("An mlock operation is starting on " + identifier);
      try {
        Thread.sleep(3000);
      }
 catch (      InterruptedException e) {
        Assert.fail();
      }
    }
  }
;
  for (int i=0; i < NUM_BLOCKS; i++) {
    setHeartbeatResponse(cacheBlock(locs[i]));
    current=verifyExpectedCacheUsage(current + blockSizes[i]);
  }
  setHeartbeatResponse(new DatanodeCommand[]{getResponse(locs,DatanodeProtocol.DNA_UNCACHE)});
  current=verifyExpectedCacheUsage(0);
  LOG.info("finishing testUncachingBlocksBeforeCachingFinishes");
}
