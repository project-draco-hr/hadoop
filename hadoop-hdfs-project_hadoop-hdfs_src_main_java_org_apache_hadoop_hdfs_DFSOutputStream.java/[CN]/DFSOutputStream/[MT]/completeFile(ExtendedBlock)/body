{
  long localstart=Time.now();
  long localTimeout=400;
  boolean fileComplete=false;
  int retries=dfsClient.getConf().nBlockWriteLocateFollowingRetry;
  while (!fileComplete) {
    fileComplete=dfsClient.namenode.complete(src,dfsClient.clientName,last,fileId);
    if (!fileComplete) {
      final int hdfsTimeout=dfsClient.getHdfsTimeout();
      if (!dfsClient.clientRunning || (hdfsTimeout > 0 && localstart + hdfsTimeout < Time.now())) {
        String msg="Unable to close file because dfsclient " + " was unable to contact the HDFS servers." + " clientRunning " + dfsClient.clientRunning + " hdfsTimeout "+ hdfsTimeout;
        DFSClient.LOG.info(msg);
        throw new IOException(msg);
      }
      try {
        if (retries == 0) {
          throw new IOException("Unable to close file because the last block" + " does not have enough number of replicas.");
        }
        retries--;
        Thread.sleep(localTimeout);
        localTimeout*=2;
        if (Time.now() - localstart > 5000) {
          DFSClient.LOG.info("Could not complete " + src + " retrying...");
        }
      }
 catch (      InterruptedException ie) {
        DFSClient.LOG.warn("Caught exception ",ie);
      }
    }
  }
}
