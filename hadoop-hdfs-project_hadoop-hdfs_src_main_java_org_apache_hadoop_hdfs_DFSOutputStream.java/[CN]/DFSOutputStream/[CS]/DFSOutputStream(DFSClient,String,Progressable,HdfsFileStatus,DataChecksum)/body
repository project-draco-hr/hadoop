{
  super(getChecksum4Compute(checksum,stat));
  this.dfsClient=dfsClient;
  this.src=src;
  this.fileId=stat.getFileId();
  this.blockSize=stat.getBlockSize();
  this.blockReplication=stat.getReplication();
  this.fileEncryptionInfo=stat.getFileEncryptionInfo();
  this.progress=progress;
  this.cachingStrategy=new AtomicReference<CachingStrategy>(dfsClient.getDefaultWriteCachingStrategy());
  if ((progress != null) && DFSClient.LOG.isDebugEnabled()) {
    DFSClient.LOG.debug("Set non-null progress callback on DFSOutputStream " + src);
  }
  this.bytesPerChecksum=checksum.getBytesPerChecksum();
  if (bytesPerChecksum <= 0) {
    throw new HadoopIllegalArgumentException("Invalid value: bytesPerChecksum = " + bytesPerChecksum + " <= 0");
  }
  if (blockSize % bytesPerChecksum != 0) {
    throw new HadoopIllegalArgumentException("Invalid values: " + DFSConfigKeys.DFS_BYTES_PER_CHECKSUM_KEY + " (="+ bytesPerChecksum+ ") must divide block size (="+ blockSize+ ").");
  }
  this.checksum4WriteBlock=checksum;
  this.dfsclientSlowLogThresholdMs=dfsClient.getConf().dfsclientSlowIoWarningThresholdMs;
}
