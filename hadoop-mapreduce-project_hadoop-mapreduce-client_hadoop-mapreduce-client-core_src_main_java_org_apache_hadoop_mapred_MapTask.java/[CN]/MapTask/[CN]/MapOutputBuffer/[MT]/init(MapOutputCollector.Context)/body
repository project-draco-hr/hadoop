{
  job=context.getJobConf();
  reporter=context.getReporter();
  mapTask=context.getMapTask();
  mapOutputFile=mapTask.getMapOutputFile();
  sortPhase=mapTask.getSortPhase();
  spilledRecordsCounter=reporter.getCounter(TaskCounter.SPILLED_RECORDS);
  partitions=job.getNumReduceTasks();
  rfs=((LocalFileSystem)FileSystem.getLocal(job)).getRaw();
  final float spillper=job.getFloat(JobContext.MAP_SORT_SPILL_PERCENT,(float)0.8);
  final int sortmb=job.getInt(JobContext.IO_SORT_MB,100);
  indexCacheMemoryLimit=job.getInt(JobContext.INDEX_CACHE_MEMORY_LIMIT,INDEX_CACHE_MEMORY_LIMIT_DEFAULT);
  if (spillper > (float)1.0 || spillper <= (float)0.0) {
    throw new IOException("Invalid \"" + JobContext.MAP_SORT_SPILL_PERCENT + "\": "+ spillper);
  }
  if ((sortmb & 0x7FF) != sortmb) {
    throw new IOException("Invalid \"" + JobContext.IO_SORT_MB + "\": "+ sortmb);
  }
  sorter=ReflectionUtils.newInstance(job.getClass(MRJobConfig.MAP_SORT_CLASS,QuickSort.class,IndexedSorter.class),job);
  int maxMemUsage=sortmb << 20;
  maxMemUsage-=maxMemUsage % METASIZE;
  kvbuffer=new byte[maxMemUsage];
  bufvoid=kvbuffer.length;
  kvmeta=ByteBuffer.wrap(kvbuffer).order(ByteOrder.nativeOrder()).asIntBuffer();
  setEquator(0);
  bufstart=bufend=bufindex=equator;
  kvstart=kvend=kvindex;
  maxRec=kvmeta.capacity() / NMETA;
  softLimit=(int)(kvbuffer.length * spillper);
  bufferRemaining=softLimit;
  LOG.info(JobContext.IO_SORT_MB + ": " + sortmb);
  LOG.info("soft limit at " + softLimit);
  LOG.info("bufstart = " + bufstart + "; bufvoid = "+ bufvoid);
  LOG.info("kvstart = " + kvstart + "; length = "+ maxRec);
  comparator=job.getOutputKeyComparator();
  keyClass=(Class<K>)job.getMapOutputKeyClass();
  valClass=(Class<V>)job.getMapOutputValueClass();
  serializationFactory=new SerializationFactory(job);
  keySerializer=serializationFactory.getSerializer(keyClass);
  keySerializer.open(bb);
  valSerializer=serializationFactory.getSerializer(valClass);
  valSerializer.open(bb);
  mapOutputByteCounter=reporter.getCounter(TaskCounter.MAP_OUTPUT_BYTES);
  mapOutputRecordCounter=reporter.getCounter(TaskCounter.MAP_OUTPUT_RECORDS);
  fileOutputByteCounter=reporter.getCounter(TaskCounter.MAP_OUTPUT_MATERIALIZED_BYTES);
  if (job.getCompressMapOutput()) {
    Class<? extends CompressionCodec> codecClass=job.getMapOutputCompressorClass(DefaultCodec.class);
    codec=ReflectionUtils.newInstance(codecClass,job);
  }
 else {
    codec=null;
  }
  final Counters.Counter combineInputCounter=reporter.getCounter(TaskCounter.COMBINE_INPUT_RECORDS);
  combinerRunner=CombinerRunner.create(job,getTaskID(),combineInputCounter,reporter,null);
  if (combinerRunner != null) {
    final Counters.Counter combineOutputCounter=reporter.getCounter(TaskCounter.COMBINE_OUTPUT_RECORDS);
    combineCollector=new CombineOutputCollector<K,V>(combineOutputCounter,reporter,job);
  }
 else {
    combineCollector=null;
  }
  spillInProgress=false;
  minSpillsForCombine=job.getInt(JobContext.MAP_COMBINE_MIN_SPILLS,3);
  spillThread.setDaemon(true);
  spillThread.setName("SpillThread");
  spillLock.lock();
  try {
    spillThread.start();
    while (!spillThreadRunning) {
      spillDone.await();
    }
  }
 catch (  InterruptedException e) {
    throw new IOException("Spill thread failed to initialize",e);
  }
 finally {
    spillLock.unlock();
  }
  if (sortSpillException != null) {
    throw new IOException("Spill thread failed to initialize",sortSpillException);
  }
}
