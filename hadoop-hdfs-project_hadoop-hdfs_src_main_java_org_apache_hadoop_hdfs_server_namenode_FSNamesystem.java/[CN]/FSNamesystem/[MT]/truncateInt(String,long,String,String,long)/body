{
  String src=srcArg;
  NameNode.stateChangeLog.debug("DIR* NameSystem.truncate: src={} newLength={}",src,newLength);
  if (newLength < 0) {
    throw new HadoopIllegalArgumentException("Cannot truncate to a negative file size: " + newLength + ".");
  }
  HdfsFileStatus stat=null;
  FSPermissionChecker pc=getPermissionChecker();
  checkOperation(OperationCategory.WRITE);
  boolean res;
  byte[][] pathComponents=FSDirectory.getPathComponentsForReservedPath(src);
  writeLock();
  BlocksMapUpdateInfo toRemoveBlocks=new BlocksMapUpdateInfo();
  try {
    checkOperation(OperationCategory.WRITE);
    checkNameNodeSafeMode("Cannot truncate for " + src);
    src=dir.resolvePath(pc,src,pathComponents);
    res=truncateInternal(src,newLength,clientName,clientMachine,mtime,pc,toRemoveBlocks);
    stat=dir.getAuditFileInfo(dir.getINodesInPath4Write(src,false));
  }
  finally {
    writeUnlock();
  }
  getEditLog().logSync();
  if (!toRemoveBlocks.getToDeleteList().isEmpty()) {
    removeBlocks(toRemoveBlocks);
    toRemoveBlocks.clear();
  }
  logAuditEvent(true,"truncate",src,null,stat);
  return res;
}
