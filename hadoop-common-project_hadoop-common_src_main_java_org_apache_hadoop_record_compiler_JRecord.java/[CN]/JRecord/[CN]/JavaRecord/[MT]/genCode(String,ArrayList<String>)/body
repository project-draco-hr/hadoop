{
  String pkg=module;
  String pkgpath=pkg.replaceAll("\\.","/");
  File pkgdir=new File(destDir,pkgpath);
  final File jfile=new File(pkgdir,name + ".java");
  if (!pkgdir.exists()) {
    boolean ret=pkgdir.mkdirs();
    if (!ret) {
      throw new IOException("Cannnot create directory: " + pkgpath);
    }
  }
 else   if (!pkgdir.isDirectory()) {
    throw new IOException(pkgpath + " is not a directory.");
  }
  CodeBuffer cb=new CodeBuffer();
  cb.append("// File generated by hadoop record compiler. Do not edit.\n");
  cb.append("package " + module + ";\n\n");
  cb.append("public class " + name + " extends org.apache.hadoop.record.Record {\n");
  cb.append("private static final " + "org.apache.hadoop.record.meta.RecordTypeInfo " + Consts.RTI_VAR + ";\n");
  cb.append("private static " + "org.apache.hadoop.record.meta.RecordTypeInfo " + Consts.RTI_FILTER + ";\n");
  cb.append("private static int[] " + Consts.RTI_FILTER_FIELDS + ";\n");
  cb.append("static {\n");
  cb.append(Consts.RTI_VAR + " = " + "new org.apache.hadoop.record.meta.RecordTypeInfo(\""+ name+ "\");\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genStaticTypeInfo(cb,name);
  }
  cb.append("}\n\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genDecl(cb,name);
  }
  cb.append("public " + name + "() { }\n");
  cb.append("public " + name + "(\n");
  int fIdx=0;
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); fIdx++) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genConstructorParam(cb,name);
    cb.append((!i.hasNext()) ? "" : ",\n");
  }
  cb.append(") {\n");
  fIdx=0;
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); fIdx++) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genConstructorSet(cb,name);
  }
  cb.append("}\n");
  cb.append("public static org.apache.hadoop.record.meta.RecordTypeInfo" + " getTypeInfo() {\n");
  cb.append("return " + Consts.RTI_VAR + ";\n");
  cb.append("}\n");
  cb.append("public static void setTypeFilter(" + "org.apache.hadoop.record.meta.RecordTypeInfo rti) {\n");
  cb.append("if (null == rti) return;\n");
  cb.append(Consts.RTI_FILTER + " = rti;\n");
  cb.append(Consts.RTI_FILTER_FIELDS + " = null;\n");
  Map<String,Integer> nestedStructMap=new HashMap<String,Integer>();
  for (  JField<JavaType> jf : fields) {
    JavaType type=jf.getType();
    type.genSetRTIFilter(cb,nestedStructMap);
  }
  cb.append("}\n");
  genSetupRtiFields(cb);
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genGetSet(cb,name);
  }
  cb.append("public void serialize(" + "final org.apache.hadoop.record.RecordOutput " + Consts.RECORD_OUTPUT + ", final String "+ Consts.TAG+ ")\n"+ "throws java.io.IOException {\n");
  cb.append(Consts.RECORD_OUTPUT + ".startRecord(this," + Consts.TAG+ ");\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genWriteMethod(cb,name,name);
  }
  cb.append(Consts.RECORD_OUTPUT + ".endRecord(this," + Consts.TAG+ ");\n");
  cb.append("}\n");
  cb.append("private void deserializeWithoutFilter(" + "final org.apache.hadoop.record.RecordInput " + Consts.RECORD_INPUT + ", final String "+ Consts.TAG+ ")\n"+ "throws java.io.IOException {\n");
  cb.append(Consts.RECORD_INPUT + ".startRecord(" + Consts.TAG+ ");\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genReadMethod(cb,name,name,false);
  }
  cb.append(Consts.RECORD_INPUT + ".endRecord(" + Consts.TAG+ ");\n");
  cb.append("}\n");
  cb.append("public void deserialize(final " + "org.apache.hadoop.record.RecordInput " + Consts.RECORD_INPUT + ", final String "+ Consts.TAG+ ")\n"+ "throws java.io.IOException {\n");
  cb.append("if (null == " + Consts.RTI_FILTER + ") {\n");
  cb.append("deserializeWithoutFilter(" + Consts.RECORD_INPUT + ", "+ Consts.TAG+ ");\n");
  cb.append("return;\n");
  cb.append("}\n");
  cb.append("// if we're here, we need to read based on version info\n");
  cb.append(Consts.RECORD_INPUT + ".startRecord(" + Consts.TAG+ ");\n");
  cb.append("setupRtiFields();\n");
  cb.append("for (int " + Consts.RIO_PREFIX + "i=0; "+ Consts.RIO_PREFIX+ "i<"+ Consts.RTI_FILTER+ ".getFieldTypeInfos().size(); "+ Consts.RIO_PREFIX+ "i++) {\n");
  int ct=0;
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    ct++;
    if (1 != ct) {
      cb.append("else ");
    }
    cb.append("if (" + ct + " == "+ Consts.RTI_FILTER_FIELDS+ "["+ Consts.RIO_PREFIX+ "i]) {\n");
    type.genReadMethod(cb,name,name,false);
    cb.append("}\n");
  }
  if (0 != ct) {
    cb.append("else {\n");
    cb.append("java.util.ArrayList<" + "org.apache.hadoop.record.meta.FieldTypeInfo> typeInfos = " + "(java.util.ArrayList<"+ "org.apache.hadoop.record.meta.FieldTypeInfo>)"+ "(" + Consts.RTI_FILTER + ".getFieldTypeInfos());\n");
    cb.append("org.apache.hadoop.record.meta.Utils.skip(" + Consts.RECORD_INPUT + ", "+ "typeInfos.get("+ Consts.RIO_PREFIX+ "i).getFieldID(), typeInfos.get("+ Consts.RIO_PREFIX+ "i).getTypeID());\n");
    cb.append("}\n");
  }
  cb.append("}\n");
  cb.append(Consts.RECORD_INPUT + ".endRecord(" + Consts.TAG+ ");\n");
  cb.append("}\n");
  cb.append("public int compareTo (final Object " + Consts.RIO_PREFIX + "peer_) throws ClassCastException {\n");
  cb.append("if (!(" + Consts.RIO_PREFIX + "peer_ instanceof "+ name+ ")) {\n");
  cb.append("throw new ClassCastException(\"Comparing different types of records.\");\n");
  cb.append("}\n");
  cb.append(name + " " + Consts.RIO_PREFIX+ "peer = ("+ name+ ") "+ Consts.RIO_PREFIX+ "peer_;\n");
  cb.append("int " + Consts.RIO_PREFIX + "ret = 0;\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genCompareTo(cb,name,Consts.RIO_PREFIX + "peer." + name);
    cb.append("if (" + Consts.RIO_PREFIX + "ret != 0) return "+ Consts.RIO_PREFIX+ "ret;\n");
  }
  cb.append("return " + Consts.RIO_PREFIX + "ret;\n");
  cb.append("}\n");
  cb.append("public boolean equals(final Object " + Consts.RIO_PREFIX + "peer_) {\n");
  cb.append("if (!(" + Consts.RIO_PREFIX + "peer_ instanceof "+ name+ ")) {\n");
  cb.append("return false;\n");
  cb.append("}\n");
  cb.append("if (" + Consts.RIO_PREFIX + "peer_ == this) {\n");
  cb.append("return true;\n");
  cb.append("}\n");
  cb.append(name + " " + Consts.RIO_PREFIX+ "peer = ("+ name+ ") "+ Consts.RIO_PREFIX+ "peer_;\n");
  cb.append("boolean " + Consts.RIO_PREFIX + "ret = false;\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genEquals(cb,name,Consts.RIO_PREFIX + "peer." + name);
    cb.append("if (!" + Consts.RIO_PREFIX + "ret) return "+ Consts.RIO_PREFIX+ "ret;\n");
  }
  cb.append("return " + Consts.RIO_PREFIX + "ret;\n");
  cb.append("}\n");
  cb.append("public Object clone() throws CloneNotSupportedException {\n");
  cb.append(name + " " + Consts.RIO_PREFIX+ "other = new "+ name+ "();\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genClone(cb,name);
  }
  cb.append("return " + Consts.RIO_PREFIX + "other;\n");
  cb.append("}\n");
  cb.append("public int hashCode() {\n");
  cb.append("int " + Consts.RIO_PREFIX + "result = 17;\n");
  cb.append("int " + Consts.RIO_PREFIX + "ret;\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genHashCode(cb,name);
    cb.append(Consts.RIO_PREFIX + "result = 37*" + Consts.RIO_PREFIX+ "result + "+ Consts.RIO_PREFIX+ "ret;\n");
  }
  cb.append("return " + Consts.RIO_PREFIX + "result;\n");
  cb.append("}\n");
  cb.append("public static String signature() {\n");
  cb.append("return \"" + getSignature() + "\";\n");
  cb.append("}\n");
  cb.append("public static class Comparator extends" + " org.apache.hadoop.record.RecordComparator {\n");
  cb.append("public Comparator() {\n");
  cb.append("super(" + name + ".class);\n");
  cb.append("}\n");
  cb.append("static public int slurpRaw(byte[] b, int s, int l) {\n");
  cb.append("try {\n");
  cb.append("int os = s;\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genSlurpBytes(cb,"b","s","l");
  }
  cb.append("return (os - s);\n");
  cb.append("} catch(java.io.IOException e) {\n");
  cb.append("throw new RuntimeException(e);\n");
  cb.append("}\n");
  cb.append("}\n");
  cb.append("static public int compareRaw(byte[] b1, int s1, int l1,\n");
  cb.append("                             byte[] b2, int s2, int l2) {\n");
  cb.append("try {\n");
  cb.append("int os1 = s1;\n");
  for (Iterator<JField<JavaType>> i=fields.iterator(); i.hasNext(); ) {
    JField<JavaType> jf=i.next();
    String name=jf.getName();
    JavaType type=jf.getType();
    type.genCompareBytes(cb);
  }
  cb.append("return (os1 - s1);\n");
  cb.append("} catch(java.io.IOException e) {\n");
  cb.append("throw new RuntimeException(e);\n");
  cb.append("}\n");
  cb.append("}\n");
  cb.append("public int compare(byte[] b1, int s1, int l1,\n");
  cb.append("                   byte[] b2, int s2, int l2) {\n");
  cb.append("int ret = compareRaw(b1,s1,l1,b2,s2,l2);\n");
  cb.append("return (ret == -1)? -1 : ((ret==0)? 1 : 0);");
  cb.append("}\n");
  cb.append("}\n\n");
  cb.append("static {\n");
  cb.append("org.apache.hadoop.record.RecordComparator.define(" + name + ".class, new Comparator());\n");
  cb.append("}\n");
  cb.append("}\n");
  FileWriter jj=new FileWriter(jfile);
  try {
    jj.write(cb.toString());
  }
  finally {
    jj.close();
  }
}
