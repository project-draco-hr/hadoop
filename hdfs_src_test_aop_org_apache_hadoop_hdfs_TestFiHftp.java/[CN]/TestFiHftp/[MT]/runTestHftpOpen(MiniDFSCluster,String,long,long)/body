{
  final DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
  final Path filepath=new Path(file);
  final byte[] filemd5=createFile(dfs,filepath,filesize,DATANODE_NUM,blocksize);
  DFSTestUtil.waitReplication(dfs,filepath,DATANODE_NUM);
  final HftpFileSystem hftpfs=cluster.getHftpFileSystem(0);
{
    final FSDataInputStream in=hftpfs.open(filepath);
    long bytesRead=0;
    try {
      for (int r; (r=in.read(buffer)) != -1; ) {
        bytesRead+=r;
        md5.update(buffer,0,r);
      }
    }
  finally {
      LOG.info("bytesRead=" + bytesRead);
      in.close();
    }
    Assert.assertEquals(filesize,bytesRead);
    Assert.assertArrayEquals(filemd5,md5.digest());
  }
  final DFSClient client=dfs.getClient();
  final LocatedBlocks locatedblocks=client.getNamenode().getBlockLocations(file,0,filesize);
  Assert.assertEquals((filesize - 1) / blocksize + 1,locatedblocks.locatedBlockCount());
  final LocatedBlock lb=locatedblocks.get(1);
  final ExtendedBlock blk=lb.getBlock();
  Assert.assertEquals(blocksize,lb.getBlockSize());
  final DatanodeInfo[] datanodeinfos=lb.getLocations();
  Assert.assertEquals(DATANODE_NUM,datanodeinfos.length);
  final DataNode dn=cluster.getDataNode(datanodeinfos[0].getIpcPort());
  LOG.info("dn=" + dn + ", blk="+ blk+ " (length="+ blk.getNumBytes()+ ")");
  final FSDataset data=(FSDataset)dn.getFSDataset();
  final File blkfile=data.getBlockFile(blk);
  Assert.assertTrue(blkfile.delete());
  LOG.info("hftpfs.getUri() = " + hftpfs.getUri());
  final ContentSummary cs=hftpfs.getContentSummary(filepath);
  LOG.info("hftpfs.getContentSummary = " + cs);
  Assert.assertEquals(filesize,cs.getLength());
  final FSDataInputStream in=hftpfs.open(hftpfs.makeQualified(filepath));
  long bytesRead=0;
  try {
    for (int r; (r=in.read(buffer)) != -1; ) {
      bytesRead+=r;
    }
    Assert.fail();
  }
 catch (  IOException ioe) {
    LOG.info("GOOD: get an exception",ioe);
  }
 finally {
    LOG.info("bytesRead=" + bytesRead);
    in.close();
  }
}
