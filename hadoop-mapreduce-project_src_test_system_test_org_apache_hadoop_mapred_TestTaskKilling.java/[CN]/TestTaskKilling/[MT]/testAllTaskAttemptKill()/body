{
  Configuration conf=new Configuration(cluster.getConf());
  JobStatus[] jobStatus=null;
  SleepJob job=new SleepJob();
  job.setConf(conf);
  Job slpJob=job.createJob(3,1,40000,1000,100,100);
  JobConf jconf=new JobConf(conf);
  slpJob.submit();
  RunningJob rJob=cluster.getJTClient().getClient().getJob(org.apache.hadoop.mapred.JobID.downgrade(slpJob.getJobID()));
  int MAX_MAP_TASK_ATTEMPTS=Integer.parseInt(jconf.get(MRJobConfig.MAP_MAX_ATTEMPTS));
  LOG.info("MAX_MAP_TASK_ATTEMPTS is : " + MAX_MAP_TASK_ATTEMPTS);
  Assert.assertTrue(MAX_MAP_TASK_ATTEMPTS > 0);
  TTClient tClient=null;
  TTClient[] ttClients=null;
  JobInfo jInfo=remoteJTClient.getJobInfo(rJob.getID());
  Assert.assertNotNull(jInfo.getStatus().getRunState());
  while (jInfo.getStatus().getRunState() != JobStatus.RUNNING) {
    try {
      Thread.sleep(10000);
    }
 catch (    InterruptedException e) {
    }
    ;
    jInfo=remoteJTClient.getJobInfo(rJob.getID());
  }
  JobID jobidStore=rJob.getID();
  jobidStore=JobID.downgrade(jobidStore);
  LOG.info("job id is :" + jobidStore.toString());
  TaskInfo[] taskInfos=null;
  boolean runningCount=false;
  int count=0;
  do {
    taskInfos=cluster.getJTClient().getProxy().getTaskInfo(rJob.getID());
    runningCount=false;
    for (    TaskInfo taskInfo : taskInfos) {
      TaskStatus[] taskStatuses=taskInfo.getTaskStatus();
      if (taskStatuses.length > 0) {
        LOG.info("taskStatuses[0].getRunState() is :" + taskStatuses[0].getRunState());
        if (taskStatuses[0].getRunState() == TaskStatus.State.RUNNING) {
          runningCount=true;
          break;
        }
 else {
          LOG.info("Sleeping 5 seconds");
          Thread.sleep(5000);
        }
      }
    }
    count++;
    if (count > 10) {
      Assert.fail("Since the sleep count has reached beyond a point" + "failing at this point");
    }
  }
 while (!runningCount);
  String taskIdKilled=null;
  for (int i=0; i < MAX_MAP_TASK_ATTEMPTS; i++) {
    taskInfos=cluster.getJTClient().getProxy().getTaskInfo(rJob.getID());
    for (    TaskInfo taskInfo : taskInfos) {
      TaskAttemptID taskAttemptID;
      if (!taskInfo.isSetupOrCleanup()) {
        TaskID taskid=TaskID.downgrade(taskInfo.getTaskID());
        LOG.info("taskid is :" + taskid);
        if (i == 0) {
          taskIdKilled=taskid.toString();
          taskAttemptID=new TaskAttemptID(taskid,i);
          LOG.info("taskAttemptid going to be killed is : " + taskAttemptID);
          (new JobClient.NetworkedJob(jInfo.getStatus(),jobClient.cluster)).killTask(taskAttemptID,true);
          checkTaskCompletionEvent(taskAttemptID,jInfo);
          break;
        }
 else {
          if (taskIdKilled.equals(taskid.toString())) {
            taskAttemptID=new TaskAttemptID(taskid,i);
            LOG.info("taskAttemptid going to be killed is : " + taskAttemptID);
            (new JobClient.NetworkedJob(jInfo.getStatus(),jobClient.cluster)).killTask(taskAttemptID,true);
            checkTaskCompletionEvent(taskAttemptID,jInfo);
            break;
          }
        }
      }
    }
  }
  while (jInfo != null && !jInfo.getStatus().isJobComplete()) {
    Thread.sleep(10000);
    jInfo=remoteJTClient.getJobInfo(rJob.getID());
  }
  jobStatus=jobClient.getAllJobs();
  JobStatus jobStatusFound=null;
  for (  JobStatus jobStatusTmp : jobStatus) {
    if (JobID.downgrade(jobStatusTmp.getJobID()).equals(jobidStore)) {
      jobStatusFound=jobStatusTmp;
      LOG.info("jobStatus found is :" + jobStatusFound.getJobId().toString());
    }
  }
  Assert.assertEquals("The job should have failed at this stage",JobStatus.FAILED,jobStatusFound.getRunState());
}
