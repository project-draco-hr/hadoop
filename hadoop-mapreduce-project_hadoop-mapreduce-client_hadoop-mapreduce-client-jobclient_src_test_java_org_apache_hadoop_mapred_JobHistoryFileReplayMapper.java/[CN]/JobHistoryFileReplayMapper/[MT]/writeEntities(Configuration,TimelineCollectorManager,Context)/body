{
  Configuration conf=context.getConfiguration();
  int taskId=context.getTaskAttemptID().getTaskID().getId();
  int size=conf.getInt(MRJobConfig.NUM_MAPS,TimelineServicePerformanceV2.NUM_MAPS_DEFAULT);
  String processingDir=conf.get(JobHistoryFileReplayMapper.PROCESSING_PATH);
  int replayMode=conf.getInt(JobHistoryFileReplayMapper.REPLAY_MODE,JobHistoryFileReplayMapper.REPLAY_MODE_DEFAULT);
  Path processingPath=new Path(processingDir);
  FileSystem processingFs=processingPath.getFileSystem(conf);
  JobHistoryFileParser parser=new JobHistoryFileParser(processingFs);
  TimelineEntityConverter converter=new TimelineEntityConverter();
  Collection<JobFiles> jobs=selectJobFiles(processingFs,processingPath,taskId,size);
  if (jobs.isEmpty()) {
    LOG.info(context.getTaskAttemptID().getTaskID() + " will process no jobs");
  }
 else {
    LOG.info(context.getTaskAttemptID().getTaskID() + " will process " + jobs.size()+ " jobs");
  }
  for (  JobFiles job : jobs) {
    String jobIdStr=job.getJobId();
    LOG.info("processing " + jobIdStr + "...");
    JobId jobId=TypeConverter.toYarn(JobID.forName(jobIdStr));
    ApplicationId appId=jobId.getAppId();
    AppLevelTimelineCollector collector=new AppLevelTimelineCollector(appId);
    manager.putIfAbsent(appId,collector);
    try {
      JobInfo jobInfo=parser.parseHistoryFile(job.getJobHistoryFilePath());
      Configuration jobConf=parser.parseConfiguration(job.getJobConfFilePath());
      LOG.info("parsed the job history file and the configuration file for job" + jobIdStr);
      TimelineCollectorContext tlContext=collector.getTimelineEntityContext();
      tlContext.setFlowName(jobInfo.getJobname());
      tlContext.setFlowRunId(jobInfo.getSubmitTime());
      tlContext.setUserId(jobInfo.getUsername());
      long totalTime=0;
      Set<TimelineEntity> entitySet=converter.createTimelineEntities(jobInfo,jobConf);
      LOG.info("converted them into timeline entities for job " + jobIdStr);
      UserGroupInformation ugi=UserGroupInformation.getCurrentUser();
      long startWrite=System.nanoTime();
      try {
switch (replayMode) {
case JobHistoryFileReplayMapper.WRITE_ALL_AT_ONCE:
          writeAllEntities(collector,entitySet,ugi);
        break;
case JobHistoryFileReplayMapper.WRITE_PER_ENTITY:
      writePerEntity(collector,entitySet,ugi);
    break;
default :
  break;
}
}
 catch (Exception e) {
context.getCounter(PerfCounters.TIMELINE_SERVICE_WRITE_FAILURES).increment(1);
LOG.error("writing to the timeline service failed",e);
}
long endWrite=System.nanoTime();
totalTime+=TimeUnit.NANOSECONDS.toMillis(endWrite - startWrite);
int numEntities=entitySet.size();
LOG.info("wrote " + numEntities + " entities in "+ totalTime+ " ms");
context.getCounter(PerfCounters.TIMELINE_SERVICE_WRITE_TIME).increment(totalTime);
context.getCounter(PerfCounters.TIMELINE_SERVICE_WRITE_COUNTER).increment(numEntities);
}
  finally {
manager.remove(appId);
context.progress();
}
}
}
