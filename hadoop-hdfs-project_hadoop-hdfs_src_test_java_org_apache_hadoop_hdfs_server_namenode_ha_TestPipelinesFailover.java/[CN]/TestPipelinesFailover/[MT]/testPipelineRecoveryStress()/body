{
  String[] scmd=new String[]{"/bin/sh","-c","ulimit -a"};
  ShellCommandExecutor sce=new ShellCommandExecutor(scmd);
  sce.execute();
  System.out.println("HDFS-6694 Debug Data BEGIN===");
  System.out.println("'ulimit -a' output:\n" + sce.getOutput());
  scmd=new String[]{"hostname"};
  sce=new ShellCommandExecutor(scmd);
  sce.execute();
  System.out.println("'hostname' output:\n" + sce.getOutput());
  scmd=new String[]{"ifconfig"};
  sce=new ShellCommandExecutor(scmd);
  sce.execute();
  System.out.println("'ifconfig' output:\n" + sce.getOutput());
  scmd=new String[]{"whoami"};
  sce=new ShellCommandExecutor(scmd);
  sce.execute();
  System.out.println("'whoami' output:\n" + sce.getOutput());
  System.out.println("===HDFS-6694 Debug Data END");
  HAStressTestHarness harness=new HAStressTestHarness();
  harness.conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY,false);
  harness.conf.setInt(HdfsClientConfigKeys.Failover.SLEEPTIME_MAX_KEY,1000);
  final MiniDFSCluster cluster=harness.startCluster();
  try {
    cluster.waitActive();
    cluster.transitionToActive(0);
    FileSystem fs=harness.getFailoverFs();
    DistributedFileSystem fsAsOtherUser=createFsAsOtherUser(cluster,harness.conf);
    TestContext testers=new TestContext();
    for (int i=0; i < STRESS_NUM_THREADS; i++) {
      Path p=new Path("/test-" + i);
      testers.addThread(new PipelineTestThread(testers,fs,fsAsOtherUser,p));
    }
    harness.addReplicationTriggerThread(500);
    harness.addFailoverThread(5000);
    harness.startThreads();
    testers.startThreads();
    testers.waitFor(STRESS_RUNTIME);
    testers.stop();
    harness.stopThreads();
  }
  finally {
    System.err.println("===========================\n\n\n\n");
    harness.shutdown();
  }
}
