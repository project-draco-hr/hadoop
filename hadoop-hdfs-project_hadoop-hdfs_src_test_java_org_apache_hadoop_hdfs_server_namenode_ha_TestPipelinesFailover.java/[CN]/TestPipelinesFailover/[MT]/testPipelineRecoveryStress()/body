{
  LOG.info("HDFS-6694 Debug Data BEGIN");
  String[][] scmds=new String[][]{{"/bin/sh","-c","ulimit -a"},{"hostname"},{"ifconfig","-a"}};
  for (  String[] scmd : scmds) {
    String scmd_str=StringUtils.join(" ",scmd);
    try {
      ShellCommandExecutor sce=new ShellCommandExecutor(scmd);
      sce.execute();
      LOG.info("'" + scmd_str + "' output:\n"+ sce.getOutput());
    }
 catch (    IOException e) {
      LOG.warn("Error when running '" + scmd_str + "'",e);
    }
  }
  LOG.info("HDFS-6694 Debug Data END");
  HAStressTestHarness harness=new HAStressTestHarness();
  harness.conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY,false);
  harness.conf.setInt(HdfsClientConfigKeys.Failover.SLEEPTIME_MAX_KEY,1000);
  final MiniDFSCluster cluster=harness.startCluster();
  try {
    cluster.waitActive();
    cluster.transitionToActive(0);
    FileSystem fs=harness.getFailoverFs();
    DistributedFileSystem fsAsOtherUser=createFsAsOtherUser(cluster,harness.conf);
    TestContext testers=new TestContext();
    for (int i=0; i < STRESS_NUM_THREADS; i++) {
      Path p=new Path("/test-" + i);
      testers.addThread(new PipelineTestThread(testers,fs,fsAsOtherUser,p));
    }
    harness.addReplicationTriggerThread(500);
    harness.addFailoverThread(5000);
    harness.startThreads();
    testers.startThreads();
    testers.waitFor(STRESS_RUNTIME);
    testers.stop();
    harness.stopThreads();
  }
  finally {
    System.err.println("===========================\n\n\n\n");
    harness.shutdown();
  }
}
