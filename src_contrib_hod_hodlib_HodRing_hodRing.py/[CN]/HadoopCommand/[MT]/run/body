def run(self, dir):
    status = True
    args = []
    desc = self.desc
    self.log.debug(pprint.pformat(desc.dict))
    self.log.debug(('Got package dir of %s' % dir))
    self.path = os.path.join(dir, self.program)
    self.log.debug(('path: %s' % self.path))
    args.append(self.path)
    args.extend(desc.getArgv())
    envs = desc.getEnvs()
    fenvs = os.environ
    for (k, v) in envs.iteritems():
        fenvs[k] = v
    if envs.has_key('HADOOP_OPTS'):
        fenvs['HADOOP_OPTS'] = envs['HADOOP_OPTS']
        self.log.debug(('HADOOP_OPTS : %s' % fenvs['HADOOP_OPTS']))
    fenvs['JAVA_HOME'] = self.javahome
    fenvs['HADOOP_CONF_DIR'] = self.confdir
    fenvs['HADOOP_LOG_DIR'] = self.logdir
    self.log.info(pprint.pformat(fenvs))
    hadoopCommand = ''
    for item in args:
        hadoopCommand = ('%s%s ' % (hadoopCommand, item))
    hadoopCommand = (hadoopCommand + (' 1>%s 2>%s ' % (self.out, self.err)))
    self.log.debug(('running command: %s' % hadoopCommand))
    self.log.debug(('hadoop env: %s' % fenvs))
    self.log.debug((('Command stdout will be redirected to %s ' % self.out) + ('and command stderr to %s' % self.err)))
    self.__hadoopThread = simpleCommand('hadoop', hadoopCommand, env=fenvs)
    self.__hadoopThread.start()
    while (self.__hadoopThread.stdin == None):
        time.sleep(0.2)
        self.log.debug('hadoopThread still == None ...')
    input = desc.getStdin()
    self.log.debug(('hadoop input: %s' % input))
    if input:
        if self.__hadoopThread.is_running():
            print  >> self.__hadoopThread.stdin, input
        else:
            self.log.error('hadoop command failed to start')
    self.__hadoopThread.stdin.close()
    self.log.debug(('isForground: %s' % desc.isForeground()))
    if desc.isForeground():
        self.log.debug('Waiting on hadoop to finish...')
        self.__hadoopThread.wait()
        self.log.debug('Joining hadoop thread...')
        self.__hadoopThread.join()
        if (self.__hadoopThread.exit_code() != 0):
            status = False
    else:
        status = self.getCommandStatus()
    self.log.debug(('hadoop run status: %s' % status))
    if (status == False):
        self.handleFailedCommand()
    if ((status == True) or (not desc.isIgnoreFailures())):
        return status
    else:
        self.log.error('Ignoring Failure')
        return True
