{
  recalculateReduceSchedule=true;
  if (event.getType() == ContainerAllocator.EventType.CONTAINER_REQ) {
    ContainerRequestEvent reqEvent=(ContainerRequestEvent)event;
    JobId jobId=getJob().getID();
    int supportedMaxContainerCapability=getMaxContainerCapability().getMemory();
    if (reqEvent.getAttemptID().getTaskId().getTaskType().equals(TaskType.MAP)) {
      if (mapResourceReqt == 0) {
        mapResourceReqt=reqEvent.getCapability().getMemory();
        eventHandler.handle(new JobHistoryEvent(jobId,new NormalizedResourceEvent(org.apache.hadoop.mapreduce.TaskType.MAP,mapResourceReqt)));
        LOG.info("mapResourceReqt:" + mapResourceReqt);
        if (mapResourceReqt > supportedMaxContainerCapability) {
          String diagMsg="MAP capability required is more than the supported " + "max container capability in the cluster. Killing the Job. mapResourceReqt: " + mapResourceReqt + " maxContainerCapability:"+ supportedMaxContainerCapability;
          LOG.info(diagMsg);
          eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId,diagMsg));
          eventHandler.handle(new JobEvent(jobId,JobEventType.JOB_KILL));
        }
      }
      reqEvent.getCapability().setMemory(mapResourceReqt);
      scheduledRequests.addMap(reqEvent);
    }
 else {
      if (reduceResourceReqt == 0) {
        reduceResourceReqt=reqEvent.getCapability().getMemory();
        eventHandler.handle(new JobHistoryEvent(jobId,new NormalizedResourceEvent(org.apache.hadoop.mapreduce.TaskType.REDUCE,reduceResourceReqt)));
        LOG.info("reduceResourceReqt:" + reduceResourceReqt);
        if (reduceResourceReqt > supportedMaxContainerCapability) {
          String diagMsg="REDUCE capability required is more than the " + "supported max container capability in the cluster. Killing the " + "Job. reduceResourceReqt: " + reduceResourceReqt + " maxContainerCapability:"+ supportedMaxContainerCapability;
          LOG.info(diagMsg);
          eventHandler.handle(new JobDiagnosticsUpdateEvent(jobId,diagMsg));
          eventHandler.handle(new JobEvent(jobId,JobEventType.JOB_KILL));
        }
      }
      reqEvent.getCapability().setMemory(reduceResourceReqt);
      if (reqEvent.getEarlierAttemptFailed()) {
        pendingReduces.addFirst(new ContainerRequest(reqEvent,PRIORITY_REDUCE));
      }
 else {
        pendingReduces.add(new ContainerRequest(reqEvent,PRIORITY_REDUCE));
      }
    }
  }
 else   if (event.getType() == ContainerAllocator.EventType.CONTAINER_DEALLOCATE) {
    LOG.info("Processing the event " + event.toString());
    TaskAttemptId aId=event.getAttemptID();
    boolean removed=scheduledRequests.remove(aId);
    if (!removed) {
      ContainerId containerId=assignedRequests.get(aId);
      if (containerId != null) {
        removed=true;
        assignedRequests.remove(aId);
        containersReleased++;
        release(containerId);
      }
    }
    if (!removed) {
      LOG.error("Could not deallocate container for task attemptId " + aId);
    }
  }
 else   if (event.getType() == ContainerAllocator.EventType.CONTAINER_FAILED) {
    ContainerFailedEvent fEv=(ContainerFailedEvent)event;
    String host=getHost(fEv.getContMgrAddress());
    containerFailedOnHost(host);
  }
}
