{
  Path file=new Path(fileName);
  long fileLen=DATA_BLK_NUM * BLOCKSIZE;
  final byte[] data=StripedFileTestUtil.generateBytes((int)fileLen);
  DFSTestUtil.writeFile(fs,file,data);
  StripedFileTestUtil.waitBlockGroupsReported(fs,fileName);
  LocatedBlocks locatedBlocks=StripedFileTestUtil.getLocatedBlocks(file,fs);
  LocatedStripedBlock lastBlock=(LocatedStripedBlock)locatedBlocks.getLastLocatedBlock();
  DataNode workerDn=null;
  DatanodeInfo[] locations=lastBlock.getLocations();
  assertEquals(locations.length,GROUPSIZE);
  for (  DataNode dn : cluster.getDataNodes()) {
    boolean appear=false;
    for (    DatanodeInfo info : locations) {
      if (dn.getDatanodeUuid().equals(info.getDatanodeUuid())) {
        appear=true;
        break;
      }
    }
    if (!appear) {
      workerDn=dn;
      break;
    }
  }
  LOG.info("Block locations: " + Arrays.asList(locations));
  LOG.info("Erasure coding worker datanode: " + workerDn);
  assertNotNull("Failed to find a worker datanode",workerDn);
  DataNode toCorruptDn=cluster.getDataNode(locations[0].getIpcPort());
  LOG.info("Datanode to be corrupted: " + toCorruptDn);
  assertNotNull("Failed to find a datanode to be corrupted",toCorruptDn);
  toCorruptDn.shutdown();
  setDataNodeDead(toCorruptDn.getDatanodeId());
  DFSTestUtil.waitForDatanodeState(cluster,toCorruptDn.getDatanodeUuid(),false,10000);
  int workCount=getComputedDatanodeWork();
  assertTrue("Wrongly computed block reconstruction work",workCount > 0);
  cluster.triggerHeartbeats();
  StripedFileTestUtil.waitForReconstructionFinished(file,fs,GROUPSIZE);
  return workerDn;
}
