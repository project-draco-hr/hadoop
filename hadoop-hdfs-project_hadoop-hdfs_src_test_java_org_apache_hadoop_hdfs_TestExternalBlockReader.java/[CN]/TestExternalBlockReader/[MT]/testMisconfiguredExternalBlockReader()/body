{
  Configuration conf=new Configuration();
  conf.set(HdfsClientConfigKeys.REPLICA_ACCESSOR_BUILDER_CLASSES_KEY,"org.apache.hadoop.hdfs.NonExistentReplicaAccessorBuilderClass");
  conf.setLong(HdfsClientConfigKeys.DFS_BLOCK_SIZE_KEY,1024);
  conf.setLong(DFSConfigKeys.DFS_NAMENODE_MIN_BLOCK_SIZE_KEY,0);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
  final int TEST_LENGTH=2048;
  DistributedFileSystem dfs=cluster.getFileSystem();
  try {
    DFSTestUtil.createFile(dfs,new Path("/a"),TEST_LENGTH,(short)1,SEED);
    FSDataInputStream stream=dfs.open(new Path("/a"));
    byte buf[]=new byte[TEST_LENGTH];
    IOUtils.readFully(stream,buf,0,TEST_LENGTH);
    byte expected[]=DFSTestUtil.calculateFileContentsFromSeed(SEED,TEST_LENGTH);
    Assert.assertArrayEquals(expected,buf);
    stream.close();
  }
  finally {
    dfs.close();
    cluster.shutdown();
  }
}
