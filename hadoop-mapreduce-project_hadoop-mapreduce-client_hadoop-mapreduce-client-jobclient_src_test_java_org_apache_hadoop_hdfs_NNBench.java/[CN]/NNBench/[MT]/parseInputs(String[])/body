{
  if (args.length == 0) {
    displayUsage();
    throw new HadoopIllegalArgumentException("Give valid inputs");
  }
  for (int i=0; i < args.length; i++) {
    if (args[i].equals("-operation")) {
      operation=args[++i];
    }
 else     if (args[i].equals("-maps")) {
      checkArgs(i + 1,args.length);
      numberOfMaps=Long.parseLong(args[++i]);
    }
 else     if (args[i].equals("-reduces")) {
      checkArgs(i + 1,args.length);
      numberOfReduces=Long.parseLong(args[++i]);
    }
 else     if (args[i].equals("-startTime")) {
      checkArgs(i + 1,args.length);
      startTime=Long.parseLong(args[++i]) * 1000;
    }
 else     if (args[i].equals("-blockSize")) {
      checkArgs(i + 1,args.length);
      blockSize=Long.parseLong(args[++i]);
    }
 else     if (args[i].equals("-bytesToWrite")) {
      checkArgs(i + 1,args.length);
      bytesToWrite=Integer.parseInt(args[++i]);
    }
 else     if (args[i].equals("-bytesPerChecksum")) {
      checkArgs(i + 1,args.length);
      bytesPerChecksum=Long.parseLong(args[++i]);
    }
 else     if (args[i].equals("-numberOfFiles")) {
      checkArgs(i + 1,args.length);
      numberOfFiles=Long.parseLong(args[++i]);
    }
 else     if (args[i].equals("-replicationFactorPerFile")) {
      checkArgs(i + 1,args.length);
      replicationFactorPerFile=Short.parseShort(args[++i]);
    }
 else     if (args[i].equals("-baseDir")) {
      checkArgs(i + 1,args.length);
      baseDir=args[++i];
    }
 else     if (args[i].equals("-readFileAfterOpen")) {
      checkArgs(i + 1,args.length);
      readFileAfterOpen=Boolean.parseBoolean(args[++i]);
    }
 else     if (args[i].equals("-help")) {
      displayUsage();
      isHelpMessage=true;
    }
  }
  LOG.info("Test Inputs: ");
  LOG.info("           Test Operation: " + operation);
  LOG.info("               Start time: " + sdf.format(new Date(startTime)));
  LOG.info("           Number of maps: " + numberOfMaps);
  LOG.info("        Number of reduces: " + numberOfReduces);
  LOG.info("               Block Size: " + blockSize);
  LOG.info("           Bytes to write: " + bytesToWrite);
  LOG.info("       Bytes per checksum: " + bytesPerChecksum);
  LOG.info("          Number of files: " + numberOfFiles);
  LOG.info("       Replication factor: " + replicationFactorPerFile);
  LOG.info("                 Base dir: " + baseDir);
  LOG.info("     Read file after open: " + readFileAfterOpen);
  getConf().set("test.nnbench.operation",operation);
  getConf().setLong("test.nnbench.maps",numberOfMaps);
  getConf().setLong("test.nnbench.reduces",numberOfReduces);
  getConf().setLong("test.nnbench.starttime",startTime);
  getConf().setLong("test.nnbench.blocksize",blockSize);
  getConf().setInt("test.nnbench.bytestowrite",bytesToWrite);
  getConf().setLong("test.nnbench.bytesperchecksum",bytesPerChecksum);
  getConf().setLong("test.nnbench.numberoffiles",numberOfFiles);
  getConf().setInt("test.nnbench.replicationfactor",(int)replicationFactorPerFile);
  getConf().set("test.nnbench.basedir",baseDir);
  getConf().setBoolean("test.nnbench.readFileAfterOpen",readFileAfterOpen);
  getConf().set("test.nnbench.datadir.name",DATA_DIR_NAME);
  getConf().set("test.nnbench.outputdir.name",OUTPUT_DIR_NAME);
  getConf().set("test.nnbench.controldir.name",CONTROL_DIR_NAME);
}
