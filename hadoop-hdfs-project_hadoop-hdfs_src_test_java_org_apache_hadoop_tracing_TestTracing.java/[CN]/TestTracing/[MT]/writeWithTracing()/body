{
  long startTime=System.currentTimeMillis();
  TraceScope ts=Trace.startSpan("testWriteTraceHooks",Sampler.ALWAYS);
  writeTestFile("testWriteTraceHooks.dat");
  long endTime=System.currentTimeMillis();
  ts.close();
  String[] expectedSpanNames={"testWriteTraceHooks","org.apache.hadoop.hdfs.protocol.ClientProtocol.create","ClientNamenodeProtocol#create","org.apache.hadoop.hdfs.protocol.ClientProtocol.fsync","ClientNamenodeProtocol#fsync","org.apache.hadoop.hdfs.protocol.ClientProtocol.complete","ClientNamenodeProtocol#complete","newStreamForCreate","DFSOutputStream#write","DFSOutputStream#close","dataStreamer","OpWriteBlockProto","org.apache.hadoop.hdfs.protocol.ClientProtocol.addBlock","ClientNamenodeProtocol#addBlock"};
  SetSpanReceiver.assertSpanNamesFound(expectedSpanNames);
  Map<String,List<Span>> map=SetSpanReceiver.getMap();
  Span s=map.get("testWriteTraceHooks").get(0);
  Assert.assertNotNull(s);
  long spanStart=s.getStartTimeMillis();
  long spanEnd=s.getStopTimeMillis();
  String[] spansInTopTrace={"testWriteTraceHooks","org.apache.hadoop.hdfs.protocol.ClientProtocol.create","ClientNamenodeProtocol#create","org.apache.hadoop.hdfs.protocol.ClientProtocol.fsync","ClientNamenodeProtocol#fsync","org.apache.hadoop.hdfs.protocol.ClientProtocol.complete","ClientNamenodeProtocol#complete","newStreamForCreate","DFSOutputStream#write","DFSOutputStream#close"};
  for (  String desc : spansInTopTrace) {
    for (    Span span : map.get(desc)) {
      Assert.assertEquals(ts.getSpan().getTraceId(),span.getTraceId());
    }
  }
  Assert.assertEquals("called",map.get("org.apache.hadoop.hdfs.protocol.ClientProtocol.create").get(0).getTimelineAnnotations().get(0).getMessage());
  SetSpanReceiver.clear();
}
