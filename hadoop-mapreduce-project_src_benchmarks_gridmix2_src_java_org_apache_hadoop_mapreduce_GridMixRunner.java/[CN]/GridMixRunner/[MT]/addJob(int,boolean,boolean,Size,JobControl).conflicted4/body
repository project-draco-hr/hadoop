{
  final String prop=String.format("monsterQuery.%sJobs.inputFiles",size);
  final String indir=getInputDirsFor(prop,size.defaultPath(FIXCOMPSEQ));
  final String outdir=addTSSuffix("perf-out/mq-out-dir-" + size);
  int iter=3;
  try {
    ControlledJob pjob=null;
    ControlledJob cjob=null;
    for (int i=0; i < iter; i++) {
      String outdirfull=outdir + "." + i;
      String indirfull=(0 == i) ? indir : outdir + "." + (i - 1);
      Path outfile=new Path(outdirfull);
      StringBuffer sb=new StringBuffer();
      sb.append("-keepmap 10 ");
      sb.append("-keepred 40 ");
      sb.append("-inFormat");
      sb.append(" org.apache.hadoop.mapreduce." + "lib.input.SequenceFileInputFormat ");
      sb.append("-outFormat");
      sb.append(" org.apache.hadoop.mapreduce." + "lib.output.SequenceFileOutputFormat ");
      sb.append("-outKey org.apache.hadoop.io.Text ");
      sb.append("-outValue org.apache.hadoop.io.Text ");
      sb.append("-indir ").append(indirfull).append(" ");
      sb.append("-outdir ").append(outdirfull).append(" ");
      sb.append("-r ").append(numReducers);
      String[] args=sb.toString().split(" ");
      try {
        fs.delete(outfile,true);
      }
 catch (      IOException ex) {
        System.out.println(ex.toString());
      }
      Job job=GenericMRLoadJobCreator.createJob(args,mapoutputCompressed,outputCompressed);
      job.setJobName("GridmixMonsterQuery." + size);
      cjob=new ControlledJob(job,null);
      if (pjob != null) {
        cjob.addDependingJob(pjob);
      }
      gridmix.addJob(cjob);
      pjob=cjob;
    }
  }
 catch (  Exception e) {
    System.out.println(e.getStackTrace());
  }
}
