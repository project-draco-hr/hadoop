{
  String[] baseDirs;
  for (int numDirs=1; numDirs <= 2; numDirs++) {
    conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_SCAN_PERIOD_HOURS_KEY,-1);
    conf=UpgradeUtilities.initializeStorageStateConf(numDirs,conf);
    for (int i=0; i < NUM_NN_TEST_CASES; i++) {
      boolean[] testCase=testCases[i];
      boolean shouldRecover=testCase[SHOULD_RECOVER];
      boolean curAfterRecover=testCase[CURRENT_SHOULD_EXIST_AFTER_RECOVER];
      boolean prevAfterRecover=testCase[PREVIOUS_SHOULD_EXIST_AFTER_RECOVER];
      log("NAME_NODE recovery",numDirs,i,testCase);
      baseDirs=createNameNodeStorageState(testCase);
      if (shouldRecover) {
        cluster=createCluster(conf);
        checkResultNameNode(baseDirs,curAfterRecover,prevAfterRecover);
        cluster.shutdown();
      }
 else {
        try {
          cluster=createCluster(conf);
          throw new AssertionError("NameNode should have failed to start");
        }
 catch (        IOException expected) {
          if (!testCases[i][CURRENT_EXISTS] && !testCases[i][PREVIOUS_TMP_EXISTS] && !testCases[i][PREVIOUS_EXISTS]&& !testCases[i][REMOVED_TMP_EXISTS]) {
            assertTrue(expected.getLocalizedMessage().contains("NameNode is not formatted"));
          }
        }
      }
      cluster.shutdown();
    }
  }
}
