{
  super(conf);
  this.blockScanner=new BlockScanner(this,conf);
  this.lastDiskErrorCheck=0;
  this.maxNumberOfBlocksToLog=conf.getLong(DFS_MAX_NUM_BLOCKS_TO_LOG_KEY,DFS_MAX_NUM_BLOCKS_TO_LOG_DEFAULT);
  this.usersWithLocalPathAccess=Arrays.asList(conf.getTrimmedStrings(DFSConfigKeys.DFS_BLOCK_LOCAL_PATH_ACCESS_USER_KEY));
  this.connectToDnViaHostname=conf.getBoolean(DFSConfigKeys.DFS_DATANODE_USE_DN_HOSTNAME,DFSConfigKeys.DFS_DATANODE_USE_DN_HOSTNAME_DEFAULT);
  this.supergroup=conf.get(DFSConfigKeys.DFS_PERMISSIONS_SUPERUSERGROUP_KEY,DFSConfigKeys.DFS_PERMISSIONS_SUPERUSERGROUP_DEFAULT);
  this.isPermissionEnabled=conf.getBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY,DFSConfigKeys.DFS_PERMISSIONS_ENABLED_DEFAULT);
  this.pipelineSupportECN=conf.getBoolean(DFSConfigKeys.DFS_PIPELINE_ECN_ENABLED,DFSConfigKeys.DFS_PIPELINE_ECN_ENABLED_DEFAULT);
  confVersion="core-" + conf.get("hadoop.common.configuration.version","UNSPECIFIED") + ",hdfs-"+ conf.get("hadoop.hdfs.configuration.version","UNSPECIFIED");
  this.checkDiskErrorInterval=ThreadLocalRandom.current().nextInt(5000,(int)(5000 * 1.25));
  if (conf.getBoolean(HdfsClientConfigKeys.Read.ShortCircuit.KEY,HdfsClientConfigKeys.Read.ShortCircuit.DEFAULT)) {
    String reason=DomainSocket.getLoadingFailureReason();
    if (reason != null) {
      LOG.warn("File descriptor passing is disabled because " + reason);
      this.fileDescriptorPassingDisabledReason=reason;
    }
 else {
      LOG.info("File descriptor passing is enabled.");
      this.fileDescriptorPassingDisabledReason=null;
    }
  }
 else {
    this.fileDescriptorPassingDisabledReason="File descriptor passing was not configured.";
    LOG.debug(this.fileDescriptorPassingDisabledReason);
  }
  try {
    hostName=getHostName(conf);
    LOG.info("Configured hostname is " + hostName);
    startDataNode(conf,dataDirs,resources);
  }
 catch (  IOException ie) {
    shutdown();
    throw ie;
  }
  final int dncCacheMaxSize=conf.getInt(DFS_DATANODE_NETWORK_COUNTS_CACHE_MAX_SIZE_KEY,DFS_DATANODE_NETWORK_COUNTS_CACHE_MAX_SIZE_DEFAULT);
  datanodeNetworkCounts=CacheBuilder.newBuilder().maximumSize(dncCacheMaxSize).build(new CacheLoader<String,Map<String,Long>>(){
    @Override public Map<String,Long> load(    String key) throws Exception {
      final Map<String,Long> ret=new HashMap<String,Long>();
      ret.put("networkErrors",0L);
      return ret;
    }
  }
);
  initOOBTimeout();
}
