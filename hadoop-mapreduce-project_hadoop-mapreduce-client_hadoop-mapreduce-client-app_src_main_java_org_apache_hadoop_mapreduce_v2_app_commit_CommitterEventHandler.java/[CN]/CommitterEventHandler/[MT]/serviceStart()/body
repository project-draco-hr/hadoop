{
  ThreadFactoryBuilder tfBuilder=new ThreadFactoryBuilder().setNameFormat("CommitterEvent Processor #%d");
  if (jobClassLoader != null) {
    ThreadFactory backingTf=new ThreadFactory(){
      @Override public Thread newThread(      Runnable r){
        Thread thread=new Thread(r);
        thread.setContextClassLoader(jobClassLoader);
        return thread;
      }
    }
;
    tfBuilder.setThreadFactory(backingTf);
  }
  ThreadFactory tf=tfBuilder.build();
  launcherPool=new HadoopThreadPoolExecutor(5,5,1,TimeUnit.HOURS,new LinkedBlockingQueue<Runnable>(),tf);
  eventHandlingThread=new Thread(new Runnable(){
    @Override public void run(){
      CommitterEvent event=null;
      while (!stopped.get() && !Thread.currentThread().isInterrupted()) {
        try {
          event=eventQueue.take();
        }
 catch (        InterruptedException e) {
          if (!stopped.get()) {
            LOG.error("Returning, interrupted : " + e);
          }
          return;
        }
        launcherPool.execute(new EventProcessor(event));
      }
    }
  }
);
  eventHandlingThread.setName("CommitterEvent Handler");
  eventHandlingThread.start();
  super.serviceStart();
}
