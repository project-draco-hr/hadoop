{
  com.google.protobuf.UnknownFieldSet.Builder unknownFields=com.google.protobuf.UnknownFieldSet.newBuilder(this.getUnknownFields());
  while (true) {
    int tag=input.readTag();
switch (tag) {
case 0:
      this.setUnknownFields(unknownFields.build());
    onChanged();
  return this;
default :
{
  if (!parseUnknownField(input,unknownFields,extensionRegistry,tag)) {
    this.setUnknownFields(unknownFields.build());
    onChanged();
    return this;
  }
  break;
}
case 8:
{
int rawValue=input.readEnum();
org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockCommandProto.Action value=org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.BlockCommandProto.Action.valueOf(rawValue);
if (value == null) {
  unknownFields.mergeVarintField(1,rawValue);
}
 else {
  bitField0_|=0x00000001;
  action_=value;
}
break;
}
case 18:
{
bitField0_|=0x00000002;
blockPoolId_=input.readBytes();
break;
}
case 26:
{
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockProto.Builder subBuilder=org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.BlockProto.newBuilder();
input.readMessage(subBuilder,extensionRegistry);
addBlocks(subBuilder.buildPartial());
break;
}
case 34:
{
org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfosProto.Builder subBuilder=org.apache.hadoop.hdfs.protocol.proto.HdfsProtos.DatanodeInfosProto.newBuilder();
input.readMessage(subBuilder,extensionRegistry);
addTargets(subBuilder.buildPartial());
break;
}
}
}
}
