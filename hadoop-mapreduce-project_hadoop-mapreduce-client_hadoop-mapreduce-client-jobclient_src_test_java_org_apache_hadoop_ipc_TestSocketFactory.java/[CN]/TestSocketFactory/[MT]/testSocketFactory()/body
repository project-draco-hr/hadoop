{
  Configuration sconf=new Configuration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(sconf).numDataNodes(1).build();
  final int nameNodePort=cluster.getNameNodePort();
  FileSystem fs=cluster.getFileSystem();
  Assert.assertTrue(fs instanceof DistributedFileSystem);
  DistributedFileSystem directDfs=(DistributedFileSystem)fs;
  Configuration cconf=getCustomSocketConfigs(nameNodePort);
  fs=FileSystem.get(cconf);
  Assert.assertTrue(fs instanceof DistributedFileSystem);
  DistributedFileSystem dfs=(DistributedFileSystem)fs;
  JobClient client=null;
  MiniMRYarnCluster miniMRYarnCluster=null;
  try {
    Path filePath=new Path("/dir");
    Assert.assertFalse(directDfs.exists(filePath));
    Assert.assertFalse(dfs.exists(filePath));
    directDfs.mkdirs(filePath);
    Assert.assertTrue(directDfs.exists(filePath));
    Assert.assertTrue(dfs.exists(filePath));
    fs=FileSystem.get(sconf);
    JobConf jobConf=new JobConf();
    FileSystem.setDefaultUri(jobConf,fs.getUri().toString());
    miniMRYarnCluster=initAndStartMiniMRYarnCluster(jobConf);
    JobConf jconf=new JobConf(miniMRYarnCluster.getConfig());
    jconf.set("hadoop.rpc.socket.factory.class.default","org.apache.hadoop.ipc.DummySocketFactory");
    jconf.set(MRConfig.FRAMEWORK_NAME,MRConfig.YARN_FRAMEWORK_NAME);
    String rmAddress=jconf.get("yarn.resourcemanager.address");
    String[] split=rmAddress.split(":");
    jconf.set("yarn.resourcemanager.address",split[0] + ':' + (Integer.parseInt(split[1]) + 10));
    client=new JobClient(jconf);
    JobStatus[] jobs=client.jobsToComplete();
    Assert.assertTrue(jobs.length == 0);
  }
  finally {
    closeClient(client);
    closeDfs(dfs);
    closeDfs(directDfs);
    stopMiniMRYarnCluster(miniMRYarnCluster);
    shutdownDFSCluster(cluster);
  }
}
