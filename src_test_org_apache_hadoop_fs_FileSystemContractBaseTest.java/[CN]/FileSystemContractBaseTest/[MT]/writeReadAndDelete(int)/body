{
  Path path=path("/test/hadoop/file");
  fs.mkdirs(path.getParent());
  FSDataOutputStream out=fs.create(path,false,fs.getConf().getInt("io.file.buffer.size",4096),(short)1,getBlockSize());
  out.write(data,0,len);
  out.close();
  assertTrue("Exists",fs.exists(path));
  assertEquals("Length",len,fs.getFileStatus(path).getLen());
  FSDataInputStream in=fs.open(path);
  byte[] buf=new byte[len];
  in.readFully(0,buf);
  in.close();
  assertEquals(len,buf.length);
  for (int i=0; i < buf.length; i++) {
    assertEquals("Position " + i,data[i],buf[i]);
  }
  assertTrue("Deleted",fs.delete(path,false));
  assertFalse("No longer exists",fs.exists(path));
}
