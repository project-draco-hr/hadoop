{
  ContainerId containerId;
  try {
    containerId=ContainerId.fromString(containerIdStr);
  }
 catch (  IllegalArgumentException ex) {
    return Response.status(Status.BAD_REQUEST).build();
  }
  File logFile=null;
  try {
    logFile=ContainerLogsUtils.getContainerLogFile(containerId,filename,request.getRemoteUser(),nmContext);
  }
 catch (  NotFoundException ex) {
    return Response.status(Status.NOT_FOUND).entity(ex.getMessage()).build();
  }
catch (  YarnException ex) {
    return Response.serverError().entity(ex.getMessage()).build();
  }
  final long bytes=parseLongParam(size);
  String contentType=WebAppUtils.getDefaultLogContentType();
  if (format != null && !format.isEmpty()) {
    contentType=WebAppUtils.getSupportedLogContentType(format);
    if (contentType == null) {
      String errorMessage="The valid values for the parameter : format " + "are " + WebAppUtils.listSupportedLogContentType();
      return Response.status(Status.BAD_REQUEST).entity(errorMessage).build();
    }
  }
  try {
    final FileInputStream fis=ContainerLogsUtils.openLogFileForRead(containerIdStr,logFile,nmContext);
    final long fileLength=logFile.length();
    StreamingOutput stream=new StreamingOutput(){
      @Override public void write(      OutputStream os) throws IOException, WebApplicationException {
        try {
          int bufferSize=65536;
          byte[] buf=new byte[bufferSize];
          long toSkip=0;
          long totalBytesToRead=fileLength;
          long skipAfterRead=0;
          if (bytes < 0) {
            long absBytes=Math.abs(bytes);
            if (absBytes < fileLength) {
              toSkip=fileLength - absBytes;
              totalBytesToRead=absBytes;
            }
            org.apache.hadoop.io.IOUtils.skipFully(fis,toSkip);
          }
 else {
            if (bytes < fileLength) {
              totalBytesToRead=bytes;
              skipAfterRead=fileLength - bytes;
            }
          }
          long curRead=0;
          long pendingRead=totalBytesToRead - curRead;
          int toRead=pendingRead > buf.length ? buf.length : (int)pendingRead;
          int len=fis.read(buf,0,toRead);
          while (len != -1 && curRead < totalBytesToRead) {
            os.write(buf,0,len);
            curRead+=len;
            pendingRead=totalBytesToRead - curRead;
            toRead=pendingRead > buf.length ? buf.length : (int)pendingRead;
            len=fis.read(buf,0,toRead);
          }
          org.apache.hadoop.io.IOUtils.skipFully(fis,skipAfterRead);
          os.flush();
        }
  finally {
          IOUtils.closeQuietly(fis);
        }
      }
    }
;
    ResponseBuilder resp=Response.ok(stream);
    resp.header("Content-Type",contentType);
    resp.header("X-Content-Type-Options","nosniff");
    return resp.build();
  }
 catch (  IOException ex) {
    return Response.serverError().entity(ex.getMessage()).build();
  }
}
