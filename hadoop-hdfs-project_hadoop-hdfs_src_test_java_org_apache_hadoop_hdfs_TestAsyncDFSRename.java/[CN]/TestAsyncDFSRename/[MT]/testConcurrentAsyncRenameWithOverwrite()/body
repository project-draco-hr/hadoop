{
  final short replFactor=2;
  final long blockSize=512;
  final Path renameDir=new Path("/test/concurrent_reanme_with_overwrite_dir/");
  Configuration conf=new HdfsConfiguration();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  cluster.waitActive();
  DistributedFileSystem dfs=cluster.getFileSystem();
  AsyncDistributedFileSystem adfs=dfs.getAsyncDistributedFileSystem();
  int count=1000;
  try {
    long fileLen=blockSize * 3;
    assertTrue(dfs.mkdirs(renameDir));
    Map<Integer,Future<Void>> returnFutures=new HashMap<Integer,Future<Void>>();
    for (int i=0; i < count; i++) {
      Path src=new Path(renameDir,"src" + i);
      Path dst=new Path(renameDir,"dst" + i);
      DFSTestUtil.createFile(dfs,src,fileLen,replFactor,1);
      DFSTestUtil.createFile(dfs,dst,fileLen,replFactor,1);
      Future<Void> returnFuture=adfs.rename(src,dst,Rename.OVERWRITE);
      returnFutures.put(i,returnFuture);
    }
    for (int i=0; i < count; i++) {
      returnFutures.get(i).get();
    }
    cluster.restartNameNodes();
    for (int i=0; i < count; i++) {
      Path src=new Path(renameDir,"src" + i);
      Path dst=new Path(renameDir,"dst" + i);
      assertFalse(dfs.exists(src));
      assertTrue(dfs.exists(dst));
    }
  }
  finally {
    dfs.delete(renameDir,true);
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
