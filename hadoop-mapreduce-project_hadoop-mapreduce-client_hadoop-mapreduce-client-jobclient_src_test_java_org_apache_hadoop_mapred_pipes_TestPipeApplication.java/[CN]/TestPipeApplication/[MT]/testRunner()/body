{
  File[] psw=cleanTokenPasswordFile();
  try {
    RecordReader<FloatWritable,NullWritable> rReader=new ReaderPipesMapRunner();
    JobConf conf=new JobConf();
    conf.set(Submitter.IS_JAVA_RR,"true");
    conf.set(MRJobConfig.TASK_ATTEMPT_ID,taskName);
    CombineOutputCollector<IntWritable,Text> output=new CombineOutputCollector<IntWritable,Text>(new Counters.Counter(),new Progress());
    FileSystem fs=new RawLocalFileSystem();
    fs.setConf(conf);
    Writer<IntWritable,Text> wr=new Writer<IntWritable,Text>(conf,fs,new Path(workSpace + File.separator + "outfile"),IntWritable.class,Text.class,null,null);
    output.setWriter(wr);
    File fCommand=getFileCommand("org.apache.hadoop.mapred.pipes.PipeApplicationRunnableStub");
    conf.set(MRJobConfig.CACHE_LOCALFILES,fCommand.getAbsolutePath());
    Token<AMRMTokenIdentifier> token=new Token<AMRMTokenIdentifier>("user".getBytes(),"password".getBytes(),new Text("kind"),new Text("service"));
    TokenCache.setJobToken(token,conf.getCredentials());
    conf.setBoolean(MRJobConfig.SKIP_RECORDS,true);
    TestTaskReporter reporter=new TestTaskReporter();
    PipesMapRunner<FloatWritable,NullWritable,IntWritable,Text> runner=new PipesMapRunner<FloatWritable,NullWritable,IntWritable,Text>();
    initStdOut(conf);
    runner.configure(conf);
    runner.run(rReader,output,reporter);
    String stdOut=readStdOut(conf);
    assertTrue(stdOut.contains("CURRENT_PROTOCOL_VERSION:0"));
    assertTrue(stdOut.contains("Key class:org.apache.hadoop.io.FloatWritable"));
    assertTrue(stdOut.contains("Value class:org.apache.hadoop.io.NullWritable"));
    assertTrue(stdOut.contains("value:0.0"));
    assertTrue(stdOut.contains("value:9.0"));
  }
  finally {
    if (psw != null) {
      for (      File file : psw) {
        file.deleteOnExit();
      }
    }
  }
}
