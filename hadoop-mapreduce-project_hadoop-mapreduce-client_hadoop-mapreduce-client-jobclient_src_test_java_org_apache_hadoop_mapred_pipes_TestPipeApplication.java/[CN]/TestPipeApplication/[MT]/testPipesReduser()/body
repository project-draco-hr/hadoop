{
  File[] psw=cleanTokenPasswordFile();
  JobConf conf=new JobConf();
  try {
    Token<AMRMTokenIdentifier> token=new Token<AMRMTokenIdentifier>("user".getBytes(),"password".getBytes(),new Text("kind"),new Text("service"));
    TokenCache.setJobToken(token,conf.getCredentials());
    File fCommand=getFileCommand("org.apache.hadoop.mapred.pipes.PipeReducerStub");
    conf.set(MRJobConfig.CACHE_LOCALFILES,fCommand.getAbsolutePath());
    PipesReducer<BooleanWritable,Text,IntWritable,Text> reducer=new PipesReducer<BooleanWritable,Text,IntWritable,Text>();
    reducer.configure(conf);
    BooleanWritable bw=new BooleanWritable(true);
    conf.set(MRJobConfig.TASK_ATTEMPT_ID,taskName);
    initStdOut(conf);
    conf.setBoolean(MRJobConfig.SKIP_RECORDS,true);
    CombineOutputCollector<IntWritable,Text> output=new CombineOutputCollector<IntWritable,Text>(new Counters.Counter(),new Progress());
    Reporter reporter=new TestTaskReporter();
    List<Text> texts=new ArrayList<Text>();
    texts.add(new Text("first"));
    texts.add(new Text("second"));
    texts.add(new Text("third"));
    reducer.reduce(bw,texts.iterator(),output,reporter);
    reducer.close();
    String stdOut=readStdOut(conf);
    assertTrue(stdOut.contains("reducer key :true"));
    assertTrue(stdOut.contains("reduce value  :first"));
    assertTrue(stdOut.contains("reduce value  :second"));
    assertTrue(stdOut.contains("reduce value  :third"));
  }
  finally {
    if (psw != null) {
      for (      File file : psw) {
        file.deleteOnExit();
      }
    }
  }
}
