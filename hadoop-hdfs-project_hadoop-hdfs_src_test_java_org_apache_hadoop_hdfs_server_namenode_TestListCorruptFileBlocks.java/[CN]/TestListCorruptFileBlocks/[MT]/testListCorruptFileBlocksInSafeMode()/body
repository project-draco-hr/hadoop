{
  MiniDFSCluster cluster=null;
  Random random=new Random();
  try {
    Configuration conf=new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_DATANODE_DIRECTORYSCAN_INTERVAL_KEY,1);
    conf.setInt(DFSConfigKeys.DFS_BLOCKREPORT_INTERVAL_MSEC_KEY,3 * 1000);
    conf.setFloat(DFSConfigKeys.DFS_NAMENODE_SAFEMODE_THRESHOLD_PCT_KEY,1.5f);
    conf.setFloat(DFSConfigKeys.DFS_NAMENODE_REPL_QUEUE_THRESHOLD_PCT_KEY,0f);
    conf.setInt(DFSConfigKeys.DFS_CLIENT_RETRY_WINDOW_BASE,10);
    cluster=new MiniDFSCluster.Builder(conf).waitSafeMode(false).build();
    cluster.getNameNodeRpc().setSafeMode(HdfsConstants.SafeModeAction.SAFEMODE_LEAVE,false);
    FileSystem fs=cluster.getFileSystem();
    DFSTestUtil util=new DFSTestUtil.Builder().setName("testListCorruptFileBlocksInSafeMode").setNumFiles(2).setMaxLevels(1).setMaxSize(512).build();
    util.createFiles(fs,"/srcdat10");
    Collection<FSNamesystem.CorruptFileBlockInfo> badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    assertTrue("Namenode has " + badFiles.size() + " corrupt files. Expecting None.",badFiles.size() == 0);
    File storageDir=cluster.getInstanceStorageDir(0,0);
    File data_dir=MiniDFSCluster.getFinalizedDir(storageDir,cluster.getNamesystem().getBlockPoolId());
    assertTrue("data directory does not exist",data_dir.exists());
    File[] blocks=data_dir.listFiles();
    assertTrue("Blocks do not exist in data-dir",(blocks != null) && (blocks.length > 0));
    for (int idx=0; idx < blocks.length; idx++) {
      if (blocks[idx].getName().startsWith("blk_") && blocks[idx].getName().endsWith(".meta")) {
        RandomAccessFile file=new RandomAccessFile(blocks[idx],"rw");
        FileChannel channel=file.getChannel();
        long position=channel.size() - 2;
        int length=2;
        byte[] buffer=new byte[length];
        random.nextBytes(buffer);
        channel.write(ByteBuffer.wrap(buffer),position);
        file.close();
        LOG.info("Deliberately corrupting file " + blocks[idx].getName() + " at offset "+ position+ " length "+ length);
        try {
          util.checkFiles(fs,"/srcdat10");
        }
 catch (        BlockMissingException e) {
          System.out.println("Received BlockMissingException as expected.");
        }
catch (        IOException e) {
          assertTrue("Corrupted replicas not handled properly. " + "Expecting BlockMissingException " + " but received IOException "+ e,false);
        }
        break;
      }
    }
    badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting 1.",badFiles.size() == 1);
    cluster.restartNameNode(0);
    fs=cluster.getFileSystem();
    while (!cluster.getNameNode().namesystem.isPopulatingReplQueues()) {
      try {
        LOG.info("waiting for replication queues");
        Thread.sleep(1000);
      }
 catch (      InterruptedException ignore) {
      }
    }
    try {
      util.checkFiles(fs,"/srcdat10");
    }
 catch (    BlockMissingException e) {
      System.out.println("Received BlockMissingException as expected.");
    }
catch (    IOException e) {
      assertTrue("Corrupted replicas not handled properly. " + "Expecting BlockMissingException " + " but received IOException "+ e,false);
    }
    badFiles=cluster.getNameNode().getNamesystem().listCorruptFileBlocks("/",null);
    LOG.info("Namenode has bad files. " + badFiles.size());
    assertTrue("Namenode has " + badFiles.size() + " bad files. Expecting 1.",badFiles.size() == 1);
    assertTrue("Namenode is not in safe mode",cluster.getNameNode().isInSafeMode());
    cluster.getNameNodeRpc().setSafeMode(HdfsConstants.SafeModeAction.SAFEMODE_LEAVE,false);
    util.cleanup(fs,"/srcdat10");
  }
 catch (  Exception e) {
    LOG.error(StringUtils.stringifyException(e));
    throw e;
  }
 finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
