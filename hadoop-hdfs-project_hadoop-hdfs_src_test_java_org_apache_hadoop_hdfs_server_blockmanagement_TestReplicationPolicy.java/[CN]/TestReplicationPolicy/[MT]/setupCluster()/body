{
  Configuration conf=new HdfsConfiguration();
  dataNodes=new DatanodeDescriptor[]{new DatanodeDescriptor(new DatanodeID("1.1.1.1",5020),"/d1/r1"),new DatanodeDescriptor(new DatanodeID("2.2.2.2",5020),"/d1/r1"),new DatanodeDescriptor(new DatanodeID("3.3.3.3",5020),"/d1/r2"),new DatanodeDescriptor(new DatanodeID("4.4.4.4",5020),"/d1/r2"),new DatanodeDescriptor(new DatanodeID("5.5.5.5",5020),"/d2/r3"),new DatanodeDescriptor(new DatanodeID("6.6.6.6",5020),"/d2/r3")};
  FileSystem.setDefaultUri(conf,"hdfs://localhost:0");
  conf.set(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY,"0.0.0.0:0");
  File baseDir=new File(System.getProperty("test.build.data","build/test/data"),"dfs/");
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,new File(baseDir,"name").getPath());
  DFSTestUtil.formatNameNode(conf);
  namenode=new NameNode(conf);
  final BlockManager bm=namenode.getNamesystem().getBlockManager();
  replicator=bm.getBlockPlacementPolicy();
  cluster=bm.getDatanodeManager().getNetworkTopology();
  for (int i=0; i < NUM_OF_DATANODES; i++) {
    cluster.add(dataNodes[i]);
  }
  for (int i=0; i < NUM_OF_DATANODES; i++) {
    dataNodes[i].updateHeartbeat(2 * HdfsConstants.MIN_BLOCKS_FOR_WRITE * BLOCK_SIZE,0L,2 * HdfsConstants.MIN_BLOCKS_FOR_WRITE * BLOCK_SIZE,0L,0,0);
  }
}
