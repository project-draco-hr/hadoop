{
  Configuration conf=new HdfsConfiguration();
  final String[] racks={"/d1/r1","/d1/r1","/d1/r2","/d1/r2","/d2/r3","/d2/r3"};
  storages=DFSTestUtil.createDatanodeStorageInfos(racks);
  dataNodes=DFSTestUtil.toDatanodeDescriptor(storages);
  DatanodeStorage extraStorage=new DatanodeStorage(storages[5].getStorageID() + "-extra",DatanodeStorage.State.NORMAL,StorageType.DEFAULT);
  BlockManagerTestUtil.updateStorage(storages[5].getDatanodeDescriptor(),extraStorage);
  FileSystem.setDefaultUri(conf,"hdfs://localhost:0");
  conf.set(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY,"0.0.0.0:0");
  File baseDir=PathUtils.getTestDir(TestReplicationPolicy.class);
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,new File(baseDir,"name").getPath());
  conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_READ_KEY,true);
  conf.setBoolean(DFSConfigKeys.DFS_NAMENODE_AVOID_STALE_DATANODE_FOR_WRITE_KEY,true);
  DFSTestUtil.formatNameNode(conf);
  namenode=new NameNode(conf);
  final BlockManager bm=namenode.getNamesystem().getBlockManager();
  replicator=bm.getBlockPlacementPolicy();
  cluster=bm.getDatanodeManager().getNetworkTopology();
  for (int i=0; i < NUM_OF_DATANODES; i++) {
    cluster.add(dataNodes[i]);
    bm.getDatanodeManager().getHeartbeatManager().addDatanode(dataNodes[i]);
  }
  resetHeartbeatForStorages();
}
