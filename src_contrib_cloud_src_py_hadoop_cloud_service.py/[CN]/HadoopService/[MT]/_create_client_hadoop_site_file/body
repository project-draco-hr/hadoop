def _create_client_hadoop_site_file(self, config_dir):
    namenode = self._get_namenode()
    jobtracker = self._get_jobtracker()
    cluster_dir = os.path.join(config_dir, self.cluster.name)
    aws_access_key_id = os.environ['AWS_ACCESS_KEY_ID']
    aws_secret_access_key = os.environ['AWS_SECRET_ACCESS_KEY']
    if (not os.path.exists(cluster_dir)):
        os.makedirs(cluster_dir)
    with open(os.path.join(cluster_dir, 'hadoop-site.xml'), 'w') as f:
        f.write(('<?xml version="1.0"?>\n  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>\n  <!-- Put site-specific property overrides in this file. -->\n  <configuration>\n  <property>\n    <name>hadoop.job.ugi</name>\n    <value>root,root</value>\n  </property>\n  <property>\n    <name>fs.default.name</name>\n    <value>hdfs://%(namenode)s:8020/</value>\n  </property>\n  <property>\n    <name>mapred.job.tracker</name>\n    <value>%(jobtracker)s:8021</value>\n  </property>\n  <property>\n    <name>hadoop.socks.server</name>\n    <value>localhost:6666</value>\n  </property>\n  <property>\n    <name>hadoop.rpc.socket.factory.class.default</name>\n    <value>org.apache.hadoop.net.SocksSocketFactory</value>\n  </property>\n  <property>\n    <name>fs.s3.awsAccessKeyId</name>\n    <value>%(aws_access_key_id)s</value>\n  </property>\n  <property>\n    <name>fs.s3.awsSecretAccessKey</name>\n    <value>%(aws_secret_access_key)s</value>\n  </property>\n  <property>\n    <name>fs.s3n.awsAccessKeyId</name>\n    <value>%(aws_access_key_id)s</value>\n  </property>\n  <property>\n    <name>fs.s3n.awsSecretAccessKey</name>\n    <value>%(aws_secret_access_key)s</value>\n  </property>\n  </configuration>\n  ' % {'namenode': namenode.public_ip, 'jobtracker': jobtracker.public_ip, 'aws_access_key_id': aws_access_key_id, 'aws_secret_access_key': aws_secret_access_key, }))
