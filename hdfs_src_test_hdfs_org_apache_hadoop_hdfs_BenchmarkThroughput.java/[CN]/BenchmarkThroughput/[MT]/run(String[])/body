{
  Log hadoopLog=LogFactory.getLog("org");
  if (hadoopLog instanceof Log4JLogger) {
    ((Log4JLogger)hadoopLog).getLogger().setLevel(Level.WARN);
  }
  int reps=1;
  if (args.length == 1) {
    try {
      reps=Integer.parseInt(args[0]);
    }
 catch (    NumberFormatException e) {
      printUsage();
      return -1;
    }
  }
 else   if (args.length > 1) {
    printUsage();
    return -1;
  }
  Configuration conf=getConf();
  long SIZE=conf.getLong("dfsthroughput.file.size",10L * 1024 * 1024* 1024);
  BUFFER_SIZE=conf.getInt("dfsthroughput.buffer.size",4 * 1024);
  String localDir=conf.get("mapred.temp.dir");
  dir=new LocalDirAllocator("mapred.temp.dir");
  System.setProperty("test.build.data",localDir);
  System.out.println("Local = " + localDir);
  ChecksumFileSystem checkedLocal=FileSystem.getLocal(conf);
  FileSystem rawLocal=checkedLocal.getRawFileSystem();
  for (int i=0; i < reps; ++i) {
    writeAndReadLocalFile("local",conf,SIZE);
    writeAndReadFile(rawLocal,"raw",conf,SIZE);
    writeAndReadFile(checkedLocal,"checked",conf,SIZE);
  }
  MiniDFSCluster cluster=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).racks(new String[]{"/foo"}).build();
    cluster.waitActive();
    FileSystem dfs=cluster.getFileSystem();
    for (int i=0; i < reps; ++i) {
      writeAndReadFile(dfs,"dfs",conf,SIZE);
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
      rawLocal.delete(new Path(localDir,"dfs"),true);
    }
  }
  return 0;
}
