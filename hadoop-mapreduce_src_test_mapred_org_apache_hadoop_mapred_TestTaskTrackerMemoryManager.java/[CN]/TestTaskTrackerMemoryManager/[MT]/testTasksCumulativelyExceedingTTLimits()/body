{
  if (!isProcfsBasedTreeAvailable()) {
    return;
  }
  long PER_TASK_LIMIT=100 * 1024L;
  JobConf fConf=new JobConf();
  fConf.setLong(MRConfig.MAPMEMORY_MB,1L);
  fConf.setLong(MRConfig.REDUCEMEMORY_MB,1L);
  long TASK_TRACKER_LIMIT=2 * 1024 * 1024L;
  fConf.setInt(TTConfig.TT_MEMORY_MANAGER_MONITORING_INTERVAL,100);
  startCluster(fConf);
  Pattern taskOverLimitPattern=Pattern.compile(String.format(taskOverLimitPatternString,String.valueOf(PER_TASK_LIMIT)));
  Pattern trackerOverLimitPattern=Pattern.compile("Killing one of the least progress tasks - .*, as " + "the cumulative memory usage of all the tasks on the TaskTracker" + " exceeds virtual memory limit " + TASK_TRACKER_LIMIT + ".");
  Matcher mat=null;
  JobConf conf=new JobConf(miniMRCluster.createJobConf());
  conf.setMemoryForMapTask(PER_TASK_LIMIT);
  conf.setMemoryForReduceTask(PER_TASK_LIMIT);
  JobClient jClient=new JobClient(conf);
  SleepJob sleepJob=new SleepJob();
  sleepJob.setConf(conf);
  Job job=sleepJob.createJob(1,1,5000,1,1000,1);
  job.submit();
  boolean TTOverFlowMsgPresent=false;
  while (true) {
    List<TaskReport> allTaskReports=new ArrayList<TaskReport>();
    allTaskReports.addAll(Arrays.asList(jClient.getSetupTaskReports(JobID.downgrade(job.getJobID()))));
    allTaskReports.addAll(Arrays.asList(jClient.getMapTaskReports(JobID.downgrade(job.getJobID()))));
    for (    TaskReport tr : allTaskReports) {
      String[] diag=tr.getDiagnostics();
      for (      String str : diag) {
        mat=taskOverLimitPattern.matcher(str);
        assertFalse(mat.find());
        mat=trackerOverLimitPattern.matcher(str);
        if (mat.find()) {
          TTOverFlowMsgPresent=true;
        }
      }
    }
    if (TTOverFlowMsgPresent) {
      break;
    }
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
    }
  }
  job.killJob();
}
