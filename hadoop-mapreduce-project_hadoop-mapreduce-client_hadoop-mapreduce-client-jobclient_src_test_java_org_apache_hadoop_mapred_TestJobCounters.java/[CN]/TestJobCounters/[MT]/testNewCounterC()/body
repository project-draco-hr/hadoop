{
  final Job job=createJob();
  final Configuration conf=job.getConfiguration();
  conf.setInt(JobContext.IO_SORT_FACTOR,3);
  createWordsFile(inFiles[3],conf);
  createWordsFile(inFiles[4],conf);
  long inputSize=0;
  inputSize+=getFileSize(inFiles[0]);
  inputSize+=getFileSize(inFiles[1]);
  inputSize+=getFileSize(inFiles[2]);
  inputSize+=getFileSize(inFiles[3]);
  inputSize+=getFileSize(inFiles[4]);
  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,IN_DIR);
  org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(OUT_DIR,"outputN2"));
  assertTrue(job.waitForCompletion(true));
  final Counters c1=Counters.downgrade(job.getCounters());
  validateCounters(c1,122880,25600,102400);
  validateFileCounters(c1,inputSize,0,0,0);
}
