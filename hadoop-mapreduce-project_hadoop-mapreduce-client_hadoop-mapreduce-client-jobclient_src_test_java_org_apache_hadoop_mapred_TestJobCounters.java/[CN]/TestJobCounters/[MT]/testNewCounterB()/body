{
  final Job job=createJob();
  final Configuration conf=job.getConfiguration();
  conf.setInt(JobContext.IO_SORT_FACTOR,2);
  createWordsFile(inFiles[3],conf);
  removeWordsFile(inFiles[4],conf);
  long inputSize=0;
  inputSize+=getFileSize(inFiles[0]);
  inputSize+=getFileSize(inFiles[1]);
  inputSize+=getFileSize(inFiles[2]);
  inputSize+=getFileSize(inFiles[3]);
  org.apache.hadoop.mapreduce.lib.input.FileInputFormat.setInputPaths(job,IN_DIR);
  org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.setOutputPath(job,new Path(OUT_DIR,"outputN1"));
  assertTrue(job.waitForCompletion(true));
  final Counters c1=Counters.downgrade(job.getCounters());
  validateCounters(c1,98304,20480,81920);
  validateFileCounters(c1,inputSize,0,0,0);
}
