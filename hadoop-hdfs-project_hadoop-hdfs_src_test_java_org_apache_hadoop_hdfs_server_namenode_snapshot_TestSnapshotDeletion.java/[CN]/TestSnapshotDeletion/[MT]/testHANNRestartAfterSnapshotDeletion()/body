{
  hdfs.close();
  cluster.shutdown();
  conf=new Configuration();
  cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(1).build();
  cluster.transitionToActive(0);
  NameNode snn=cluster.getNameNode(1);
  snn.stop();
  hdfs=(DistributedFileSystem)HATestUtil.configureFailoverFs(cluster,conf);
  Path dir=new Path("/dir");
  Path subDir=new Path(dir,"sub");
  hdfs.mkdirs(dir);
  hdfs.allowSnapshot(dir);
  for (int i=0; i < 5; i++) {
    DFSTestUtil.createFile(hdfs,new Path(subDir,"" + i),100,(short)1,1024L);
  }
  hdfs.createSnapshot(dir,"s0");
  hdfs.delete(subDir,true);
  NameNode ann=cluster.getNameNode(0);
  ann.getRpcServer().rollEditLog();
  hdfs.deleteSnapshot(dir,"s0");
  Thread.sleep(2000);
  NameNodeAdapter.abortEditLogs(ann);
  cluster.restartNameNode(0,false);
  cluster.transitionToActive(0);
  cluster.waitClusterUp();
}
