def main():
    logging.basicConfig(level=getattr(logging, os.getenv('HADOOP_CLOUD_LOGGING_LEVEL', 'INFO')))
    if (len(sys.argv) < 2):
        print_usage(sys.argv[0])
        sys.exit(1)
    command = sys.argv[1]
    if (command == 'list'):
        (opt, args) = parse_options(command, BASIC_OPTIONS, unbounded_args=True)
        if (len(args) == 0):
            commands.list_all(get_cloud_provider(opt))
        else:
            (opt, args, cluster) = parse_options_and_config(command, BASIC_OPTIONS)
            commands.list_cluster(cluster)
    elif (command == 'launch-master'):
        (opt, args, cluster) = parse_options_and_config(command, LAUNCH_OPTIONS)
        check_launch_options_set(cluster, opt)
        config_dir = get_config_dir(opt)
        commands.launch_master(cluster, config_dir, get_image_id(cluster, opt), opt.get('instance_type'), opt.get('key_name'), opt.get('public_key'), opt.get('user_data_file'), opt.get('availability_zone'), opt.get('user_packages'), opt.get('auto_shutdown'), opt.get('env'), opt.get('client_cidr'))
        commands.attach_storage(cluster, (commands.MASTER,))
        try:
            commands.wait_for_hadoop(cluster, 0)
        except TimeoutException:
            print ('Timeout while waiting for Hadoop to start. Please check logs on' + ' master.')
        commands.print_master_url(cluster)
    elif (command == 'launch-slaves'):
        (opt, args, cluster) = parse_options_and_config(command, LAUNCH_OPTIONS, ('NUM_SLAVES',))
        number_of_slaves = int(args[1])
        check_launch_options_set(cluster, opt)
        config_dir = get_config_dir(opt)
        commands.launch_slaves(cluster, number_of_slaves, get_image_id(cluster, opt), opt.get('instance_type'), opt.get('key_name'), opt.get('public_key'), opt.get('user_data_file'), opt.get('availability_zone'), opt.get('user_packages'), opt.get('auto_shutdown'), opt.get('env'))
        commands.attach_storage(cluster, (commands.SLAVE,))
        commands.print_master_url(cluster)
    elif (command == 'launch-cluster'):
        (opt, args, cluster) = parse_options_and_config(command, LAUNCH_OPTIONS, ('NUM_SLAVES',))
        number_of_slaves = int(args[1])
        check_launch_options_set(cluster, opt)
        config_dir = get_config_dir(opt)
        commands.launch_master(cluster, config_dir, get_image_id(cluster, opt), opt.get('instance_type'), opt.get('key_name'), opt.get('public_key'), opt.get('user_data_file'), opt.get('availability_zone'), opt.get('user_packages'), opt.get('auto_shutdown'), opt.get('env'), opt.get('client_cidr'))
        commands.launch_slaves(cluster, number_of_slaves, get_image_id(cluster, opt), opt.get('instance_type'), opt.get('key_name'), opt.get('public_key'), opt.get('user_data_file'), opt.get('availability_zone'), opt.get('user_packages'), opt.get('auto_shutdown'), opt.get('env'))
        commands.attach_storage(cluster, commands.ROLES)
        try:
            commands.wait_for_hadoop(cluster, number_of_slaves)
        except TimeoutException:
            print ('Timeout while waiting for Hadoop to start. Please check logs on' + ' cluster.')
        commands.print_master_url(cluster)
    elif (command == 'login'):
        (opt, args, cluster) = parse_options_and_config(command, SSH_OPTIONS)
        instances = cluster.check_running(commands.MASTER, 1)
        if (not instances):
            sys.exit(1)
        subprocess.call(('ssh %s root@%s' % (xstr(opt.get('ssh_options')), instances[0].public_ip)), shell=True)
    elif (command == 'proxy'):
        (opt, args, cluster) = parse_options_and_config(command, SSH_OPTIONS)
        instances = cluster.check_running(commands.MASTER, 1)
        if (not instances):
            sys.exit(1)
        options = '-o "ConnectTimeout 10" -o "ServerAliveInterval 60" -N -D 6666'
        process = subprocess.Popen(('ssh %s %s root@%s' % (xstr(opt.get('ssh_options')), options, instances[0].public_ip)), stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
        print ('export HADOOP_CLOUD_PROXY_PID=%s;\necho Proxy pid %s;' % (process.pid, process.pid))
    elif (command == 'push'):
        (opt, args, cluster) = parse_options_and_config(command, SSH_OPTIONS, ('FILE',))
        instances = cluster.check_running(commands.MASTER, 1)
        if (not instances):
            sys.exit(1)
        subprocess.call(('scp %s -r %s root@%s:' % (xstr(opt.get('ssh_options')), args[1], instances[0].public_ip)), shell=True)
    elif (command == 'exec'):
        (opt, args, cluster) = parse_options_and_config(command, SSH_OPTIONS, ('CMD',), True)
        instances = cluster.check_running(commands.MASTER, 1)
        if (not instances):
            sys.exit(1)
        subprocess.call(("ssh %s root@%s '%s'" % (xstr(opt.get('ssh_options')), instances[0].public_ip, ' '.join(args[1:]))), shell=True)
    elif (command == 'terminate-cluster'):
        (opt, args, cluster) = parse_options_and_config(command, FORCE_OPTIONS)
        cluster.print_status(commands.ROLES)
        if ((not opt['force']) and (not _prompt('Terminate all instances?'))):
            print 'Not terminating cluster.'
        else:
            print 'Terminating cluster'
            cluster.terminate()
    elif (command == 'delete-cluster'):
        (opt, args, cluster) = parse_options_and_config(command, BASIC_OPTIONS)
        cluster.delete()
    elif (command == 'create-formatted-snapshot'):
        (opt, args, cluster) = parse_options_and_config(command, SNAPSHOT_OPTIONS, ('SIZE',))
        size = int(args[1])
        check_options_set(opt, ['availability_zone', 'key_name'])
        ami_ubuntu_intrepid_x86 = 'ami-ec48af85'
        Ec2Storage.create_formatted_snapshot(cluster, size, opt.get('availability_zone'), ami_ubuntu_intrepid_x86, opt.get('key_name'), xstr(opt.get('ssh_options')))
    elif (command == 'list-storage'):
        (opt, args, cluster) = parse_options_and_config(command, BASIC_OPTIONS)
        storage = cluster.get_storage()
        storage.print_status(commands.ROLES)
    elif (command == 'create-storage'):
        (opt, args, cluster) = parse_options_and_config(command, PLACEMENT_OPTIONS, ('ROLE', 'NUM_INSTANCES', 'SPEC_FILE'))
        storage = cluster.get_storage()
        role = args[1]
        number_of_instances = int(args[2])
        spec_file = args[3]
        check_options_set(opt, ['availability_zone'])
        storage.create(role, number_of_instances, opt.get('availability_zone'), spec_file)
        storage.print_status(commands.ROLES)
    elif (command == 'attach-storage'):
        (opt, args, cluster) = parse_options_and_config(command, BASIC_OPTIONS, ('ROLE',))
        storage = cluster.get_storage()
        role = args[1]
        storage.attach(role, cluster.get_instances_in_role(role, 'running'))
        storage.print_status(commands.ROLES)
    elif (command == 'delete-storage'):
        (opt, args, cluster) = parse_options_and_config(command, FORCE_OPTIONS)
        storage = cluster.get_storage()
        storage.print_status(commands.ROLES)
        if ((not opt['force']) and (not _prompt('Delete all storage volumes? THIS WILL       PERMANENTLY DELETE ALL DATA'))):
            print 'Not deleting storage volumes.'
        else:
            print 'Deleting storage'
            for role in commands.ROLES:
                storage.delete(role)
    elif (command == 'update-slaves-file'):
        (opt, args, cluster) = parse_options_and_config(command, SSH_OPTIONS)
        check_options_set(opt, ['private_key'])
        ssh_options = xstr(opt.get('ssh_options'))
        instances = cluster.check_running(commands.MASTER, 1)
        if (not instances):
            sys.exit(1)
        master = instances[0]
        slaves = cluster.get_instances_in_role(commands.SLAVE)
        with open('slaves', 'w') as f:
            for slave in slaves:
                f.write((slave.public_ip + '\n'))
        subprocess.call(('scp %s -r %s root@%s:/etc/hadoop/conf' % (ssh_options, 'slaves', master.public_ip)), shell=True)
        private_key = opt.get('private_key')
        subprocess.call(('scp %s -r %s root@%s:/root/.ssh/id_rsa' % (ssh_options, private_key, master.public_ip)), shell=True)
        for slave in slaves:
            subprocess.call(('scp %s -r %s root@%s:/root/.ssh/id_rsa' % (ssh_options, private_key, slave.public_ip)), shell=True)
    else:
        print ("Unrecognized command '%s'" % command)
        print_usage(sys.argv[0])
        sys.exit(1)
