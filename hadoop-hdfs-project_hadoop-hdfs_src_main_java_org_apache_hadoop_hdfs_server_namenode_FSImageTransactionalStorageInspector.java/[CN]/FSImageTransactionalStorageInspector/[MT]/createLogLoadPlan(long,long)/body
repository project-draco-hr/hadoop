{
  long expectedTxId=sinceTxId + 1;
  List<EditLogFile> recoveryLogs=new ArrayList<EditLogFile>();
  SortedMap<Long,LogGroup> tailGroups=logGroups.tailMap(expectedTxId);
  if (logGroups.size() > tailGroups.size()) {
    LOG.debug("Excluded " + (logGroups.size() - tailGroups.size()) + " groups of logs because they start with a txid less than image "+ "txid "+ sinceTxId);
  }
  SortedMap<Long,LogGroup> usefulGroups;
  if (maxStartTxId > sinceTxId) {
    usefulGroups=tailGroups.headMap(maxStartTxId);
  }
 else {
    usefulGroups=new TreeMap<Long,LogGroup>();
  }
  if (usefulGroups.size() > tailGroups.size()) {
    LOG.debug("Excluded " + (tailGroups.size() - usefulGroups.size()) + " groups of logs because they start with a txid higher than max "+ "txid "+ sinceTxId);
  }
  for (  Map.Entry<Long,LogGroup> entry : usefulGroups.entrySet()) {
    long logStartTxId=entry.getKey();
    LogGroup logGroup=entry.getValue();
    logGroup.planRecovery();
    if (expectedTxId != HdfsConstants.INVALID_TXID && logStartTxId != expectedTxId) {
      throw new IOException("Expected next log group would start at txid " + expectedTxId + " but starts at txid "+ logStartTxId);
    }
    recoveryLogs.add(logGroup.getBestNonCorruptLog());
    if (logGroup.hasKnownLastTxId()) {
      expectedTxId=logGroup.getLastTxId() + 1;
    }
 else {
      expectedTxId=HdfsConstants.INVALID_TXID;
    }
  }
  long lastLogGroupStartTxId=usefulGroups.isEmpty() ? 0 : usefulGroups.lastKey();
  if (maxSeenTxId > sinceTxId && maxSeenTxId > lastLogGroupStartTxId) {
    String msg="At least one storage directory indicated it has seen a " + "log segment starting at txid " + maxSeenTxId;
    if (usefulGroups.isEmpty()) {
      msg+=" but there are no logs to load.";
    }
 else {
      msg+=" but the most recent log file found starts with txid " + lastLogGroupStartTxId;
    }
    throw new IOException(msg);
  }
  return new LogLoadPlan(recoveryLogs,Lists.newArrayList(usefulGroups.values()));
}
