{
  ApplicationSubmissionContext appContext=recordFactory.newRecordInstance(ApplicationSubmissionContext.class);
  ApplicationId applicationId=resMgrDelegate.getApplicationId();
  appContext.setApplicationId(applicationId);
  Resource capability=recordFactory.newRecordInstance(Resource.class);
  capability.setMemory(conf.getInt(MRJobConfig.MR_AM_VMEM_MB,MRJobConfig.DEFAULT_MR_AM_VMEM_MB));
  LOG.info("AppMaster capability = " + capability);
  appContext.setMasterCapability(capability);
  Path jobConfPath=new Path(jobSubmitDir,MRConstants.JOB_CONF_FILE);
  URL yarnUrlForJobSubmitDir=ConverterUtils.getYarnUrlFromPath(defaultFileContext.getDefaultFileSystem().resolvePath(defaultFileContext.makeQualified(new Path(jobSubmitDir))));
  LOG.debug("Creating setup context, jobSubmitDir url is " + yarnUrlForJobSubmitDir);
  appContext.setResource(MRConstants.JOB_SUBMIT_DIR,yarnUrlForJobSubmitDir);
  appContext.setResourceTodo(MRConstants.JOB_CONF_FILE,createApplicationResource(defaultFileContext,jobConfPath));
  if (jobConf.get(MRJobConfig.JAR) != null) {
    appContext.setResourceTodo(MRConstants.JOB_JAR,createApplicationResource(defaultFileContext,new Path(jobSubmitDir,MRConstants.JOB_JAR)));
  }
 else {
    LOG.info("Job jar is not present. " + "Not adding any jar to the list of resources.");
  }
  for (  String s : new String[]{"job.split","job.splitmetainfo",MRConstants.APPLICATION_TOKENS_FILE}) {
    appContext.setResourceTodo(MRConstants.JOB_SUBMIT_DIR + "/" + s,createApplicationResource(defaultFileContext,new Path(jobSubmitDir,s)));
  }
  List<String> fsTokens=new ArrayList<String>();
  for (  Token<? extends TokenIdentifier> token : ts.getAllTokens()) {
    fsTokens.add(token.encodeToUrlString());
  }
  appContext.addAllFsTokens(fsTokens);
  DataOutputBuffer dob=new DataOutputBuffer();
  ts.writeTokenStorageToStream(dob);
  appContext.setFsTokensTodo(ByteBuffer.wrap(dob.getData(),0,dob.getLength()));
  appContext.setQueue(jobConf.get(JobContext.QUEUE_NAME,JobConf.DEFAULT_QUEUE_NAME));
  appContext.setApplicationName(jobConf.get(JobContext.JOB_NAME,"N/A"));
  String javaHome="$JAVA_HOME";
  Vector<CharSequence> vargs=new Vector<CharSequence>(8);
  vargs.add(javaHome + "/bin/java");
  vargs.add("-Dhadoop.root.logger=" + conf.get(MRJobConfig.MR_AM_LOG_OPTS,MRJobConfig.DEFAULT_MR_AM_LOG_OPTS) + ",console");
  vargs.add(conf.get(MRJobConfig.MR_AM_COMMAND_OPTS,MRJobConfig.DEFAULT_MR_AM_COMMAND_OPTS));
  Map<String,String> environment=new HashMap<String,String>();
  MRApps.setInitialClasspath(environment);
  MRApps.addToClassPath(environment,MRConstants.JOB_JAR);
  MRApps.addToClassPath(environment,MRConstants.YARN_MAPREDUCE_APP_JAR_PATH);
  appContext.addAllEnvironment(environment);
  vargs.add("org.apache.hadoop.mapreduce.v2.app.MRAppMaster");
  vargs.add(String.valueOf(applicationId.getClusterTimestamp()));
  vargs.add(String.valueOf(applicationId.getId()));
  vargs.add(ApplicationConstants.AM_FAIL_COUNT_STRING);
  vargs.add("1>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/stdout");
  vargs.add("2>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/stderr");
  Vector<String> vargsFinal=new Vector<String>(8);
  StringBuilder mergedCommand=new StringBuilder();
  for (  CharSequence str : vargs) {
    mergedCommand.append(str).append(" ");
  }
  vargsFinal.add(mergedCommand.toString());
  LOG.info("Command to launch container for ApplicationMaster is : " + mergedCommand);
  appContext.addAllCommands(vargsFinal);
  appContext.setUser(UserGroupInformation.getCurrentUser().getShortUserName());
  return appContext;
}
