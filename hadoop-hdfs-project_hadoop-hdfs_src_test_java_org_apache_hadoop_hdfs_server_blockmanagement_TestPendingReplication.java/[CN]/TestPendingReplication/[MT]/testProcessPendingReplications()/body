{
  final Configuration conf=new HdfsConfiguration();
  conf.setLong(DFSConfigKeys.DFS_NAMENODE_REPLICATION_PENDING_TIMEOUT_SEC_KEY,TIMEOUT);
  MiniDFSCluster cluster=null;
  Block block;
  BlockInfo blockInfo;
  try {
    cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_COUNT).build();
    cluster.waitActive();
    FSNamesystem fsn=cluster.getNamesystem();
    BlockManager blkManager=fsn.getBlockManager();
    PendingReplicationBlocks pendingReplications=blkManager.pendingReplications;
    UnderReplicatedBlocks neededReplications=blkManager.neededReplications;
    BlocksMap blocksMap=blkManager.blocksMap;
    block=new Block(1,1,0);
    blockInfo=new BlockInfoContiguous(block,(short)3);
    pendingReplications.increment(blockInfo,DatanodeStorageInfo.toDatanodeDescriptors(DFSTestUtil.createDatanodeStorageInfos(1)));
    BlockCollection bc=Mockito.mock(BlockCollection.class);
    blockInfo.setGenerationStamp(1);
    blocksMap.addBlockCollection(blockInfo,bc);
    assertEquals("Size of pendingReplications ",1,pendingReplications.size());
    block=new Block(2,2,0);
    blockInfo=new BlockInfoContiguous(block,(short)3);
    pendingReplications.increment(blockInfo,DatanodeStorageInfo.toDatanodeDescriptors(DFSTestUtil.createDatanodeStorageInfos(1)));
    assertEquals("Size of pendingReplications ",2,pendingReplications.size());
    while (pendingReplications.size() > 0) {
      try {
        Thread.sleep(100);
      }
 catch (      Exception e) {
      }
    }
    while (neededReplications.size() == 0) {
      try {
        Thread.sleep(100);
      }
 catch (      Exception e) {
      }
    }
    for (    Block b : neededReplications) {
      assertEquals("Generation stamp is 1 ",1,b.getGenerationStamp());
    }
    assertEquals("size of neededReplications is 1 ",1,neededReplications.size());
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
