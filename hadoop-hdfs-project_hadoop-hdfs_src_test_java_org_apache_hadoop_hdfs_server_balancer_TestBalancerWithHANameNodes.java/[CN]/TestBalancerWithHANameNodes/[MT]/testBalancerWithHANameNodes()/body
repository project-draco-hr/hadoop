{
  Configuration conf=new HdfsConfiguration();
  TestBalancer.initConf(conf);
  long newNodeCapacity=TestBalancer.CAPACITY;
  String newNodeRack=TestBalancer.RACK2;
  String[] racks=new String[]{TestBalancer.RACK0,TestBalancer.RACK1};
  long[] capacities=new long[]{TestBalancer.CAPACITY,TestBalancer.CAPACITY};
  assertEquals(capacities.length,racks.length);
  int numOfDatanodes=capacities.length;
  NNConf nn1Conf=new MiniDFSNNTopology.NNConf("nn1");
  nn1Conf.setIpcPort(NameNode.DEFAULT_PORT);
  MiniDFSNNTopology simpleHATopology=new MiniDFSNNTopology().addNameservice(new MiniDFSNNTopology.NSConf(null).addNN(nn1Conf).addNN(new MiniDFSNNTopology.NNConf("nn2")));
  cluster=new MiniDFSCluster.Builder(conf).nnTopology(simpleHATopology).numDataNodes(capacities.length).racks(racks).simulatedCapacities(capacities).build();
  try {
    cluster.waitActive();
    cluster.transitionToActive(1);
    Thread.sleep(500);
    client=DFSUtil.createNamenode(cluster.getNameNode(1).getNameNodeAddress(),conf);
    long totalCapacity=TestBalancer.sum(capacities);
    long totalUsedSpace=totalCapacity * 3 / 10;
    TestBalancer.createFile(cluster,TestBalancer.filePath,totalUsedSpace / numOfDatanodes,(short)numOfDatanodes,1);
    cluster.startDataNodes(conf,1,true,null,new String[]{newNodeRack},new long[]{newNodeCapacity});
    HATestUtil.setFailoverConfigurations(cluster,conf,NameNode.getUri(cluster.getNameNode(0).getNameNodeAddress()).getHost());
    totalCapacity+=newNodeCapacity;
    TestBalancer.waitForHeartBeat(totalUsedSpace,totalCapacity,client,cluster);
    Map<String,Map<String,InetSocketAddress>> namenodes=DFSUtil.getNNServiceRpcAddresses(conf);
    final int r=Balancer.run(namenodes,Balancer.Parameters.DEFALUT,conf);
    assertEquals(Balancer.ReturnStatus.SUCCESS.code,r);
    TestBalancer.waitForBalancer(totalUsedSpace,totalCapacity,client,cluster);
  }
  finally {
    cluster.shutdown();
  }
}
