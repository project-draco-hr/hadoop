{
  int eventsPerReducer=Math.max(MIN_EVENTS_TO_FETCH,MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());
  int maxEventsToFetch=Math.min(MAX_EVENTS_TO_FETCH,eventsPerReducer);
  final EventFetcher<K,V> eventFetcher=new EventFetcher<K,V>(reduceId,umbilical,scheduler,this,maxEventsToFetch);
  eventFetcher.start();
  boolean isLocal=localMapFiles != null;
  final int numFetchers=isLocal ? 1 : jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES,5);
  Fetcher<K,V>[] fetchers=new Fetcher[numFetchers];
  if (isLocal) {
    fetchers[0]=new LocalFetcher<K,V>(jobConf,reduceId,scheduler,merger,reporter,metrics,this,reduceTask.getShuffleSecret(),localMapFiles);
    fetchers[0].start();
  }
 else {
    for (int i=0; i < numFetchers; ++i) {
      fetchers[i]=new Fetcher<K,V>(jobConf,reduceId,scheduler,merger,reporter,metrics,this,reduceTask.getShuffleSecret());
      fetchers[i].start();
    }
  }
  while (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) {
    reporter.progress();
synchronized (this) {
      if (throwable != null) {
        throw new ShuffleError("error in shuffle in " + throwingThreadName,throwable);
      }
    }
  }
  eventFetcher.shutDown();
  for (  Fetcher<K,V> fetcher : fetchers) {
    fetcher.shutDown();
  }
  scheduler.close();
  copyPhase.complete();
  taskStatus.setPhase(TaskStatus.Phase.SORT);
  reduceTask.statusUpdate(umbilical);
  RawKeyValueIterator kvIter=null;
  try {
    kvIter=merger.close();
  }
 catch (  Throwable e) {
    throw new ShuffleError("Error while doing final merge ",e);
  }
synchronized (this) {
    if (throwable != null) {
      throw new ShuffleError("error in shuffle in " + throwingThreadName,throwable);
    }
  }
  return kvIter;
}
