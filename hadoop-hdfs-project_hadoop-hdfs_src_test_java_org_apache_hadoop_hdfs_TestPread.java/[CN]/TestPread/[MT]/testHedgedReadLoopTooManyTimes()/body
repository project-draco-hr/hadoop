{
  Configuration conf=new Configuration();
  int numHedgedReadPoolThreads=5;
  final int hedgedReadTimeoutMillis=50;
  conf.setInt(DFSConfigKeys.DFS_DFSCLIENT_HEDGED_READ_THREADPOOL_SIZE,numHedgedReadPoolThreads);
  conf.setLong(DFSConfigKeys.DFS_DFSCLIENT_HEDGED_READ_THRESHOLD_MILLIS,hedgedReadTimeoutMillis);
  conf.setInt(DFSConfigKeys.DFS_CLIENT_RETRY_WINDOW_BASE,0);
  DFSClientFaultInjector.instance=Mockito.mock(DFSClientFaultInjector.class);
  DFSClientFaultInjector injector=DFSClientFaultInjector.instance;
  Mockito.doAnswer(new Answer<Void>(){
    @Override public Void answer(    InvocationOnMock invocation) throws Throwable {
      if (true) {
        Thread.sleep(hedgedReadTimeoutMillis + 1);
        if (DFSClientFaultInjector.exceptionNum.compareAndSet(0,1)) {
          System.out.println("-------------- throw Checksum Exception");
          throw new ChecksumException("ChecksumException test",100);
        }
      }
      return null;
    }
  }
).when(injector).fetchFromDatanodeException();
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).format(true).build();
  DistributedFileSystem fileSys=cluster.getFileSystem();
  DFSClient dfsClient=fileSys.getClient();
  FSDataOutputStream output=null;
  DFSInputStream input=null;
  String filename="/hedgedReadMaxOut.dat";
  try {
    Path file=new Path(filename);
    output=fileSys.create(file,(short)2);
    byte[] data=new byte[64 * 1024];
    output.write(data);
    output.flush();
    output.write(data);
    output.flush();
    output.write(data);
    output.flush();
    output.close();
    byte[] buffer=new byte[64 * 1024];
    input=dfsClient.open(filename);
    input.read(0,buffer,0,1024);
    input.close();
    assertEquals(3,input.getHedgedReadOpsLoopNumForTesting());
  }
 catch (  BlockMissingException e) {
    assertTrue(false);
  }
 finally {
    Mockito.reset(injector);
    IOUtils.cleanup(null,input);
    IOUtils.cleanup(null,output);
    fileSys.close();
    cluster.shutdown();
  }
}
