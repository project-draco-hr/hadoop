{
  Configuration conf=new HdfsConfiguration();
  Path file=new Path("/test-file");
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  try {
    FileSystem fs=cluster.getFileSystem();
    NamenodeProtocols namenode=cluster.getNameNodeRpc();
    DFSOutputStream out=null;
    try {
      out=(DFSOutputStream)(fs.create(file).getWrappedStream());
      out.write(1);
      out.hflush();
      SnapshotTestHelper.createSnapshot((DistributedFileSystem)fs,new Path("/"),"s1");
      FSDataInputStream in=null;
      ExtendedBlock oldBlock=null;
      try {
        in=fs.open(file);
        oldBlock=DFSTestUtil.getAllBlocks(in).get(0).getBlock();
      }
  finally {
        IOUtils.closeStream(in);
      }
      String clientName=((DistributedFileSystem)fs).getClient().getClientName();
      LocatedBlock newLocatedBlock=namenode.updateBlockForPipeline(oldBlock,clientName);
      ExtendedBlock newBlock=new ExtendedBlock(oldBlock.getBlockPoolId(),oldBlock.getBlockId(),oldBlock.getNumBytes(),newLocatedBlock.getBlock().getGenerationStamp());
      fs.delete(file,true);
      try {
        namenode.updatePipeline(clientName,oldBlock,newBlock,newLocatedBlock.getLocations(),newLocatedBlock.getStorageIDs());
      }
 catch (      IOException ioe) {
        assertExceptionContains("does not exist or it is not under construction",ioe);
      }
      cluster.restartNameNode(true);
    }
  finally {
      IOUtils.closeStream(out);
    }
  }
  finally {
    cluster.shutdown();
  }
}
