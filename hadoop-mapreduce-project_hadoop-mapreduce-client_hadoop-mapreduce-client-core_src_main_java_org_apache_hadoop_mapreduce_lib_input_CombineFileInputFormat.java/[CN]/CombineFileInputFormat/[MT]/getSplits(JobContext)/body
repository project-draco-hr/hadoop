{
  long minSizeNode=0;
  long minSizeRack=0;
  long maxSize=0;
  Configuration conf=job.getConfiguration();
  if (minSplitSizeNode != 0) {
    minSizeNode=minSplitSizeNode;
  }
 else {
    minSizeNode=conf.getLong(SPLIT_MINSIZE_PERNODE,0);
  }
  if (minSplitSizeRack != 0) {
    minSizeRack=minSplitSizeRack;
  }
 else {
    minSizeRack=conf.getLong(SPLIT_MINSIZE_PERRACK,0);
  }
  if (maxSplitSize != 0) {
    maxSize=maxSplitSize;
  }
 else {
    maxSize=conf.getLong("mapreduce.input.fileinputformat.split.maxsize",0);
  }
  if (minSizeNode != 0 && maxSize != 0 && minSizeNode > maxSize) {
    throw new IOException("Minimum split size pernode " + minSizeNode + " cannot be larger than maximum split size "+ maxSize);
  }
  if (minSizeRack != 0 && maxSize != 0 && minSizeRack > maxSize) {
    throw new IOException("Minimum split size per rack" + minSizeRack + " cannot be larger than maximum split size "+ maxSize);
  }
  if (minSizeRack != 0 && minSizeNode > minSizeRack) {
    throw new IOException("Minimum split size per node" + minSizeNode + " cannot be smaller than minimum split "+ "size per rack "+ minSizeRack);
  }
  List<FileStatus> stats=listStatus(job);
  List<InputSplit> splits=new ArrayList<InputSplit>();
  if (stats.size() == 0) {
    return splits;
  }
  for (  MultiPathFilter onepool : pools) {
    ArrayList<FileStatus> myPaths=new ArrayList<FileStatus>();
    for (Iterator<FileStatus> iter=stats.iterator(); iter.hasNext(); ) {
      FileStatus p=iter.next();
      if (onepool.accept(p.getPath())) {
        myPaths.add(p);
        iter.remove();
      }
    }
    getMoreSplits(job,myPaths,maxSize,minSizeNode,minSizeRack,splits);
  }
  getMoreSplits(job,stats,maxSize,minSizeNode,minSizeRack,splits);
  rackToNodes.clear();
  return splits;
}
