{
  LOG.info("Creating edits by performing fs operations");
  DistributedFileSystem dfs=(DistributedFileSystem)cluster.getFileSystem();
  FileContext fc=FileContext.getFileContext(cluster.getURI(0),config);
  Path pathFileCreate=new Path("/file_create_u\1F431");
  FSDataOutputStream s=dfs.create(pathFileCreate);
  s.close();
  Path pathFileMoved=new Path("/file_moved");
  dfs.rename(pathFileCreate,pathFileMoved);
  dfs.delete(pathFileMoved,false);
  Path pathDirectoryMkdir=new Path("/directory_mkdir");
  dfs.mkdirs(pathDirectoryMkdir);
  dfs.allowSnapshot(pathDirectoryMkdir);
  dfs.disallowSnapshot(pathDirectoryMkdir);
  String ssName="snapshot1";
  dfs.allowSnapshot(pathDirectoryMkdir);
  dfs.createSnapshot(pathDirectoryMkdir,ssName);
  String ssNewName="snapshot2";
  dfs.renameSnapshot(pathDirectoryMkdir,ssName,ssNewName);
  dfs.deleteSnapshot(pathDirectoryMkdir,ssNewName);
  s=dfs.create(pathFileCreate);
  s.close();
  dfs.setReplication(pathFileCreate,(short)1);
  Short permission=0777;
  dfs.setPermission(pathFileCreate,new FsPermission(permission));
  dfs.setOwner(pathFileCreate,new String("newOwner"),null);
  long mtime=1285195527000L;
  long atime=mtime;
  dfs.setTimes(pathFileCreate,mtime,atime);
  dfs.setQuota(pathDirectoryMkdir,1000L,HdfsConstants.QUOTA_DONT_SET);
  fc.rename(pathFileCreate,pathFileMoved,Rename.NONE);
  Path pathConcatTarget=new Path("/file_concat_target");
  Path[] pathConcatFiles=new Path[2];
  pathConcatFiles[0]=new Path("/file_concat_0");
  pathConcatFiles[1]=new Path("/file_concat_1");
  long length=blockSize * 3;
  short replication=1;
  long seed=1;
  DFSTestUtil.createFile(dfs,pathConcatTarget,length,replication,seed);
  DFSTestUtil.createFile(dfs,pathConcatFiles[0],length,replication,seed);
  DFSTestUtil.createFile(dfs,pathConcatFiles[1],length,replication,seed);
  dfs.concat(pathConcatTarget,pathConcatFiles);
  Path pathSymlink=new Path("/file_symlink");
  fc.createSymlink(pathConcatTarget,pathSymlink,false);
  final Token<?>[] tokens=dfs.addDelegationTokens("JobTracker",null);
  UserGroupInformation longUgi=UserGroupInformation.createRemoteUser("JobTracker/foo.com@FOO.COM");
  try {
    longUgi.doAs(new PrivilegedExceptionAction<Object>(){
      @Override public Object run() throws IOException, InterruptedException {
        for (        Token<?> token : tokens) {
          token.renew(config);
          token.cancel(config);
        }
        return null;
      }
    }
);
  }
 catch (  InterruptedException e) {
    throw new IOException("renewDelegationToken threw InterruptedException",e);
  }
  final String pool="poolparty";
  dfs.addCachePool(new CachePoolInfo(pool));
  dfs.modifyCachePool(new CachePoolInfo(pool).setOwnerName("carlton").setGroupName("party").setMode(new FsPermission((short)0700)).setWeight(1989));
  long id=dfs.addPathBasedCacheDirective(new PathBasedCacheDirective.Builder().setPath(new Path("/bar")).setReplication((short)1).setPool(pool).build());
  dfs.modifyPathBasedCacheDirective(new PathBasedCacheDirective.Builder().setId(id).setPath(new Path("/bar2")).build());
  dfs.removePathBasedCacheDirective(id);
  dfs.removeCachePool(pool);
  cluster.getNameNode().getFSImage().getEditLog().logSync();
  String filePath="/hard-lease-recovery-test";
  byte[] bytes="foo-bar-baz".getBytes();
  DFSClientAdapter.stopLeaseRenewer(dfs);
  FSDataOutputStream leaseRecoveryPath=dfs.create(new Path(filePath));
  leaseRecoveryPath.write(bytes);
  leaseRecoveryPath.hflush();
  cluster.setLeasePeriod(60 * 1000,1000);
  LocatedBlocks locatedBlocks;
  do {
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException e) {
      LOG.info("Innocuous exception",e);
    }
    locatedBlocks=DFSClientAdapter.callGetBlockLocations(cluster.getNameNodeRpc(),filePath,0L,bytes.length);
  }
 while (locatedBlocks.isUnderConstruction());
  return cluster.getNameNodeRpc().rollEditLog();
}
