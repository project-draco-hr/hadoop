{
  Configuration conf=new HdfsConfiguration();
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
  cluster.setLeasePeriod(LEASE_PERIOD,LEASE_PERIOD);
  cluster.waitActive();
  Path file=new Path("/testRecoveryFile");
  DistributedFileSystem dfs=cluster.getFileSystem();
  FSDataOutputStream out=dfs.create(file,(short)1);
  long writtenBytes=0;
  while (writtenBytes < 2 * 1024 * 1024) {
    out.writeLong(writtenBytes);
    writtenBytes+=8;
  }
  System.out.println("Written " + writtenBytes + " bytes");
  out.hsync();
  System.out.println("hsynced the data");
  DatanodeInfo dn=((DFSOutputStream)out.getWrappedStream()).getPipeline()[0];
  DataNodeProperties dnStopped=cluster.stopDataNode(dn.getName());
  LeaseManager lm=NameNodeAdapter.getLeaseManager(cluster.getNamesystem());
  int i=40;
  while (i-- > 0 && lm.countLease() != 0) {
    System.out.println("Still got " + lm.countLease() + " lease(s)");
    Thread.sleep(500);
  }
  assertTrue("The lease was not recovered",lm.countLease() == 0);
  System.out.println("Got " + lm.countLease() + " leases");
  FSDataInputStream in=dfs.open(file);
  try {
    in.readLong();
    assertTrue("Shouldn't have reached here",false);
  }
 catch (  BlockMissingException bme) {
    System.out.println("Correctly got BlockMissingException because datanode" + " is still dead");
  }
  cluster.restartDataNode(dnStopped);
  System.out.println("Restart datanode");
  in=dfs.open(file);
  int readBytes=0;
  while (in.available() != 0) {
    assertEquals("Didn't read the data we wrote",in.readLong(),readBytes);
    readBytes+=8;
  }
  assertEquals("Didn't get all the data",readBytes,writtenBytes);
  System.out.println("Read back all the " + readBytes + " bytes");
}
