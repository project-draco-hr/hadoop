{
  URL testFileUrl=getClass().getClassLoader().getResource(testFileName);
  assertNotNull("Cannot find " + testFileName,testFileUrl);
  File testFile=new File(testFileUrl.getFile());
  long testFileSize=testFile.length();
  Path testFilePath=new Path(testFile.getAbsolutePath());
  Configuration conf=new Configuration();
  conf.setInt(org.apache.hadoop.mapreduce.lib.input.LineRecordReader.MAX_LINE_LENGTH,Integer.MAX_VALUE);
  assertTrue("unexpected test data at " + testFile,testFileSize > firstSplitLength);
  TaskAttemptContext context=new TaskAttemptContextImpl(conf,new TaskAttemptID());
  FileSplit split=new FileSplit(testFilePath,0,testFileSize,(String[])null);
  LineRecordReader reader=new LineRecordReader();
  reader.initialize(split,context);
  int numRecordsNoSplits=0;
  while (reader.nextKeyValue()) {
    ++numRecordsNoSplits;
  }
  reader.close();
  split=new FileSplit(testFilePath,0,firstSplitLength,(String[])null);
  reader=new LineRecordReader();
  reader.initialize(split,context);
  int numRecordsFirstSplit=0;
  while (reader.nextKeyValue()) {
    ++numRecordsFirstSplit;
  }
  reader.close();
  split=new FileSplit(testFilePath,firstSplitLength,testFileSize - firstSplitLength,(String[])null);
  reader=new LineRecordReader();
  reader.initialize(split,context);
  int numRecordsRemainingSplits=0;
  while (reader.nextKeyValue()) {
    ++numRecordsRemainingSplits;
  }
  reader.close();
  assertEquals("Unexpected number of records in bzip2 compressed split",numRecordsNoSplits,numRecordsFirstSplit + numRecordsRemainingSplits);
}
