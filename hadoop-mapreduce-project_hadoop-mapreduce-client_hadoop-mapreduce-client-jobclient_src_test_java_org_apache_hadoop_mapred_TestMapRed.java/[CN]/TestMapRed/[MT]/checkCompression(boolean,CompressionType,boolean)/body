{
  JobConf conf=new JobConf(TestMapRed.class);
  Path testdir=new Path(TEST_DIR.getAbsolutePath());
  Path inDir=new Path(testdir,"in");
  Path outDir=new Path(testdir,"out");
  FileSystem fs=FileSystem.get(conf);
  fs.delete(testdir,true);
  FileInputFormat.setInputPaths(conf,inDir);
  FileOutputFormat.setOutputPath(conf,outDir);
  conf.setMapperClass(MyMap.class);
  conf.setReducerClass(MyReduce.class);
  conf.setOutputKeyClass(Text.class);
  conf.setOutputValueClass(Text.class);
  conf.setOutputFormat(SequenceFileOutputFormat.class);
  conf.set(MRConfig.FRAMEWORK_NAME,MRConfig.LOCAL_FRAMEWORK_NAME);
  if (includeCombine) {
    conf.setCombinerClass(IdentityReducer.class);
  }
  conf.setCompressMapOutput(compressMapOutputs);
  SequenceFileOutputFormat.setOutputCompressionType(conf,redCompression);
  try {
    if (!fs.mkdirs(testdir)) {
      throw new IOException("Mkdirs failed to create " + testdir.toString());
    }
    if (!fs.mkdirs(inDir)) {
      throw new IOException("Mkdirs failed to create " + inDir.toString());
    }
    Path inFile=new Path(inDir,"part0");
    DataOutputStream f=fs.create(inFile);
    f.writeBytes("Owen was here\n");
    f.writeBytes("Hadoop is fun\n");
    f.writeBytes("Is this done, yet?\n");
    f.close();
    RunningJob rj=JobClient.runJob(conf);
    assertTrue("job was complete",rj.isComplete());
    assertTrue("job was successful",rj.isSuccessful());
    Path output=new Path(outDir,Task.getOutputName(0));
    assertTrue("reduce output exists " + output,fs.exists(output));
    SequenceFile.Reader rdr=new SequenceFile.Reader(fs,output,conf);
    assertEquals("is reduce output compressed " + output,redCompression != CompressionType.NONE,rdr.isCompressed());
    rdr.close();
  }
  finally {
    fs.delete(testdir,true);
  }
}
