{
  Configuration conf=new Configuration();
  try (MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build()){
    DataNode dn=cluster.getDataNodes().get(0);
    for (int i=0; i < 100; i++) {
      DFSTestUtil.writeFile(cluster.getFileSystem(),new Path("/foo" + String.valueOf(i) + ".txt"),"test content");
    }
    DataNodeTestUtils.triggerBlockReport(dn);
    MBeanServer mbs=ManagementFactory.getPlatformMBeanServer();
    ObjectName mxbeanName=new ObjectName("Hadoop:service=DataNode,name=DataNodeInfo");
    String bpActorInfo=(String)mbs.getAttribute(mxbeanName,"BPServiceActorInfo");
    Assert.assertEquals(dn.getBPServiceActorInfo(),bpActorInfo);
    LOG.info("bpActorInfo is " + bpActorInfo);
    TypeReference<ArrayList<Map<String,String>>> typeRef=new TypeReference<ArrayList<Map<String,String>>>(){
    }
;
    ArrayList<Map<String,String>> bpActorInfoList=new ObjectMapper().readValue(bpActorInfo,typeRef);
    int maxDataLength=Integer.valueOf(bpActorInfoList.get(0).get("maxDataLength"));
    int confMaxDataLength=dn.getConf().getInt(CommonConfigurationKeys.IPC_MAXIMUM_DATA_LENGTH,CommonConfigurationKeys.IPC_MAXIMUM_DATA_LENGTH_DEFAULT);
    int maxBlockReportSize=Integer.valueOf(bpActorInfoList.get(0).get("maxBlockReportSize"));
    LOG.info("maxDataLength is " + maxDataLength);
    LOG.info("maxBlockReportSize is " + maxBlockReportSize);
    assertTrue("maxBlockReportSize should be greater than zero",maxBlockReportSize > 0);
    assertEquals("maxDataLength should be exactly " + "the same value of ipc.maximum.data.length",confMaxDataLength,maxDataLength);
  }
 }
