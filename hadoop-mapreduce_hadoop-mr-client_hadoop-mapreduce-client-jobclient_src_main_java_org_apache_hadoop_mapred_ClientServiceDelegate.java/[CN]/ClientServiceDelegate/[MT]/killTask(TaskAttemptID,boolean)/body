{
  org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId attemptID=TypeConverter.toYarn(taskAttemptID);
  KillTaskAttemptRequest killRequest=recordFactory.newRecordInstance(KillTaskAttemptRequest.class);
  FailTaskAttemptRequest failRequest=recordFactory.newRecordInstance(FailTaskAttemptRequest.class);
  MRClientProtocol protocol=getProxy(taskAttemptID.getJobID());
  if (protocol == null) {
    return false;
  }
  try {
    if (fail) {
      failRequest.setTaskAttemptId(attemptID);
      getProxy(taskAttemptID.getJobID()).failTaskAttempt(failRequest);
    }
 else {
      killRequest.setTaskAttemptId(attemptID);
      getProxy(taskAttemptID.getJobID()).killTaskAttempt(killRequest);
    }
  }
 catch (  YarnRemoteException yre) {
    LOG.warn(RPCUtil.toString(yre));
    throw yre;
  }
catch (  Exception e) {
    LOG.debug("Failed to contact application master ",e);
    MRClientProtocol proxy=getRefreshedProxy(taskAttemptID.getJobID());
    if (proxy == null) {
      return false;
    }
    try {
      if (fail) {
        failRequest.setTaskAttemptId(attemptID);
        proxy.failTaskAttempt(failRequest);
      }
 else {
        killRequest.setTaskAttemptId(attemptID);
        proxy.killTaskAttempt(killRequest);
      }
    }
 catch (    YarnRemoteException yre) {
      LOG.warn(RPCUtil.toString(yre));
      throw yre;
    }
  }
  return true;
}
