{
  Configuration conf=new HdfsConfiguration();
  SimulatedFSDataset.setFactory(conf);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).build();
  try {
    FileSystem fs=cluster.getFileSystem();
    List<DataNode> datanodes=cluster.getDataNodes();
    assertEquals(datanodes.size(),1);
    DataNode datanode=datanodes.get(0);
    MetricsRecordBuilder rb=getMetrics(datanode.getMetrics().name());
    final long LONG_FILE_LEN=1024 * 1024 * 10;
    long startWriteValue=getLongCounter("TotalWriteTime",rb);
    long startReadValue=getLongCounter("TotalReadTime",rb);
    for (int x=0; x < 50; x++) {
      DFSTestUtil.createFile(fs,new Path("/time.txt." + x),LONG_FILE_LEN,(short)1,Time.monotonicNow());
    }
    for (int x=0; x < 50; x++) {
      DFSTestUtil.readFile(fs,new Path("/time.txt." + x));
    }
    MetricsRecordBuilder rbNew=getMetrics(datanode.getMetrics().name());
    long endWriteValue=getLongCounter("TotalWriteTime",rbNew);
    long endReadValue=getLongCounter("TotalReadTime",rbNew);
    Thread.sleep(100);
    assertTrue(endReadValue > startReadValue);
    assertTrue(endWriteValue > startWriteValue);
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
