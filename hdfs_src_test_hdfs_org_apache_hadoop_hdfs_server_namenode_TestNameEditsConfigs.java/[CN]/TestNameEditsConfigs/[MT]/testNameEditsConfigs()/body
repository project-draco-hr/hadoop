{
  Path file1=new Path("TestNameEditsConfigs1");
  Path file2=new Path("TestNameEditsConfigs2");
  Path file3=new Path("TestNameEditsConfigs3");
  MiniDFSCluster cluster=null;
  SecondaryNameNode secondary=null;
  Configuration conf=null;
  FileSystem fileSys=null;
  final File newNameDir=new File(base_dir,"name");
  final File newEditsDir=new File(base_dir,"edits");
  final File nameAndEdits=new File(base_dir,"name_and_edits");
  final File checkpointNameDir=new File(base_dir,"secondname");
  final File checkpointEditsDir=new File(base_dir,"secondedits");
  final File checkpointNameAndEdits=new File(base_dir,"second_name_and_edits");
  ImmutableList<File> allCurrentDirs=ImmutableList.of(new File(nameAndEdits,"current"),new File(newNameDir,"current"),new File(newEditsDir,"current"),new File(checkpointNameAndEdits,"current"),new File(checkpointNameDir,"current"),new File(checkpointEditsDir,"current"));
  ImmutableList<File> imageCurrentDirs=ImmutableList.of(new File(nameAndEdits,"current"),new File(newNameDir,"current"),new File(checkpointNameAndEdits,"current"),new File(checkpointNameDir,"current"));
  conf=new HdfsConfiguration();
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,nameAndEdits.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_EDITS_DIR_KEY,nameAndEdits.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_DIR_KEY,checkpointNameAndEdits.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_EDITS_DIR_KEY,checkpointNameAndEdits.getPath());
  replication=(short)conf.getInt(DFSConfigKeys.DFS_REPLICATION_KEY,3);
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).manageNameDfsDirs(false).build();
  cluster.waitActive();
  secondary=startSecondaryNameNode(conf);
  fileSys=cluster.getFileSystem();
  try {
    assertTrue(!fileSys.exists(file1));
    writeFile(fileSys,file1,replication);
    checkFile(fileSys,file1,replication);
    secondary.doCheckpoint();
  }
  finally {
    fileSys.close();
    cluster.shutdown();
    secondary.shutdown();
  }
  conf=new HdfsConfiguration();
  assertTrue(newNameDir.mkdir());
  assertTrue(newEditsDir.mkdir());
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,nameAndEdits.getPath() + "," + newNameDir.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_EDITS_DIR_KEY,nameAndEdits.getPath() + "," + newEditsDir.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_DIR_KEY,checkpointNameDir.getPath() + "," + checkpointNameAndEdits.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_EDITS_DIR_KEY,checkpointEditsDir.getPath() + "," + checkpointNameAndEdits.getPath());
  replication=(short)conf.getInt(DFSConfigKeys.DFS_REPLICATION_KEY,3);
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).format(false).manageNameDfsDirs(false).build();
  cluster.waitActive();
  secondary=startSecondaryNameNode(conf);
  fileSys=cluster.getFileSystem();
  try {
    assertTrue(fileSys.exists(file1));
    checkFile(fileSys,file1,replication);
    cleanupFile(fileSys,file1);
    writeFile(fileSys,file2,replication);
    checkFile(fileSys,file2,replication);
    secondary.doCheckpoint();
  }
  finally {
    fileSys.close();
    cluster.shutdown();
    secondary.shutdown();
  }
  FSImageTestUtil.assertParallelFilesAreIdentical(allCurrentDirs,ImmutableSet.of("VERSION"));
  FSImageTestUtil.assertSameNewestImage(imageCurrentDirs);
  conf=new HdfsConfiguration();
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,newNameDir.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_EDITS_DIR_KEY,newEditsDir.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_DIR_KEY,checkpointNameDir.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_EDITS_DIR_KEY,checkpointEditsDir.getPath());
  replication=(short)conf.getInt(DFSConfigKeys.DFS_REPLICATION_KEY,3);
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).format(false).manageNameDfsDirs(false).build();
  cluster.waitActive();
  secondary=startSecondaryNameNode(conf);
  fileSys=cluster.getFileSystem();
  try {
    assertTrue(!fileSys.exists(file1));
    assertTrue(fileSys.exists(file2));
    checkFile(fileSys,file2,replication);
    cleanupFile(fileSys,file2);
    writeFile(fileSys,file3,replication);
    checkFile(fileSys,file3,replication);
    secondary.doCheckpoint();
  }
  finally {
    fileSys.close();
    cluster.shutdown();
    secondary.shutdown();
  }
  checkImageAndEditsFilesExistence(newNameDir,true,false);
  checkImageAndEditsFilesExistence(newEditsDir,false,true);
  checkImageAndEditsFilesExistence(checkpointNameDir,true,false);
  checkImageAndEditsFilesExistence(checkpointEditsDir,false,true);
  assertTrue(FileUtil.fullyDelete(new File(nameAndEdits,"current")));
  assertTrue(FileUtil.fullyDelete(new File(checkpointNameAndEdits,"current")));
  conf=new HdfsConfiguration();
  conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,nameAndEdits.getPath() + "," + newNameDir.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_EDITS_DIR_KEY,nameAndEdits + "," + newEditsDir.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_DIR_KEY,checkpointNameDir.getPath() + "," + checkpointNameAndEdits.getPath());
  conf.set(DFSConfigKeys.DFS_NAMENODE_CHECKPOINT_EDITS_DIR_KEY,checkpointEditsDir.getPath() + "," + checkpointNameAndEdits.getPath());
  replication=(short)conf.getInt(DFSConfigKeys.DFS_REPLICATION_KEY,3);
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).format(false).manageNameDfsDirs(false).build();
  cluster.waitActive();
  secondary=startSecondaryNameNode(conf);
  fileSys=cluster.getFileSystem();
  try {
    assertTrue(!fileSys.exists(file1));
    assertTrue(!fileSys.exists(file2));
    assertTrue(fileSys.exists(file3));
    checkFile(fileSys,file3,replication);
    secondary.doCheckpoint();
  }
  finally {
    fileSys.close();
    cluster.shutdown();
    secondary.shutdown();
  }
  checkImageAndEditsFilesExistence(nameAndEdits,true,true);
  checkImageAndEditsFilesExistence(checkpointNameAndEdits,true,true);
}
