{
  Configuration conf=new Configuration();
  conf.setInt(JobContext.NUM_REDUCES,2);
  CompressionEmulationUtil.setCompressionEmulationEnabled(conf,true);
  conf.setBoolean(FileOutputFormat.COMPRESS,true);
  CompressionEmulationUtil.setCompressionEmulationEnabled(conf,true);
  conf.setBoolean(MRJobConfig.MAP_OUTPUT_COMPRESS,true);
  TaskAttemptID taskId=new TaskAttemptID();
  RawKeyValueIterator input=new FakeRawKeyValueReducerIterator();
  Counter counter=new GenericCounter();
  Counter inputValueCounter=new GenericCounter();
  RecordWriter<NullWritable,NullWritable> output=new LoadRecordReduceWriter();
  OutputCommitter committer=new CustomOutputCommitter();
  StatusReporter reporter=new DummyReporter();
  RawComparator<GridmixKey> comparator=new FakeRawComparator();
  ReduceContext<GridmixKey,NullWritable,NullWritable,NullWritable> reducecontext=new ReduceContextImpl<GridmixKey,NullWritable,NullWritable,NullWritable>(conf,taskId,input,counter,inputValueCounter,output,committer,reporter,comparator,GridmixKey.class,NullWritable.class);
  org.apache.hadoop.mapreduce.Reducer<GridmixKey,NullWritable,NullWritable,NullWritable>.Context context=new WrappedReducer<GridmixKey,NullWritable,NullWritable,NullWritable>().getReducerContext(reducecontext);
  SleepReducer test=new SleepReducer();
  long start=System.currentTimeMillis();
  test.setup(context);
  long sleeper=context.getCurrentKey().getReduceOutputBytes();
  assertEquals("Sleeping... " + sleeper + " ms left",context.getStatus());
  assertTrue(System.currentTimeMillis() >= (start + sleeper));
  test.cleanup(context);
  assertEquals("Slept for " + sleeper,context.getStatus());
}
