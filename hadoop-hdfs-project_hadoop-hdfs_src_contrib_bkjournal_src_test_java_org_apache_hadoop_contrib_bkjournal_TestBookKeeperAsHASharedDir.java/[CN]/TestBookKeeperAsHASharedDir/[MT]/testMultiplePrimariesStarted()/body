{
  Path p1=new Path("/testBKJMMultiplePrimary");
  MiniDFSCluster cluster=null;
  try {
    Configuration conf=new Configuration();
    conf.setInt(DFSConfigKeys.DFS_HA_TAILEDITS_PERIOD_KEY,1);
    conf.set(DFSConfigKeys.DFS_NAMENODE_SHARED_EDITS_DIR_KEY,BKJMUtil.createJournalURI("/hotfailoverMultiple").toString());
    BKJMUtil.addJournalManagerDefinition(conf);
    cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).manageNameDfsSharedDirs(false).checkExitOnShutdown(false).build();
    NameNode nn1=cluster.getNameNode(0);
    NameNode nn2=cluster.getNameNode(1);
    cluster.waitActive();
    cluster.transitionToActive(0);
    FileSystem fs=HATestUtil.configureFailoverFs(cluster,conf);
    fs.mkdirs(p1);
    nn1.getRpcServer().rollEditLog();
    cluster.transitionToActive(1);
    fs=cluster.getFileSystem(0);
    try {
      fs.delete(p1,true);
      fail("Log update on older active should cause it to exit");
    }
 catch (    RemoteException re) {
      assertTrue(re.getClassName().contains("ExitException"));
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
