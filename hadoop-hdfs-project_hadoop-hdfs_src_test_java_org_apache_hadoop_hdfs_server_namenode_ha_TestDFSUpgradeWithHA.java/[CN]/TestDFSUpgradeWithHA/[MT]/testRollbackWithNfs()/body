{
  MiniDFSCluster cluster=null;
  FileSystem fs=null;
  try {
    cluster=new MiniDFSCluster.Builder(conf).nnTopology(MiniDFSNNTopology.simpleHATopology()).numDataNodes(0).build();
    File sharedDir=new File(cluster.getSharedEditsDir(0,1));
    checkClusterPreviousDirExistence(cluster,false);
    assertCTimesEqual(cluster);
    checkPreviousDirExistence(sharedDir,false);
    cluster.transitionToActive(0);
    fs=HATestUtil.configureFailoverFs(cluster,conf);
    assertTrue(fs.mkdirs(new Path("/foo1")));
    cluster.shutdownNameNode(1);
    cluster.getNameNodeInfos()[0].setStartOpt(StartupOption.UPGRADE);
    cluster.restartNameNode(0,false);
    checkNnPreviousDirExistence(cluster,0,true);
    checkNnPreviousDirExistence(cluster,1,false);
    checkPreviousDirExistence(sharedDir,true);
    assertTrue(fs.mkdirs(new Path("/foo2")));
    int rc=BootstrapStandby.run(new String[]{"-force"},cluster.getConfiguration(1));
    assertEquals(0,rc);
    cluster.restartNameNode(1);
    checkNnPreviousDirExistence(cluster,0,true);
    checkNnPreviousDirExistence(cluster,1,false);
    checkPreviousDirExistence(sharedDir,true);
    assertCTimesEqual(cluster);
    Collection<URI> nn1NameDirs=cluster.getNameDirs(0);
    cluster.shutdown();
    conf.setStrings(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,Joiner.on(",").join(nn1NameDirs));
    NameNode.doRollback(conf,false);
    checkNnPreviousDirExistence(cluster,0,false);
    checkPreviousDirExistence(sharedDir,false);
  }
  finally {
    if (fs != null) {
      fs.close();
    }
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
