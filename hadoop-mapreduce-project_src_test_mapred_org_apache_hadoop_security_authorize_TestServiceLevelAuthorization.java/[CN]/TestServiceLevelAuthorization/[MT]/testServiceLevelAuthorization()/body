{
  MiniDFSCluster dfs=null;
  MiniMRCluster mr=null;
  FileSystem fileSys=null;
  try {
    final int slaves=4;
    Configuration conf=new Configuration();
    conf.setClass(PolicyProvider.POLICY_PROVIDER_CONFIG,HadoopPolicyProvider.class,PolicyProvider.class);
    conf.setBoolean(ServiceAuthorizationManager.SERVICE_AUTHORIZATION_CONFIG,true);
    dfs=new MiniDFSCluster(conf,slaves,true,null);
    Set<Class<?>> protocolsWithAcls=NameNodeAdapter.getRpcServer(dfs.getNameNode()).getServiceAuthorizationManager().getProtocolsWithAcls();
    Service[] hdfsServices=new HDFSPolicyProvider().getServices();
    for (    Service service : hdfsServices) {
      if (!protocolsWithAcls.contains(service.getProtocol()))       fail("service authorization manager has no entry for protocol " + service.getProtocol());
    }
    if (hdfsServices.length != protocolsWithAcls.size())     fail("there should be an entry for every HDFS service in the protocols with ACLs map");
    fileSys=dfs.getFileSystem();
    JobConf mrConf=new JobConf(conf);
    mr=new MiniMRCluster(slaves,fileSys.getUri().toString(),1,null,null,mrConf);
    protocolsWithAcls=NameNodeAdapter.getRpcServer(dfs.getNameNode()).getServiceAuthorizationManager().getProtocolsWithAcls();
    hdfsServices=new HDFSPolicyProvider().getServices();
    for (    Service service : hdfsServices) {
      if (!protocolsWithAcls.contains(service.getProtocol()))       fail("service authorization manager has no entry for protocol " + service.getProtocol());
    }
    if (hdfsServices.length != protocolsWithAcls.size())     fail("there should be an entry for every HDFS service in the protocols with ACLs map");
    mr.setInlineCleanupThreads();
    TestMiniMRWithDFS.runPI(mr,mr.createJobConf(mrConf));
    TestMiniMRWithDFS.runWordCount(mr,mr.createJobConf(mrConf));
  }
  finally {
    if (dfs != null) {
      dfs.shutdown();
    }
    if (mr != null) {
      mr.shutdown();
    }
  }
}
