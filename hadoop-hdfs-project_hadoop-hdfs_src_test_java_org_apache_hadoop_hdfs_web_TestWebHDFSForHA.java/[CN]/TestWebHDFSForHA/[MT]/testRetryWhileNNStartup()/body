{
  final Configuration conf=DFSTestUtil.newHAConfiguration(LOGICAL_NAME);
  MiniDFSCluster cluster=null;
  final Map<String,Boolean> resultMap=new HashMap<String,Boolean>();
  try {
    cluster=new MiniDFSCluster.Builder(conf).nnTopology(topo).numDataNodes(0).build();
    HATestUtil.setFailoverConfigurations(cluster,conf,LOGICAL_NAME);
    cluster.waitActive();
    cluster.transitionToActive(0);
    final NameNode namenode=cluster.getNameNode(0);
    final NamenodeProtocols rpcServer=namenode.getRpcServer();
    Whitebox.setInternalState(namenode,"rpcServer",null);
    new Thread(){
      @Override public void run(){
        boolean result=false;
        FileSystem fs=null;
        try {
          fs=FileSystem.get(WEBHDFS_URI,conf);
          final Path dir=new Path("/test");
          result=fs.mkdirs(dir);
        }
 catch (        IOException e) {
          result=false;
        }
 finally {
          IOUtils.cleanup(null,fs);
        }
synchronized (TestWebHDFSForHA.this) {
          resultMap.put("mkdirs",result);
          TestWebHDFSForHA.this.notifyAll();
        }
      }
    }
.start();
    Thread.sleep(1000);
    Whitebox.setInternalState(namenode,"rpcServer",rpcServer);
synchronized (this) {
      while (!resultMap.containsKey("mkdirs")) {
        this.wait();
      }
      Assert.assertTrue(resultMap.get("mkdirs"));
    }
  }
  finally {
    if (cluster != null) {
      cluster.shutdown();
    }
  }
}
