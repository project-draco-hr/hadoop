{
  final Configuration conf=new HdfsConfiguration();
  conf.set(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,"512");
  conf.setInt(DFSConfigKeys.DFS_CONTENT_SUMMARY_LIMIT_KEY,2);
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
  final FileSystem fs=cluster.getFileSystem();
  assertTrue("Not a HDFS: " + fs.getUri(),fs instanceof DistributedFileSystem);
  final DistributedFileSystem dfs=(DistributedFileSystem)fs;
  try {
    int fileLen=1024;
    short replication=3;
    int fileSpace=fileLen * replication;
    final Path quotaDir20=new Path("/nqdir0/qdir1/qdir20");
    assertTrue(dfs.mkdirs(quotaDir20));
    dfs.setQuota(quotaDir20,HdfsConstants.QUOTA_DONT_SET,6 * fileSpace);
    Path file=new Path(quotaDir20,"fileDir/file1");
    DFSTestUtil.createFile(dfs,file,fileLen * 3,replication,0);
    dfs.delete(file,false);
    dfs.setStoragePolicy(quotaDir20,HdfsConstants.HOT_STORAGE_POLICY_NAME);
    dfs.setQuotaByStorageType(quotaDir20,StorageType.DEFAULT,2 * fileSpace);
    boolean hasException=false;
    try {
      DFSTestUtil.createFile(dfs,file,fileLen * 3,replication,0);
    }
 catch (    QuotaByStorageTypeExceededException e) {
      hasException=true;
    }
    assertTrue(hasException);
    dfs.delete(file,false);
    dfs.setQuotaByStorageType(quotaDir20,StorageType.DEFAULT,6 * fileSpace);
  }
  finally {
    cluster.shutdown();
  }
}
