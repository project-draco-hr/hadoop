{
  try {
    this.block=block;
    this.chunkOffsetOK=chunkOffsetOK;
    this.corruptChecksumOk=corruptChecksumOk;
    this.verifyChecksum=verifyChecksum;
    this.clientTraceFmt=clientTraceFmt;
synchronized (datanode.data) {
      this.replica=getReplica(block,datanode);
      this.replicaVisibleLength=replica.getVisibleLength();
    }
    ChunkChecksum chunkChecksum=null;
    if (replica instanceof ReplicaBeingWritten) {
      long minEndOffset=startOffset + length;
      waitForMinLength((ReplicaBeingWritten)replica,minEndOffset);
      ReplicaInPipeline rip=(ReplicaInPipeline)replica;
      chunkChecksum=rip.getLastChecksumAndDataLen();
    }
    if (replica.getGenerationStamp() < block.getGenerationStamp()) {
      throw new IOException("Replica gen stamp < block genstamp, block=" + block + ", replica="+ replica);
    }
    if (replicaVisibleLength < 0) {
      throw new IOException("Replica is not readable, block=" + block + ", replica="+ replica);
    }
    if (DataNode.LOG.isDebugEnabled()) {
      DataNode.LOG.debug("block=" + block + ", replica="+ replica);
    }
    this.transferToAllowed=datanode.transferToAllowed && (!is32Bit || length <= Integer.MAX_VALUE);
    DataChecksum csum;
    if (!corruptChecksumOk || datanode.data.metaFileExists(block)) {
      checksumIn=new DataInputStream(new BufferedInputStream(datanode.data.getMetaDataInputStream(block),HdfsConstants.IO_FILE_BUFFER_SIZE));
      BlockMetadataHeader header=BlockMetadataHeader.readHeader(checksumIn);
      short version=header.getVersion();
      if (version != FSDataset.METADATA_VERSION) {
        LOG.warn("Wrong version (" + version + ") for metadata file for "+ block+ " ignoring ...");
      }
      csum=header.getChecksum();
    }
 else {
      LOG.warn("Could not find metadata file for " + block);
      csum=DataChecksum.newDataChecksum(DataChecksum.CHECKSUM_NULL,16 * 1024);
    }
    int size=csum.getBytesPerChecksum();
    if (size > 10 * 1024 * 1024 && size > replicaVisibleLength) {
      csum=DataChecksum.newDataChecksum(csum.getChecksumType(),Math.max((int)replicaVisibleLength,10 * 1024 * 1024));
      size=csum.getBytesPerChecksum();
    }
    chunkSize=size;
    checksum=csum;
    checksumSize=checksum.getChecksumSize();
    length=length < 0 ? replicaVisibleLength : length;
    long end=chunkChecksum != null ? chunkChecksum.getDataLength() : replica.getBytesOnDisk();
    if (startOffset < 0 || startOffset > end || (length + startOffset) > end) {
      String msg=" Offset " + startOffset + " and length "+ length+ " don't match block "+ block+ " ( blockLen "+ end+ " )";
      LOG.warn(datanode.getDNRegistrationForBP(block.getBlockPoolId()) + ":sendBlock() : " + msg);
      throw new IOException(msg);
    }
    offset=startOffset - (startOffset % chunkSize);
    if (length >= 0) {
      long tmpLen=startOffset + length;
      if (tmpLen % chunkSize != 0) {
        tmpLen+=(chunkSize - tmpLen % chunkSize);
      }
      if (tmpLen < end) {
        end=tmpLen;
      }
 else       if (chunkChecksum != null) {
        this.lastChunkChecksum=chunkChecksum;
      }
    }
    endOffset=end;
    if (offset > 0) {
      long checksumSkip=(offset / chunkSize) * checksumSize;
      if (checksumSkip > 0) {
        IOUtils.skipFully(checksumIn,checksumSkip);
      }
    }
    seqno=0;
    if (DataNode.LOG.isDebugEnabled()) {
      DataNode.LOG.debug("replica=" + replica);
    }
    blockIn=datanode.data.getBlockInputStream(block,offset);
  }
 catch (  IOException ioe) {
    IOUtils.closeStream(this);
    IOUtils.closeStream(blockIn);
    throw ioe;
  }
}
