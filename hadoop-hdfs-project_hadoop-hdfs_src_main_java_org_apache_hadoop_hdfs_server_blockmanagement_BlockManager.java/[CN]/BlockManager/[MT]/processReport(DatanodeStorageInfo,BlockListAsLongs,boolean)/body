{
  Collection<BlockInfoToAdd> toAdd=new LinkedList<>();
  Collection<BlockInfo> toRemove=new TreeSet<>();
  Collection<Block> toInvalidate=new LinkedList<>();
  Collection<BlockToMarkCorrupt> toCorrupt=new LinkedList<>();
  Collection<StatefulBlockInfo> toUC=new LinkedList<>();
  Iterable<BlockReportReplica> sortedReport;
  if (!sorted) {
    blockLog.warn("BLOCK* processReport: Report from the DataNode ({}) is " + "unsorted. This will cause overhead on the NameNode " + "which needs to sort the Full BR. Please update the "+ "DataNode to the same version of Hadoop HDFS as the "+ "NameNode ({}).",storageInfo.getDatanodeDescriptor().getDatanodeUuid(),VersionInfo.getVersion());
    Set<BlockReportReplica> set=new FoldedTreeSet<>();
    for (    BlockReportReplica iblk : report) {
      set.add(new BlockReportReplica(iblk));
    }
    sortedReport=set;
  }
 else {
    sortedReport=report;
  }
  reportDiffSorted(storageInfo,sortedReport,toAdd,toRemove,toInvalidate,toCorrupt,toUC);
  DatanodeDescriptor node=storageInfo.getDatanodeDescriptor();
  for (  StatefulBlockInfo b : toUC) {
    addStoredBlockUnderConstruction(b,storageInfo);
  }
  for (  BlockInfo b : toRemove) {
    removeStoredBlock(b,node);
  }
  int numBlocksLogged=0;
  for (  BlockInfoToAdd b : toAdd) {
    addStoredBlock(b.stored,b.reported,storageInfo,null,numBlocksLogged < maxNumBlocksToLog);
    numBlocksLogged++;
  }
  if (numBlocksLogged > maxNumBlocksToLog) {
    blockLog.info("BLOCK* processReport: logged info for {} of {} " + "reported.",maxNumBlocksToLog,numBlocksLogged);
  }
  for (  Block b : toInvalidate) {
    addToInvalidates(b,node);
  }
  for (  BlockToMarkCorrupt b : toCorrupt) {
    markBlockAsCorrupt(b,storageInfo,node);
  }
  return toInvalidate;
}
