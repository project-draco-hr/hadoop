{
  final Configuration conf=new HdfsConfiguration();
  final int NUM_OF_DATANODES=3;
  final MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_OF_DATANODES).build();
  try {
    cluster.waitActive();
    final FSNamesystem namesystem=cluster.getNamesystem();
    final BlockManager bm=namesystem.getBlockManager();
    final int blockInvalidateLimit=bm.getDatanodeManager().blockInvalidateLimit;
    DatanodeDescriptor[] nodes=namesystem.heartbeats.toArray(new DatanodeDescriptor[NUM_OF_DATANODES]);
    assertEquals(nodes.length,NUM_OF_DATANODES);
    namesystem.writeLock();
    try {
      for (int i=0; i < nodes.length; i++) {
        for (int j=0; j < 3 * blockInvalidateLimit + 1; j++) {
          Block block=new Block(i * (blockInvalidateLimit + 1) + j,0,GenerationStamp.FIRST_VALID_STAMP);
          bm.addToInvalidates(block,nodes[i]);
        }
      }
      assertEquals(blockInvalidateLimit * NUM_OF_DATANODES,bm.computeInvalidateWork(NUM_OF_DATANODES + 1));
      assertEquals(blockInvalidateLimit * NUM_OF_DATANODES,bm.computeInvalidateWork(NUM_OF_DATANODES));
      assertEquals(blockInvalidateLimit * (NUM_OF_DATANODES - 1),bm.computeInvalidateWork(NUM_OF_DATANODES - 1));
      int workCount=bm.computeInvalidateWork(1);
      if (workCount == 1) {
        assertEquals(blockInvalidateLimit + 1,bm.computeInvalidateWork(2));
      }
 else {
        assertEquals(workCount,blockInvalidateLimit);
        assertEquals(2,bm.computeInvalidateWork(2));
      }
    }
  finally {
      namesystem.writeUnlock();
    }
  }
  finally {
    cluster.shutdown();
  }
}
