{
  dataNodes[0].updateHeartbeat(2 * HdfsConstants.MIN_BLOCKS_FOR_WRITE * BLOCK_SIZE,0L,HdfsConstants.MIN_BLOCKS_FOR_WRITE * BLOCK_SIZE,0L,4,0);
  DatanodeDescriptor[] targets;
  targets=chooseTarget(0);
  assertEquals(targets.length,0);
  targets=chooseTarget(1);
  assertEquals(targets.length,1);
  assertEquals(targets[0],dataNodes[0]);
  targets=chooseTarget(2);
  assertEquals(targets.length,2);
  assertEquals(targets[0],dataNodes[0]);
  assertFalse(cluster.isOnSameRack(targets[0],targets[1]));
  targets=chooseTarget(3);
  assertEquals(targets.length,3);
  assertEquals(targets[0],dataNodes[0]);
  assertFalse(cluster.isOnSameRack(targets[0],targets[1]));
  assertTrue(cluster.isOnSameRack(targets[1],targets[2]));
  assertFalse(cluster.isOnSameNodeGroup(targets[1],targets[2]));
  targets=chooseTarget(4);
  assertEquals(targets.length,4);
  assertEquals(targets[0],dataNodes[0]);
  assertTrue(cluster.isOnSameRack(targets[1],targets[2]) || cluster.isOnSameRack(targets[2],targets[3]));
  assertFalse(cluster.isOnSameRack(targets[0],targets[2]));
  verifyNoTwoTargetsOnSameNodeGroup(targets);
  dataNodes[0].updateHeartbeat(2 * HdfsConstants.MIN_BLOCKS_FOR_WRITE * BLOCK_SIZE,0L,HdfsConstants.MIN_BLOCKS_FOR_WRITE * BLOCK_SIZE,0L,0,0);
}
