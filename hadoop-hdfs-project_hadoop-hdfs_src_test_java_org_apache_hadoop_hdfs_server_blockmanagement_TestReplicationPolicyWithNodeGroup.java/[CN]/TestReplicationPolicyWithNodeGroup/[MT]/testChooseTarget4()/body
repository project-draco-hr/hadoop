{
  for (int i=0; i < 3; i++) {
    dataNodes[i].updateHeartbeat(2 * HdfsConstants.MIN_BLOCKS_FOR_WRITE * BLOCK_SIZE,0L,(HdfsConstants.MIN_BLOCKS_FOR_WRITE - 1) * BLOCK_SIZE,0L,0,0);
  }
  DatanodeDescriptor[] targets;
  targets=replicator.chooseTarget(filename,0,dataNodes[0],BLOCK_SIZE);
  assertEquals(targets.length,0);
  targets=replicator.chooseTarget(filename,1,dataNodes[0],BLOCK_SIZE);
  assertEquals(targets.length,1);
  assertFalse(cluster.isOnSameRack(targets[0],dataNodes[0]));
  targets=replicator.chooseTarget(filename,2,dataNodes[0],BLOCK_SIZE);
  assertEquals(targets.length,2);
  assertFalse(cluster.isOnSameRack(targets[0],dataNodes[0]));
  assertFalse(cluster.isOnSameRack(targets[0],targets[1]));
  targets=replicator.chooseTarget(filename,3,dataNodes[0],BLOCK_SIZE);
  assertEquals(targets.length,3);
  for (int i=0; i < 3; i++) {
    assertFalse(cluster.isOnSameRack(targets[i],dataNodes[0]));
  }
  verifyNoTwoTargetsOnSameNodeGroup(targets);
  assertTrue(cluster.isOnSameRack(targets[0],targets[1]) || cluster.isOnSameRack(targets[1],targets[2]));
  assertFalse(cluster.isOnSameRack(targets[0],targets[2]));
}
