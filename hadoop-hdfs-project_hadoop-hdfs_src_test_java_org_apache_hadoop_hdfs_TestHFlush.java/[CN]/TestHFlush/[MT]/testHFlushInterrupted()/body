{
  final int DATANODE_NUM=2;
  final int fileLen=6;
  byte[] fileContents=AppendTestUtil.initBuffer(fileLen);
  Configuration conf=new HdfsConfiguration();
  final Path p=new Path("/hflush-interrupted");
  System.out.println("p=" + p);
  MiniDFSCluster cluster=new MiniDFSCluster.Builder(conf).numDataNodes(DATANODE_NUM).build();
  try {
    DistributedFileSystem fs=cluster.getFileSystem();
    FSDataOutputStream stm=AppendTestUtil.createFile(fs,p,DATANODE_NUM);
    stm.write(fileContents,0,2);
    Thread.currentThread().interrupt();
    try {
      stm.hflush();
      assertTrue(Thread.interrupted());
    }
 catch (    InterruptedIOException ie) {
      System.out.println("Got expected exception during flush");
    }
    assertFalse(Thread.interrupted());
    stm.hflush();
    stm.write(fileContents,2,2);
    stm.hflush();
    stm.write(fileContents,4,2);
    Thread.currentThread().interrupt();
    try {
      stm.close();
      assertTrue(Thread.interrupted());
    }
 catch (    InterruptedIOException ioe) {
      System.out.println("Got expected exception during close");
      assertFalse(Thread.interrupted());
      stm.close();
    }
    AppendTestUtil.checkFullFile(fs,p,4,fileContents,"Failed to deal with thread interruptions",false);
  }
  finally {
    cluster.shutdown();
  }
}
